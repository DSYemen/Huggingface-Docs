# ุฌููุฉ ุณุฑูุนุฉ

ุงุจุฏุฃ ุงุณุชุฎุฏุงู ููุชุจุฉ ๐ค Transformers! ุณูุงุก ููุช ูุทูุฑูุง ุฃู ูุณุชุฎุฏููุง ุนุงุฏููุงุ ุณุชุณุงุนุฏู ูุฐู ุงูุฌููุฉ ุงูุณุฑูุนุฉ ุนูู ุงูุจุฏุก ูุณุชุฑูู ููููุฉ ุงุณุชุฎุฏุงู [`pipeline`] ููุงุณุชูุชุงุฌุ ูุชุญููู ูููุฐุฌ ููุฏุฑุจ ูุณุจููุง ููุนุงูุฌ ูุณุจู ุจุงุณุชุฎุฏุงู [AutoClass](./model_doc/auto)ุ ูุงูุชุฏุฑูุจ ุงูุณุฑูุน ููููุฐุฌ ุจุงุณุชุฎุฏุงู PyTorch ุฃู TensorFlow. ุฅุฐุง ููุช ูุจุชุฏุฆูุงุ ููุตู ุจุงูุงุทูุงุน ุนูู ุฏุฑูุณูุง ุฃู [ุงูุฏูุฑุฉ](https://huggingface.co/course/chapter1/1) ููุญุตูู ุนูู ุดุฑุญ ุฃูุซุฑ ุชุนูููุง ููููุงููู ุงูุชู ุชู ุชูุฏูููุง ููุง.

ูุจู ุฃู ุชุจุฏุฃุ ุชุฃูุฏ ูู ุชุซุจูุช ุฌููุน ุงูููุชุจุงุช ุงูุถุฑูุฑูุฉ:

```bash
!pip install transformers datasets evaluate accelerate
```

ุณูุชุนูู ุนููู ุฃูุถูุง ุชุซุจูุช ุฅุทุงุฑ ุนูู ุงูุชุนูู ุงูุขูู ุงูููุถู ูุฏูู:

<frameworkcontent>
<pt>

```bash
pip install torch
```

</pt>

<tf>

```bash
pip install tensorflow
```

</tf>

</frameworkcontent>

## ุฎุท ุงูุฃูุงุจูุจ

<Youtube id="tiZFewofSLM"/>

ููุซู [`pipeline`] ุฃุณูู ูุฃุณุฑุน ุทุฑููุฉ ูุงุณุชุฎุฏุงู ูููุฐุฌ ููุฏุฑุจ ูุณุจููุง ููุงุณุชูุชุงุฌ. ููููู ุงุณุชุฎุฏุงู [`pipeline`] ุฌุงูุฒูุง ููุนุฏูุฏ ูู ุงูููุงู ุนุจุฑ ุทุฑุงุฆู ูุฎุชููุฉุ ูุงูุชู ูุธูุฑ ุจุนุถูุง ูู ุงูุฌุฏูู ุฃุฏูุงู:

<Tip>

ููุญุตูู ุนูู ูุงุฆูุฉ ูุงููุฉ ุจุงูููุงู ุงููุชุงุญุฉุ ุฑุงุฌุน [ูุฑุฌุน API ุฎุท ุงูุฃูุงุจูุจ](./main_classes/pipelines).

</Tip>

| ุงููููุฉ | ุงููุตู | ุงูุทุฑููุฉ | ูุนุฑู ุฎุท ุงูุฃูุงุจูุจ |
| --- | --- | --- | --- |
| ุชุตููู ุงููุต | ุชุนููู ุชุณููุฉ ุฅูู ุชุณูุณู ูุต ูุนูู | NLP | pipeline(task="sentiment-analysis") |
| ุชูููุฏ ุงููุต | ุชูููุฏ ูุต ุจูุงุกู ุนูู ููุฌู | NLP | pipeline(task="text-generation") |
| ุชูุฎูุต | ุชูููุฏ ููุฎุต ูุชุณูุณู ูุต ุฃู ูุณุชูุฏ | NLP | pipeline(task="summarization") |
| ุชุตููู ุงูุตูุฑ | ุชุนููู ุชุณููุฉ ุฅูู ุตูุฑุฉ | ุฑุคูุฉ ุญุงุณูุจูุฉ | pipeline(task="image-classification") |
| ุชุฌุฒุฆุฉ ุงูุตูุฑ | ุชุนููู ุชุณููุฉ ุฅูู ูู ุจูุณู ูู ุตูุฑุฉ (ูุฏุนู ุงูุชุฌุฒุฆุฉ ุงูุฏูุงููุฉุ ูุงููููุฉุ ูุชุฌุฒุฆุฉ ุงูุญุงูุงุช) | ุฑุคูุฉ ุญุงุณูุจูุฉ | pipeline(task="image-segmentation") |
| ุงูุชุดุงู ุงูุฃุดูุงุก | ุงูุชูุจุค ุจุตูุงุฏูู ุงูุฅุญุงุทุฉ ููุฆุงุช ุงูุฃุดูุงุก ูู ุตูุฑุฉ | ุฑุคูุฉ ุญุงุณูุจูุฉ | pipeline(task="object-detection") |
| ุชุตููู ุงูุตูุช | ุชุนููู ุชุณููุฉ ุฅูู ุจูุงูุงุช ุตูุชูุฉ | ุตูุช | pipeline(task="audio-classification") |
| ุงูุชุนุฑู ุงูุชููุงุฆู ุนูู ุงูููุงู | ูุณุฎ ุงูููุงู ุฅูู ูุต | ุตูุช | pipeline(task="automatic-speech-recognition") |
| ุงูุฅุฌุงุจุฉ ุนูู ุงูุฃุณุฆูุฉ ุงููุฑุฆูุฉ | ุงูุฅุฌุงุจุฉ ุนูู ุณุคุงู ุญูู ุงูุตูุฑุฉุ ูุน ุฅุนุทุงุก ุตูุฑุฉ ูุณุคุงู | ูุชุนุฏุฏ ุงููุณุงุฆุท | pipeline(task="vqa") |
| ุงูุฅุฌุงุจุฉ ุนูู ุฃุณุฆูุฉ ุงููุณุชูุฏุงุช | ุงูุฅุฌุงุจุฉ ุนูู ุณุคุงู ุญูู ุงููุณุชูุฏุ ูุน ุฅุนุทุงุก ูุณุชูุฏ ูุณุคุงู | ูุชุนุฏุฏ ุงููุณุงุฆุท | pipeline(task="document-question-answering") |
| ูุตู ุงูุตูุฑุฉ | ุชูููุฏ ุนููุงู ูุตูุฑุฉ ูุนููุฉ | ูุชุนุฏุฏ ุงููุณุงุฆุท | pipeline(task="image-to-text") |

ุงุจุฏุฃ ุจุฅูุดุงุก ูุซูู ูู [`pipeline`] ูุชุญุฏูุฏ ุงููููุฉ ุงูุชู ุชุฑูุฏ ุงุณุชุฎุฏุงูู ููุง. ูู ูุฐุง ุงูุฏูููุ ุณุชุณุชุฎุฏู [`pipeline`] ูุชุญููู ุงููุดุงุนุฑ ููุซุงู:

```py
>>> from transformers import pipeline

>>> classifier = pipeline("sentiment-analysis")
```

ูููู [`pipeline`] ุจุชูุฒูู ูุชุฎุฒูู ูููุฐุฌ ุงูุชุฑุงุถู [ููุฏุฑุจ ูุณุจููุง](https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english) ููุนุงูุฌ ููุชุญููู ุงูุฏูุงูู. ุงูุขู ููููู ุงุณุชุฎุฏุงู `classifier` ุนูู ุงููุต ุงููุณุชูุฏู:

```py
>>> classifier("We are very happy to show you the ๐ค Transformers library.")
[{'label': 'POSITIVE', 'score': 0.9998}]
```

ุฅุฐุง ูุงู ูุฏูู ุฃูุซุฑ ูู ุฅุฏุฎุงู ูุงุญุฏุ ูู ุจุชูุฑูุฑ ุฅุฏุฎุงูุงุชู ููุงุฆูุฉ ุฅูู [`pipeline`] ูุฅุฑุฌุงุน ูุงุฆูุฉ ูู ุงูููุงููุณ:

```py
>>> results = classifier(["We are very happy to show you the ๐ค Transformers library.", "We hope you don't hate it."])
>>> for result in results:
...     print(f"label: {result['label']}, with score: {round(result['score'], 4)}")
label: POSITIVE, with score: 0.9998
label: NEGATIVE, with score: 0.5309
```

ูููู ูู [`pipeline`] ุฃูุถูุง ุฅุฌุฑุงุก ูุณุญ ุนุจุฑ ูุฌููุนุฉ ุจูุงูุงุช ูุงููุฉ ูุฃู ูููุฉ ุชุฑูุฏูุง. ูู ูุฐุง ุงููุซุงูุ ุฏุนูุง ูุฎุชุงุฑ ุงูุชุนุฑู ุงูุชููุงุฆู ุนูู ุงูููุงู ููููุฉ ููุง:

```py
>>> import torch
>>> from transformers import pipeline

>>> speech_recognizer = pipeline("automatic-speech-recognition", model="facebook/wav2vec2-base-960h")
```

ูู ุจุชุญููู ูุฌููุนุฉ ุจูุงูุงุช ุตูุชูุฉ (ุฑุงุฌุน ุฏููู ุงูุจุฏุก ุงูุณุฑูุน ูู ๐ค Datasets [ููุง](https://huggingface.co/docs/datasets/quickstart#audio) ููุฒูุฏ ูู ุงูุชูุงุตูู) ุงูุชู ุชุฑูุฏ ุฅุฌุฑุงุก ูุณุญ ุนุจุฑูุง. ุนูู ุณุจูู ุงููุซุงูุ ูู ุจุชุญููู ูุฌููุนุฉ ุจูุงูุงุช [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14):

```py
>>> from datasets import load_dataset, Audio

>>> dataset = load_dataset("PolyAI/minds14", name="en-US", split="train")  # doctest: +IGNORE_RESULT
```

ูุฌุจ ุงูุชุฃูุฏ ูู ุฃู ูุนุฏู ุฃุฎุฐ ุงูุนููุงุช ููุฌููุนุฉ ุงูุจูุงูุงุช ูุชุทุงุจู ูุน ูุนุฏู ุฃุฎุฐ ุงูุนููุงุช ุงูุฐู ุชู ุชุฏุฑูุจ [`facebook/wav2vec2-base-960h`](https://huggingface.co/facebook/wav2vec2-base-960h) ุนููู:

```py
>>> dataset = dataset.cast_column("audio", Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate))
```

ูุชู ุชุญููู ูููุงุช ุงูุตูุช ูุฅุนุงุฏุฉ ุฃุฎุฐ ุงูุนููุงุช ุชููุงุฆููุง ุนูุฏ ุงุณุชุฏุนุงุก ุงูุนููุฏ `"audio"`.

ุงุณุชุฎุฑุฌ ุตูุงุฆู ุงูููุฌุงุช ุงูุตูุชูุฉ ุงูุฎุงู ูู ุฃูู 4 ุนููุงุช ููุฑุฑูุง ููุงุฆูุฉ ุฅูู ุฎุท ุงูุฃูุงุจูุจ:

```py
>>> result = speech_recognizer(dataset[:4]["audio"])
>>> print([d["text"] for d in result])
['I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I PROCEED WITH DOING THAT', "FONDERING HOW I'D SET UP A JOIN TO HELL T WITH MY WIFE AND WHERE THE AP MIGHT BE", "I I'D LIKE TOY SET UP A JOINT ACCOUNT WITH MY PARTNER I'M NOT SEEING THE OPTION TO DO IT ON THE APSO I CALLED IN TO GET SOME HELP CAN I JUST DO IT OVER THE PHONE WITH YOU AND GIVE YOU THE INFORMATION OR SHOULD I DO IT IN THE AP AN I'M MISSING SOMETHING UQUETTE HAD PREFERRED TO JUST DO IT OVER THE PHONE OF POSSIBLE THINGS", 'HOW DO I FURN A JOINA COUT']
```

ุจุงููุณุจุฉ ููุฌููุนุงุช ุงูุจูุงูุงุช ุงูุฃูุจุฑ ุญูุซ ุชููู ุงูุฅุฏุฎุงูุงุช ูุจูุฑุฉ (ููุง ูู ุงูุญุงู ูู ุงูููุงู ุฃู ุงูุฑุคูุฉ)ุ ุณุชุฑุบุจ ูู ุชูุฑูุฑ ูููุฏ ุจุฏูุงู ูู ูุงุฆูุฉ ูุชุญููู ุฌููุน ุงูุฅุฏุฎุงูุงุช ูู ุงูุฐุงูุฑุฉ. ุฑุงุฌุน [ูุฑุฌุน API ุฎุท ุงูุฃูุงุจูุจ](./main_classes/pipelines) ููุฒูุฏ ูู ุงููุนูููุงุช.

### ุงุณุชุฎุฏุงู ูููุฐุฌ ููุนุงูุฌ ุขุฎุฑูู ูู ุฎุท ุงูุฃูุงุจูุจ

ูููู ูู [`pipeline`] ุงุณุชูุนุงุจ ุฃู ูููุฐุฌ ูู [Hub](https://huggingface.co/models)ุ ููุง ูุฌุนูู ุณูู ุงูุชููู ูุน ุญุงูุงุช ุงุณุชุฎุฏุงู ุฃุฎุฑู. ุนูู ุณุจูู ุงููุซุงูุ ุฅุฐุง ููุช ุชุฑูุฏ ูููุฐุฌูุง ูุงุฏุฑูุง ุนูู ุงูุชุนุงูู ูุน ุงููุต ุงููุฑูุณูุ ูููููู ุงุณุชุฎุฏุงู ุงูุนูุงูุงุช ุนูู Hub ูุชุตููุฉ ูููุฐุฌ ููุงุณุจ. ุชุนูุฏ ุงููุชูุฌุฉ ุงูุฃููู ุงููุตูุงุฉ ูููุฐุฌ BERT [ูุชุนุฏุฏ ุงููุบุงุช](https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment) ุงูุฐู ุชู ุถุจุทู ูุณุจููุง ูุชุญููู ุงููุดุงุนุฑ ูุงูุฐู ููููู ุงุณุชุฎุฏุงูู ูููุต ุงููุฑูุณู:

```py
>>> model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
```

<frameworkcontent>
<pt>

ุงุณุชุฎุฏู [`AutoModelForSequenceClassification`] ู [`AutoTokenizer`] ูุชุญููู ุงููููุฐุฌ ุงูููุฏุฑุจ ูุณุจููุง ููุนุงูุฌู ุงููุฑุชุจุท (ูุฒูุฏ ูู ุงููุนูููุงุช ุญูู `AutoClass` ูู ุงููุณู ุงูุชุงูู):

```py
>>> from transformers import AutoTokenizer, AutoModelForSequenceClassification

>>> model = AutoModelForSequenceClassification.from_pretrained(model_name)
>>> tokenizer = AutoTokenizer.from_pretrained(model_name)
```

</pt>

<tf>

ุงุณุชุฎุฏู [`TFAutoModelForSequenceClassification`] ู [`AutoTokenizer`] ูุชุญููู ุงููููุฐุฌ ุงูููุฏุฑุจ ูุณุจููุง ููุนุงูุฌู ุงููุฑุชุจุท (ูุฒูุฏ ูู ุงููุนูููุงุช ุญูู `TFAutoClass` ูู ุงููุณู ุงูุชุงูู):

```py
>>> from transformers import AutoTokenizer, TFAutoModelForSequenceClassification

>>> model = TFAutoModelForSequenceClassification.from_pretrained(model_name)
>>> tokenizer = AutoTokenizer.from_pretrained(model_name)
```

</tf>

</frameworkcontent>

ุญุฏุฏ ุงููููุฐุฌ ูุงููุนุงูุฌ ูู [`pipeline`]ุ ูุงูุขู ููููู ุชุทุจูู `classifier` ุนูู ุงููุต ุงููุฑูุณู:

```py
>>> classifier = pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)
>>> classifier("Nous sommes trรจs heureux de vous prรฉsenter la bibliothรจque ๐ค Transformers.")
[{'label': '5 stars', 'score': 0.7273}]
```

ุฅุฐุง ูู ุชุชููู ูู ุงูุนุซูุฑ ุนูู ูููุฐุฌ ูุญุงูุชู ุงูุงุณุชุฎุฏุงููุฉุ ูุณูุชุนูู ุนููู ุถุจุท ูููุฐุฌ ููุฏุฑุจ ูุณุจููุง ุนูู ุจูุงูุงุชู. ุงุทูุน ุนูู [ุฏููู ุงูุถุจุท ุงูุฏููู](./training) ุงูุฎุงุต ุจูุง ููุนุฑูุฉ ููููุฉ ุงูููุงู ุจุฐูู. ูุฃุฎูุฑูุงุ ุจุนุฏ ุถุจุท ูููุฐุฌู ุงูููุฏุฑุจ ูุณุจููุงุ ูุฑุฌู ุงูุชูููุฑ ูู [ูุดุงุฑูุชู](./model_sharing) ูุน ุงููุฌุชูุน ุนูู Hub ูุฏููุฑุทุฉ ุงูุชุนูู ุงูุขูู ููุฌููุน! ๐ค
## AutoClass

ุชุนูู ุงููุฆุชุงู `AutoModelForSequenceClassification` ู `AutoTokenizer` ูุนูุง ุชุญุช ุงูุบุทุงุก ูุชูููุฑ ูุธููุฉ `pipeline` ุงูุชู ุงุณุชุฎุฏูุชูุง ุฃุนูุงู. ุชุนุชุจุฑ AutoClass ุงุฎุชุตุงุฑูุง ูููู ุชููุงุฆููุง ุจุงุณุชุฑุฏุงุฏ ุจููุฉ ูููุฐุฌ ููุฏุฑุจ ูุณุจููุง ูู ุงุณูู ุฃู ูุณุงุฑู. ูู ูุง ุนููู ูุนูู ูู ุชุญุฏูุฏ ูุฆุฉ `AutoClass` ุงูููุงุณุจุฉ ููููุชู ููุฆุฉ ูุง ูุจู ุงููุนุงูุฌุฉ ุงููุฑุชุจุทุฉ ุจูุง.

ููุนุฏ ุฅูู ุงููุซุงู ูู ุงููุณู ุงูุณุงุจู ูููุฑู ููู ููููู ุงุณุชุฎุฏุงู ูุฆุฉ `AutoClass` ูุชูุฑุงุฑ ูุชุงุฆุฌ ูุธููุฉ `pipeline`.

### AutoTokenizer

ุชููู ุฃุฏุงุฉ ุงูุชุนุงูู ูุน ุงูุฑููุฒ ูุณุคููุฉ ุนู ูุนุงูุฌุฉ ุงููุต ูุณุจููุง ุฅูู ูุตูููุฉ ูู ุงูุฃุฑูุงู ููุฏุฎูุงุช ููููุฐุฌ. ููุงู ููุงุนุฏ ูุชุนุฏุฏุฉ ุชุญูู ุนูููุฉ ุงูุชุนุงูู ูุน ุงูุฑููุฒุ ุจูุง ูู ุฐูู ููููุฉ ุชูุณูู ุงููููุฉ ูุงููุณุชูู ุงูุฐู ูุฌุจ ุฃู ุชููุณู ููู ุงููููุงุช (ุชุนุฑู ุงููุฒูุฏ ุนู ุงูุชุนุงูู ูุน ุงูุฑููุฒ ูู ููุฎุต ุฃุฏุงุฉ ุงูุชุนุงูู ูุน ุงูุฑููุฒ). ุฃูู ุดูุก ูุฌุจ ุชุฐูุฑู ูู ุฃูู ุจุญุงุฌุฉ ุฅูู ุฅูุดุงุก ูุซูู ูุฃุฏุงุฉ ุงูุชุนุงูู ูุน ุงูุฑููุฒ ุจููุณ ุงุณู ุงููููุฐุฌ ูุถูุงู ุงุณุชุฎุฏุงูู ูููุงุนุฏ ุงูุชุนุงูู ูุน ุงูุฑููุฒ ููุณูุง ุงูุชู ุชู ุชุฏุฑูุจ ุงููููุฐุฌ ุนูููุง ูุณุจููุง.

ูู ุจุชุญููู ุฃุฏุงุฉ ุงูุชุนุงูู ูุน ุงูุฑููุฒ ุจุงุณุชุฎุฏุงู `AutoTokenizer`:

```py
>>> from transformers import AutoTokenizer

>>> model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
>>> tokenizer = AutoTokenizer.from_pretrained(model_name)
```

ูุฑุฑ ูุตู ุฅูู ุฃุฏุงุฉ ุงูุชุนุงูู ูุน ุงูุฑููุฒ:

```py
>>> encoding = tokenizer("We are very happy to show you the ๐ค Transformers library.")
>>> print(encoding)
{'input_ids': [101, 11312, 10320, 12495, 19308, 10114, 11391, 10855, 10103, 100, 58263, 13299, 119, 102],
'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
```

ุชูุฑุฌุน ุฃุฏุงุฉ ุงูุชุนุงูู ูุน ุงูุฑููุฒ ูุงููุณูุง ูุญุชูู ุนูู:

- `input_ids`: ุงูุชูุซููุงุช ุงูุฑูููุฉ ูุฑููุฒู.
- `attention_mask`: ุชุดูุฑ ุฅูู ุงูุฑููุฒ ุงูุชู ูุฌุจ ุงูุงูุชูุงู ุจูุง.

ูููู ูุฃุฏุงุฉ ุงูุชุนุงูู ูุน ุงูุฑููุฒ ุฃูุถูุง ูุจูู ูุงุฆูุฉ ูู ุงููุฏุฎูุงุชุ ูุชููู ุจุชูุณูู ุงููุต ูุชูุฐูุจู ูุฅุฑุฌุงุน ุฏูุนุฉ ุฐุงุช ุทูู ููุญุฏ:

```py
>>> pt_batch = tokenizer(
...     ["We are very happy to show you the ๐ค Transformers library.", "We hope you don't hate it."],
...     padding=True,
...     truncation=True,
...     max_length=512,
...     return_tensors="pt",
... )
```

```py
>>> tf_batch = tokenizer(
...     ["We are very happy to show you the ๐ค Transformers library.", "We hope you don't hate it."],
...     padding=True,
...     truncation=True,
...     max_length=512,
...     return_tensors="tf",
... )
```

### AutoModel

ูููุฑ ุจุฑูุงูุฌ ๐ค Transformers ุทุฑููุฉ ุจุณูุทุฉ ูููุญุฏุฉ ูุชุญููู ูุซููุงุช ููุฏุฑุจุฉ ูุณุจููุง. ููุฐุง ูุนูู ุฃูู ููููู ุชุญููู ูุฆุฉ `AutoModel` ููุง ูู ููุช ุชููู ุจุชุญููู ูุฆุฉ `AutoTokenizer`. ุงููุฑู ุงููุญูุฏ ูู ุชุญุฏูุฏ ูุฆุฉ `AutoModel` ุงูุตุญูุญุฉ ูููููุฉ. ุจุงููุณุจุฉ ูุชุตููู ุงููุตูุต (ุฃู ุงูุชุณูุณูุงุช)ุ ูุฌุจ ุนููู ุชุญููู `AutoModelForSequenceClassification`:

```py
>>> from transformers import AutoModelForSequenceClassification

>>> model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
>>> pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)
```

ุงูุขูุ ูุฑุฑ ุฏูุนุฉ ุงููุฏุฎูุงุช ุงูุชู ุชูุช ูุนุงูุฌุชูุง ูุณุจููุง ูุจุงุดุฑุฉ ุฅูู ุงููููุฐุฌ. ูุง ุนููู ุณูู ูู ุญุฒู ุงููุงููุณ ุนู ุทุฑูู ุฅุถุงูุฉ `**`:

```py
>>> pt_outputs = pt_model(**pt_batch)
```

ููุฎุฑุฌ ุงููููุฐุฌ ุงูุชูุดูุทุงุช ุงูููุงุฆูุฉ ูู ุฎุงุตูุฉ `logits`. ุทุจู ุฏุงูุฉ softmax ุนูู `logits` ูุงุณุชุฑุฏุงุฏ ุงูุงุญุชูุงูุงุช:

```py
>>> from torch import nn

>>> pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-1)
>>> print(pt_predictions)
tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],
[0.2084, 0.1826, 0.1969, 0.1755, 0.2365]], grad_fn=<SoftmaxBackward0>)
```

### Save a model

ุจูุฌุฑุฏ ุถุจุท ูููุฐุฌูุ ููููู ุญูุธู ูุน ุฃุฏุงุฉ ุงูุชุนุงูู ูุน ุงูุฑููุฒ ุงูุฎุงุตุฉ ุจู ุจุงุณุชุฎุฏุงู `PreTrainedModel.save_pretrained`:

```py
>>> pt_save_directory = "./pt_save_pretrained"
>>> tokenizer.save_pretrained(pt_save_directory)  # doctest: +IGNORE_RESULT
>>> pt_model.save_pretrained(pt_save_directory)
```

ุนูุฏูุง ุชููู ูุณุชุนุฏูุง ูุงุณุชุฎุฏุงู ุงููููุฐุฌ ูุฑุฉ ุฃุฎุฑูุ ุฃุนุฏ ุชุญูููู ุจุงุณุชุฎุฏุงู `PreTrainedModel.from_pretrained`:

```py
>>> pt_model = AutoModelForSequenceClassification.from_pretrained("./pt_save_pretrained")
```

### ููุฒุฉ ุฑุงุฆุนุฉ ูู ๐ค Transformers ูู ุงููุฏุฑุฉ ุนูู ุญูุธ ูููุฐุฌ ูุฅุนุงุฏุฉ ุชุญูููู ููููุฐุฌ PyTorch ุฃู TensorFlow. ูููู ููุนููุฉ `from_pt` ุฃู `from_tf` ุชุญููู ุงููููุฐุฌ ูู ุฅุทุงุฑ ุนูู ุฅูู ุขุฎุฑ:

```py
>>> from transformers import AutoModel

>>> tokenizer = AutoTokenizer.from_pretrained(tf_save_directory)
>>> pt_model = AutoModelForSequenceClassification.from_pretrained(tf_save_directory, from_tf=True)
```

```py
>>> from transformers import TFAutoModel

>>> tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)
>>> tf_model = TFAutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=True)
```

## Custom model builds

ููููู ุชุนุฏูู ูุฆุฉ ุชูููู ุงููููุฐุฌ ูุชุบููุฑ ุทุฑููุฉ ุจูุงุก ุงููููุฐุฌ. ูุญุฏุฏ ุงูุชูููู ุณูุงุช ุงููููุฐุฌุ ูุซู ุนุฏุฏ ุงูุทุจูุงุช ุงููุฎููุฉ ุฃู ุฑุคูุณ ุงูุงูุชูุงู. ุชุจุฏุฃ ูู ุงูุตูุฑ ุนูุฏ ุชููุฆุฉ ูููุฐุฌ ูู ูุฆุฉ ุชูููู ูุฎุตุต. ูุชู ุชููุฆุฉ ุณูุงุช ุงููููุฐุฌ ุจุดูู ุนุดูุงุฆูุ ููุฌุจ ุชุฏุฑูุจ ุงููููุฐุฌ ูุจู ุงุณุชุฎุฏุงูู ููุญุตูู ุนูู ูุชุงุฆุฌ ุฐุงุช ูุนูู.

ุงุจุฏุฃ ุจุงุณุชูุฑุงุฏ `AutoConfig`ุ ุซู ูู ุจุชุญููู ุงููููุฐุฌ ุงูููุฏุฑุจ ูุณุจููุง ุงูุฐู ุชุฑูุฏ ุชุนุฏููู. ุถูู `AutoConfig.from_pretrained`ุ ููููู ุชุญุฏูุฏ ุงูุณูุฉ ุงูุชู ุชุฑูุฏ ุชุบููุฑูุงุ ูุซู ุนุฏุฏ ุฑุคูุณ ุงูุงูุชูุงู:

```py
>>> from transformers import AutoConfig

>>> my_config = AutoConfig.from_pretrained("distilbert/distilbert-base-uncased", n_heads=12)
```

ุฃูุดุฆ ูููุฐุฌูุง ูู ุชููููู ุงููุฎุตุต ุจุงุณุชุฎุฏุงู `AutoModel.from_config`:

```py
>>> from transformers import AutoModel

>>> my_model = AutoModel.from_config(my_config)
```

ุฑุงุฌุน ุฏููู [ุฅูุดุงุก ุจููุฉ ูุฎุตุตุฉ](./create_a_model) ููุฒูุฏ ูู ุงููุนูููุงุช ุญูู ุชููููุงุช ูุฎุตุตุฉ.
ุจุงูุชุฃููุฏ! ูููุง ููู ุงููุต ุงููุชุฑุฌู ูุน ูุฑุงุนุงุฉ ุงูุชุนูููุงุช ุงูุชู ูุฏูุชูุง:

## ุงููุฏุฑุจ - ุญููุฉ ุชุฏุฑูุจูุฉ ููุญููููุฉ ูู PyTorch
ูููู ุงุณุชุฎุฏุงู ุฌููุน ุงูููุงุฐุฌ ูู [`torch.nn.Module`] ููุงุณูุ ูุฐุง ููููู ุงุณุชุฎุฏุงููุง ูู ุฃู ุญููุฉ ุชุฏุฑูุจูุฉ ูููุฐุฌูุฉ. ูู ุญูู ููููู ูุชุงุจุฉ ุญููุฉ ุงูุชุฏุฑูุจ ุงูุฎุงุตุฉ ุจูุ ูููุฑ ๐ค Transformers ูุฆุฉ [`Trainer`] ูู PyTorchุ ูุงูุชู ุชุญุชูู ุนูู ุญููุฉ ุงูุชุฏุฑูุจ ุงูุฃุณุงุณูุฉ ูุชุถูู ูุธุงุฆู ุฅุถุงููุฉ ูููุฒุงุช ูุซู ุงูุชุฏุฑูุจ ุงูููุฒุน ูุงูุฏูุฉ ุงููุฎุชูุทุฉุ ูุบูุฑ ุฐูู ุงููุซูุฑ.

ุงุนุชูุงุฏูุง ุนูู ูููุชูุ ุนุงุฏุฉู ูุง ุชููู ุจุชูุฑูุฑ ุงููุนููุงุช ุงูุชุงููุฉ ุฅูู [`Trainer`]:

1. ุณุชุจุฏุฃ ุจู [`PreTrainedModel`] ุฃู [`torch.nn.Module`]:

```py
>>> from transformers import AutoModelForSequenceClassification

>>> model = AutoModelForSequenceClassification.from_pretrained("distilbert/distilbert-base-uncased")
```

2. ุชุญุชูู [`TrainingArguments`] ุนูู ูุฑุท ูุนููุงุช ุงููููุฐุฌ ุงูุชู ููููู ุชุบููุฑูุง ูุซู ูุนุฏู ุงูุชุนูู ูุญุฌู ุงูุฏูุนุฉ ูุนุฏุฏ ุงูุนุตูุฑ ุงูุชู ูุฌุจ ุงูุชุฏุฑูุจ ุนูููุง. ูุชู ุงุณุชุฎุฏุงู ุงูููู ุงูุงูุชุฑุงุถูุฉ ุฅุฐุง ูู ุชุญุฏุฏ ุฃู ุญุฌุฌ ุชุฏุฑูุจ:

```py
>>> from transformers import TrainingArguments

>>> training_args = TrainingArguments(
...     output_dir="path/to/save/folder/",
...     learning_rate=2e-5,
...     per_device_train_batch_size=8,
...     per_device_eval_batch_size=8,
...     num_train_epochs=2,
... )
```

3. ูู ุจุชุญููู ูุฆุฉ ูุง ูุจู ุงููุนุงูุฌุฉ ูุซู tokenizerุ ุฃู ูุนุงูุฌ ุงูุตูุฑุ ุฃู ูุณุชุฎุฑุฌ ุงูููุฒุงุชุ ุฃู ุงููุนุงูุฌ:

```py
>>> from transformers import AutoTokenizer

>>> tokenizer = AutoTokenizer.from_pretrained("distilbert/distilbert-base-uncased")
```

4. ุชุญููู ูุฌููุนุฉ ุจูุงูุงุช:

```py
>>> from datasets import load_dataset

>>> dataset = load_dataset("rotten_tomatoes")
```

5. ูู ุจุฅูุดุงุก ุฏุงูุฉ ูุชุญููู ูุฌููุนุฉ ุงูุจูุงูุงุช ุฅูู ุฑููุฒ:

```py
>>> def tokenize_dataset(dataset):
...     return tokenizer(dataset["text"])
```

ุซู ูู ุจุชุทุจููู ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุจุฃููููุง ูุน [`~ datasets.Dataset.map`]:

```py
>>> dataset = dataset.map(tokenize_dataset, batched=True)
```

6. [`DataCollatorWithPadding`] ูุฅูุดุงุก ุฏูุนุฉ ูู ุงูุฃูุซูุฉ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจู:

```py
>>> from transformers import DataCollatorWithPadding

>>> data_collator = DataCollatorWithPadding(tokenizer=tokenizer)
```

ุงูุขู ูู ุจุชุฌููุน ุฌููุน ูุฐู ุงููุฆุงุช ูู [`Trainer`]:

```py
>>> from transformers import Trainer

>>> trainer = Trainer(
...     model=model,
...     args=training_args,
...     train_dataset=dataset["train"],
...     eval_dataset=dataset["test"],
...     tokenizer=tokenizer,
...     data_collator=data_collator,
... )
```

ุนูุฏูุง ุชููู ูุณุชุนุฏูุงุ ุงุชุตู ุจู [`~ Trainer.train`] ูุจุฏุก ุงูุชุฏุฑูุจ:

```py
>>> trainer.train()
```

<Tip>
ุจุงููุณุจุฉ ููููุงู - ูุซู ุงูุชุฑุฌูุฉ ุฃู ุงูุชูุฎูุต - ุงูุชู ุชุณุชุฎุฏู ูููุฐุฌ ุชุณูุณู ุฅูู ุชุณูุณูุ ุงุณุชุฎุฏู ูุฆุงุช [`Seq2SeqTrainer`] ู [`Seq2SeqTrainingArguments`] ุจุฏูุงู ูู ุฐูู.
</Tip>

ููููู ุชุฎุตูุต ุณููู ุญููุฉ ุงูุชุฏุฑูุจ ุนู ุทุฑูู ุฅูุดุงุก ูุฆุฉ ูุฑุนูุฉ ูู ุงูุทุฑู ุฏุงุฎู [`Trainer`]. ูุณูุญ ูู ุฐูู ุจุชุฎุตูุต ููุฒุงุช ูุซู ุฏุงูุฉ ุงูุฎุณุงุฑุฉ ูุงูููุญููููู ูุงูุฌุฏูู ุงูุฒููู. ุงูู ูุธุฑุฉ ุนูู ุงููุฑุฌุน [`Trainer`] ููุทุฑู ุงูุชู ูููู ุฅูุดุงุก ูุฆุงุช ูุฑุนูุฉ ูููุง.

ูุงูุทุฑููุฉ ุงูุฃุฎุฑู ูุชุฎุตูุต ุญููุฉ ุงูุชุฏุฑูุจ ูู ุจุงุณุชุฎุฏุงู [ุงููุณุชุฏุนูุงุช]. ููููู ุงุณุชุฎุฏุงู ุงููุณุชุฏุนูุงุช ููุชูุงูู ูุน ููุชุจุงุช ุฃุฎุฑู ููุญุต ุญููุฉ ุงูุชุฏุฑูุจ ููุฅุจูุงุบ ุนู ุงูุชูุฏู ุงููุญุฑุฒ ุฃู ุฅููุงู ุงูุชุฏุฑูุจ ูุจูุฑูุง. ูุง ุชุนุฏู ุงููุณุชุฏุนูุงุช ุฃู ุดูุก ูู ุญููุฉ ุงูุชุฏุฑูุจ ููุณูุง. ูุชุฎุตูุต ุดูุก ูุซู ุฏุงูุฉ ุงูุฎุณุงุฑุฉุ ุชุญุชุงุฌ ุฅูู ุฅูุดุงุก ูุฆุฉ ูุฑุนูุฉ ูู [`Trainer`] ุจุฏูุงู ูู ุฐูู.

## ุชุฏุฑูุจ ูุน TensorFlow
ุฌููุน ุงูููุงุฐุฌ ูู [`tf.keras.Model`] ููุงุณูุ ูุฐุง ูููู ุชุฏุฑูุจูุง ูู TensorFlow ุจุงุณุชุฎุฏุงู ูุงุฌูุฉ ุจุฑูุฌุฉ ุชุทุจููุงุช Keras. ูููุฑ ๐ค Transformers ุทุฑููุฉ [`~ TFPreTrainedModel.prepare_tf_dataset`] ูุชุญููู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจู ุจุณูููุฉ ูู `tf.data.Dataset` ุญุชู ุชุชููู ูู ุงูุจุฏุก ูู ุงูุชุฏุฑูุจ ุนูู ุงูููุฑ ุจุงุณุชุฎุฏุงู ุทุฑู `compile` ู`fit` ูู Keras.

1. ุณุชุจุฏุฃ ุจู [`TFPreTrainedModel`] ุฃู [`tf.keras.Model`]:

```py
>>> from transformers import TFAutoModelForSequenceClassification

>>> model = TFAutoModelForSequenceClassification.from_pretrained("distilbert/distilbert-base-uncased")
```

2. ูู ุจุชุญููู ูุฆุฉ ูุง ูุจู ุงููุนุงูุฌุฉ ูุซู tokenizerุ ุฃู ูุนุงูุฌ ุงูุตูุฑุ ุฃู ูุณุชุฎุฑุฌ ุงูููุฒุงุชุ ุฃู ุงููุนุงูุฌ:

```py
>>> from transformers import AutoTokenizer

>>> tokenizer = AutoTokenizer.from_pretrained("distilbert/distilbert-base-uncased")
```

3. ูู ุจุฅูุดุงุก ุฏุงูุฉ ูุชุญููู ูุฌููุนุฉ ุงูุจูุงูุงุช ุฅูู ุฑููุฒ:

```py
>>> def tokenize_dataset(dataset):
...     return tokenizer(dataset["text"])
```

4. ูู ุจุชุทุจูู tokenizer ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุจุฃููููุง ูุน [`~ datasets.Dataset.map`] ุซู ูู ุจุชูุฑูุฑ ูุฌููุนุฉ ุงูุจูุงูุงุช ู tokenizer ุฅูู [`~ TFPreTrainedModel.prepare_tf_dataset`]. ููููู ุฃูุถูุง ุชุบููุฑ ุญุฌู ุงูุฏูุนุฉ ูุฎูุท ูุฌููุนุฉ ุงูุจูุงูุงุช ููุง ุฅุฐุง ุฃุฑุฏุช:

```py
>>> dataset = dataset.map(tokenize_dataset)
>>> tf_dataset = model.prepare_tf_dataset(
...     dataset["train"], batch_size=16, shuffle=True, tokenizer=tokenizer
... )
```

5. ุนูุฏูุง ุชููู ูุณุชุนุฏูุงุ ููููู ุงุณุชุฏุนุงุก `compile` ู`fit` ูุจุฏุก ุงูุชุฏุฑูุจ. ูุงุญุธ ุฃู ููุงุฐุฌ Transformers ุชุญุชูู ุฌููุนูุง ุนูู ุฏุงูุฉ ุฎุณุงุฑุฉ ุฐุงุช ุตูุฉ ุจุงููููุฉ ุจุดูู ุงูุชุฑุงุถูุ ูุฐุง ูุฃูุช ูุณุช ุจุญุงุฌุฉ ุฅูู ุชุญุฏูุฏ ูุงุญุฏุฉ ูุง ูู ุชุฑุบุจ ูู ุฐูู:

```py
>>> from tensorflow.keras.optimizers import Adam

>>> model.compile(optimizer='adam') # ูุง ุชูุฌุฏ ุญุฌุฉ ุงูุฎุณุงุฑุฉ!
>>> model.fit(tf_dataset)
```

## ูุงุฐุง ุจุนุฏุ
ุงูุขู ุจุนุฏ ุฃู ุฃูููุช ุงูุฌููุฉ ุงูุณุฑูุนุฉ ูู ๐ค Transformersุ ุงุทูุน ุนูู ุฃุฏูุฉูุง ูุชุนุฑู ุนูู ููููุฉ ุงูููุงู ุจุฃุดูุงุก ุฃูุซุฑ ุชุญุฏูุฏูุง ูุซู ูุชุงุจุฉ ูููุฐุฌ ูุฎุตุตุ ูุชูููุญ ูููุฐุฌ ููููุฉุ ูููููุฉ ุชุฏุฑูุจ ูููุฐุฌ ุจุงุณุชุฎุฏุงู ูุต ุจุฑูุฌู. ุฅุฐุง ููุช ููุชููุง ุจูุนุฑูุฉ ุงููุฒูุฏ ุนู ุงูููุงููู ุงูุฃุณุงุณูุฉ ูู ๐ค Transformersุ ูุงุญุตู ุนูู ููุฌุงู ูู ุงููููุฉ ูุฎุฐ ูุธุฑุฉ ุนูู ุฃุฏูุฉูุง ุงูููุงููููุฉ!