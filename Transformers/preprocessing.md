# ูุนุงูุฌุฉ ูุณุจูุฉ

ูุจู ุฃู ุชุชููู ูู ุชุฏุฑูุจ ูููุฐุฌ ุนูู ูุฌููุนุฉ ุจูุงูุงุชุ ูุฌุจ ูุนุงูุฌุชูุง ูุณุจููุง ุฅูู ุชูุณูู ุฅุฏุฎุงู ุงููููุฐุฌ ุงููุชููุน. ุณูุงุก ูุงูุช ุจูุงูุงุชู ูุตูุฉ ุฃู ุตูุฑูุง ุฃู ุตูุชุ ููุฌุจ ุชุญููููุง ุฅูู ุชูุณูุฑุงุช ูุชุฌููุนูุง ูู ุฏูุนุงุช. ุชููุฑ ููุชุจุฉ ๐ค Transformers ูุฌููุนุฉ ูู ูุฆุงุช ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ูููุณุงุนุฏุฉ ูู ุฅุนุฏุงุฏ ุจูุงูุงุชู ูููููุฐุฌ. ูู ูุฐุง ุงูุจุฑูุงูุฌ ุงูุชุนููููุ ุณุชุชุนูู ุฃูู:

* ูููุตุ ุงุณุชุฎุฏู [ุฑุงุณู ุงูุฃุญุฑู](./main_classes/tokenizer) ูุชุญููู ุงููุต ุฅูู ุชุณูุณู ูู ุงูุฑููุฒุ ูุฅูุดุงุก ุชูุซูู ุฑููู ููุฑููุฒุ ูุชุฌููุนูุง ูู ุชูุณูุฑุงุช.
* ููููุงู ูุงูุตูุชุ ุงุณุชุฎุฏู [ูุณุชุฎุฑุฌ ุงูููุฒุงุช](./main_classes/feature_extractor) ูุงุณุชุฎุฑุงุฌ ููุฒุงุช ูุชุณูุณูุฉ ูู ุฃุดูุงู ููุฌุงุช ุงูุตูุช ูุชุญููููุง ุฅูู ุชูุณูุฑุงุช.
* ุชุณุชุฎุฏู ุฅุฏุฎุงูุงุช ุงูุตูุฑุฉ [ูุนุงูุฌ ุงูุตูุฑ](./main_classes/image_processor) ูุชุญููู ุงูุตูุฑ ุฅูู ุชูุณูุฑุงุช.
* ููุฅุฏุฎุงูุงุช ูุชุนุฏุฏุฉ ุงููุณุงุฆุทุ ุงุณุชุฎุฏู [ูุนุงูุฌ](./main_classes/processors) ูุฏูุฌ ุฑุงุณู ุฃุญุฑู ููุณุชุฎุฑุฌ ููุฒุงุช ุฃู ูุนุงูุฌ ุตูุฑ.

> ุชุฐูุฑ ุฃู `AutoProcessor` **ูุนูู ุฏุงุฆููุง** ููุฎุชุงุฑ ุชููุงุฆููุง ุงููุฆุฉ ุงูุตุญูุญุฉ ูููููุฐุฌ ุงูุฐู ุชุณุชุฎุฏููุ ุณูุงุก ููุช ุชุณุชุฎุฏู ุฑุงุณู ุฃุญุฑู ุฃู ูุนุงูุฌ ุตูุฑ ุฃู ูุณุชุฎุฑุฌ ููุฒุงุช ุฃู ูุนุงูุฌ.

ูุจู ุงูุจุฏุกุ ูู ุจุชุซุจูุช ๐ค Datasets ุญุชู ุชุชููู ูู ุชุญููู ุจุนุถ ูุฌููุนุงุช ุงูุจูุงูุงุช ูุชุฌุฑุจุชูุง:

```bash
pip install datasets
```

## ูุนุงูุฌุฉ ุงููุบุงุช ุงูุทุจูุนูุฉ

<Youtube id="Yffk5aydLzg"/>

ุฃุฏุงุฉ ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ุงูุฑุฆูุณูุฉ ููุจูุงูุงุช ุงููุตูุฉ ูู [ุฑุงุณู ุงูุฃุญุฑู](main_classes/tokenizer). ููุณู ุฑุงุณู ุงูุฃุญุฑู ุงููุต ุฅูู *ุฑููุฒ* ููููุง ููุฌููุนุฉ ูู ุงูููุงุนุฏ. ูุชู ุชุญููู ุงูุฑููุฒ ุฅูู ุฃุฑูุงู ุซู ุฅูู ุชูุณูุฑุงุชุ ูุงูุชู ุชุตุจุญ ุฅุฏุฎุงูุงุช ุงููููุฐุฌ. ููุถูู ุฑุงุณู ุงูุฃุญุฑู ุฃู ุฅุฏุฎุงูุงุช ุฅุถุงููุฉ ูุทููุจุฉ ูู ูุจู ุงููููุฐุฌ.

> ุฅุฐุง ููุช ุชุฎุทุท ูุงุณุชุฎุฏุงู ูููุฐุฌ ููุฏุฑุจ ูุณุจููุงุ ููู ุงูููู ุงุณุชุฎุฏุงู ุฑุงุณู ุงูุฃุญุฑู ุงูููุฏุฑุจ ูุณุจููุง ุงูููุชุฑู ุจู. ูุถูู ุฐูู ุชูุณูู ุงููุต ุจููุณ ุทุฑููุฉ ูุฌููุนุฉ ุจูุงูุงุช ุงูุชุฏุฑูุจุ ูุงุณุชุฎุฏุงู ููุณ ุงูุฑููุฒ ุงูููุงุจูุฉ ููููุฑุณ (ููุดุงุฑ ุฅูููุง ุนุงุฏุฉู ุจุงุณู *ูุนุฌู*) ุฃุซูุงุก ุงูุชุฏุฑูุจ ุงููุณุจู.

ุงุจุฏุฃ ุจุชุญููู ุฑุงุณู ุฃุญุฑู ููุฏุฑุจ ูุณุจููุง ุจุงุณุชุฎุฏุงู ุทุฑููุฉ [`AutoTokenizer.from_pretrained`]. ูููู ูุฐุง ุงูุฃุณููุจ ุจุชูุฒูู *ูุนุฌู* ุงูุฐู ุชู ุชุฏุฑูุจ ุงููููุฐุฌ ุนููู:

```py
>>> from transformers import AutoTokenizer

>>> tokenizer = AutoTokenizer.from_pretrained("google-bert/bert-base-cased")
```

ุซู ูุฑุฑ ุงููุต ุฅูู ุฑุงุณู ุงูุฃุญุฑู:

```py
>>> encoded_input = tokenizer("Do not meddle in the affairs of wizards, for they are subtle and quick to anger.")
>>> print(encoded_input)
{'input_ids': [101, 2079, 2025, 19960, 10362, 1999, 1996, 3821, 1997, 16657, 1010, 2005, 2027, 2024, 11259, 1998, 4248, 2000, 4963, 1012, 102],
'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
```

ูุนูุฏ ุฑุงุณู ุงูุฃุญุฑู ูุงููุณูุง ูุญุชูู ุนูู ุซูุงุซุฉ ุนูุงุตุฑ ูููุฉ:

* [input_ids](glossary#input-ids) ูู ุงูููุงุฑุณ ุงูููุงุจูุฉ ููู ุฑูุฒ ูู ุงูุฌููุฉ.
* [attention_mask](glossary#attention-mask) ูุดูุฑ ุฅูู ูุง ุฅุฐุง ูุงู ูุฌุจ ุงูุงูุชูุงู ุจุงูุฑูุฒ ุฃู ูุง.
* [token_type_ids](glossary#token-type-ids) ูุญุฏุฏ ุงูุชุณูุณู ุงูุฐู ููุชูู ุฅููู ุงูุฑูุฒ ุนูุฏูุง ูููู ููุงู ุฃูุซุฑ ูู ุชุณูุณู ูุงุญุฏ.

ุฃุนุฏ ุฅุฏุฎุงูู ุนู ุทุฑูู ูู ุชุฑููุฒ `input_ids`:

```py
>>> tokenizer.decode(encoded_input["input_ids"])
'[CLS] Do not meddle in the affairs of wizards, for they are subtle and quick to anger. [SEP]'
```

ููุง ุชุฑูุ ุฃุถุงู ุฑุงุณู ุงูุฃุญุฑู ุฑูุฒูู ุฎุงุตูู - `CLS` ู`SEP` (ูุตูู ููุงุตู) - ุฅูู ุงูุฌููุฉ. ูุง ุชุญุชุงุฌ ุฌููุน ุงูููุงุฐุฌ ุฅูู ุฑููุฒ ุฎุงุตุฉุ ูููู ุฅุฐุง ูุงูุช ูุฐููุ ูุฅู ุฑุงุณู ุงูุฃุญุฑู ูุถูููุง ุชููุงุฆููุง ูู.

ุฅุฐุง ูุงู ููุงู ุนุฏุฉ ุฌูู ุชุฑูุฏ ูุนุงูุฌุชูุง ูุณุจููุงุ ููู ุจุชูุฑูุฑูุง ููุงุฆูุฉ ุฅูู ุฑุงุณู ุงูุฃุญุฑู:

```py
>>> batch_sentences = [
...     "But what about second breakfast?",
...     "Don't think he knows about second breakfast, Pip.",
...     "What about elevensies?",
... ]
>>> encoded_inputs = tokenizer(batch_sentences)
>>> print(encoded_inputs)
{'input_ids': [[101, 1252, 1184, 1164, 1248, 6462, 136, 102],
[101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102],
[101, 1327, 1164, 5450, 23434, 136, 102]],
'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0],
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
[0, 0, 0, 0, 0, 0, 0]],
'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1],
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
[1, 1, 1, 1, 1, 1, 1]]}
```

### ุงูุญุดู

ููุณุช ุงูุฌูู ุฏุงุฆููุง ุจููุณ ุงูุทููุ ูุงูุฐู ูููู ุฃู ูููู ูุดููุฉ ูุฃู ุงูุชูุณูุฑุงุชุ ุฅุฏุฎุงูุงุช ุงููููุฐุฌุ ูุฌุจ ุฃู ูููู ููุง ุดูู ููุญุฏ. ุงูุญุดู ูู ุงุณุชุฑุงุชูุฌูุฉ ูุถูุงู ุฃู ุชููู ุงูุชูุณูุฑุงุช ูุณุชุทููุฉ ุนู ุทุฑูู ุฅุถุงูุฉ ุฑูุฒ *ุญุดู* ุฎุงุต ุฅูู ุงูุฌูู ุงูุฃูุตุฑ.

ูู ุจุชุนููู ูุนููุฉ `padding` ุฅูู `True` ูุญุดู ุงูุฌูู ุงูุฃูุตุฑ ูู ุงูุฏูุนุฉ ููุทุงุจูุฉ ุฃุทูู ุชุณูุณู:

```py
>>> batch_sentences = [
...     "But what about second breakfast?",
...     "Don't think he knows about second breakfast, Pip.",
...     "What about elevensies?",
... ]
>>> encoded_input = tokenizer(batch_sentences, padding=True)
>>> print(encoded_input)
{'input_ids': [[101, 1252, 1184, 1164, 1248, 6462, 136, 102, 0, 0, 0, 0, 0, 0, 0],
[101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102],
[101, 1327, 1164, 5450, 23434, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0]],
'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],
'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]]}
```

ุชู ุญุดู ุงูุฌููุชูู ุงูุฃููู ูุงูุซุงูุซุฉ ุงูุขู ุจู `0` ูุฃููุง ุฃูุตุฑ.

### ุงูุจุชุฑ

ูู ูุงุญูุฉ ุฃุฎุฑูุ ูุฏ ูููู ุงูุชุณูุณู ุทููููุง ุฌุฏูุง ุจุงููุณุจุฉ ูููููุฐุฌ ููุชุนุงูู ูุนู. ูู ูุฐู ุงูุญุงูุฉุ ุณุชุญุชุงุฌ ุฅูู ุจุชุฑ ุงูุชุณูุณู ุฅูู ุทูู ุฃูุตุฑ.

ูู ุจุชุนููู ูุนููุฉ `truncation` ุฅูู `True` ูุจุชุฑ ุชุณูุณู ุฅูู ุงูุทูู ุงูุฃูุตู ุงูุฐู ููุจูู ุงููููุฐุฌ:

```py
>>> batch_sentences = [
...     "But what about second breakfast?",
...     "Don't think he knows about second breakfast, Pip.",
...     "What about elevensies?",
... ]
>>> encoded_input = tokenizer(batch_sentences, padding=True, truncation=True)
>>> print(encoded_input)
{'input_ids': [[101, 1252, 1184, 1164, 1248, 6462, 136, 102, 0, 0, 0, 0, 0, 0, 0],
[101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102],
[101, 1327, 1164, 5450, 23434, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0]],
'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],
'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
[1, 1, Multiplier, 1, 1, 1, 1, 0ุ 0ุ 0ุ 0ุ 0ุ 0ุ 0ุ 0]]}
```

> ุชุญูู ูู ุฏููู ุงูููุงููู [ุงูุญุดู ูุงูุจุชุฑ](./pad_truncation) ููุนุฑูุฉ ุงููุฒูุฏ ุญูู ุญุฌุฉ ุงูุญุดู ูุงูุจุชุฑ ุงููุฎุชููุฉ.
## ุฅูุดุงุก ุงูููุณูุฌุงุช

ุฃุฎูุฑูุงุ ุชุฑูุฏ ุฃู ูููู ุงููุญูู ุงููุบูู ุจุฅุฑุฌุงุน ุงูููุณูุฌุงุช ุงููุนููุฉ ุงูุชู ูุชู ุชุบุฐูุชูุง ุฅูู ุงููููุฐุฌ.

ูู ุจุชุนููู ูุนููุฉ "return_tensors" ุฅูุง ุฅูู "pt" ูู PyTorchุ ุฃู "tf" ูู TensorFlow:

<Tip>
ุชุฏุนู ุงูุฃูุงุจูุจ ุงููุฎุชููุฉ ุญุฌุฉ ุงููุญูู ุงููุบูู ูู "__call__()" ุจุดูู ูุฎุชูู. ุชุฏุนู ุฃูุงุจูุจ "text-2-text-generation" (ุฃู ุชูุฑูุฑ) ููุท "truncation". ุชุฏุนู ุฃูุงุจูุจ "text-generation" "max_length" ู "truncation" ู "padding" ู "add_special_tokens".
ูู ุฃูุงุจูุจ "fill-mask"ุ ูููู ุชูุฑูุฑ ุญุฌุฉ ุงููุญูู ุงููุบูู ูู ุงูุญุฌุฉ "tokenizer_kwargs" (ูุงููุณ).
</Tip>

## ุงูุตูุช

ุจุงููุณุจุฉ ููููุงู ุงูุตูุชูุฉุ ุณุชุญุชุงุฌ ุฅูู [ูุณุชุฎุฑุฌ ุงูููุฒุงุช](main_classes/feature_extractor) ูุฅุนุฏุงุฏ ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจู ูููููุฐุฌ. ุชู ุชุตููู ูุณุชุฎุฑุฌ ุงูููุฒุงุช ูุงุณุชุฎุฑุงุฌ ุงูููุฒุงุช ูู ุงูุจูุงูุงุช ุงูุตูุชูุฉ ุงูุฎุงูุ ูุชุญููููุง ุฅูู ููุณูุฌุงุช.

ูู ุจุชุญููู ูุฌููุนุฉ ุจูุงูุงุช [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) (ุฑุงุฌุน ุงูุจุฑูุงูุฌ ุงูุชุนูููู ูู ๐ค [Datasets](https://huggingface.co/docs/datasets/load_hub) ููุญุตูู ุนูู ูุฒูุฏ ูู ุงูุชูุงุตูู ุญูู ููููุฉ ุชุญููู ูุฌููุนุฉ ุจูุงูุงุช) ููุนุฑูุฉ ููููุฉ ุงุณุชุฎุฏุงู ูุณุชุฎุฑุฌ ุงูููุฒุงุช ูุน ูุฌููุนุงุช ุงูุจูุงูุงุช ุงูุตูุชูุฉ:

```py
>>> from datasets import load_dataset, Audio

>>> dataset = load_dataset("PolyAI/minds14", name="en-US", split="train")
```

ูู ุจุงููุตูู ุฅูู ุงูุนูุตุฑ ุงูุฃูู ูู ุนููุฏ "audio" ููุนุฑูุฉ ุงููุฏุฎูุงุช. ูุคุฏู ุงุณุชุฏุนุงุก ุนููุฏ "audio" ุชููุงุฆููุง ุฅูู ุชุญููู ููู ุงูุตูุช ูุฅุนุงุฏุฉ ุฃุฎุฐ ุงูุนููุงุช ููู:

```py
>>> dataset[0]["audio"]
{'array': array([ 0.        ,  0.00024414, -0.00024414, ..., -0.00024414,
0.        ,  0.        ], dtype=float32),
'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav',
'sampling_rate': 8000}
```

ูุนูุฏ ูุฐุง ุซูุงุซุฉ ุนูุงุตุฑ:

* `array` ูู ุฅุดุงุฑุฉ ุงูููุงู ุงููุญููุฉ - ูุงูุชู ุชู ุฅุนุงุฏุฉ ุฃุฎุฐ ุนููุงุช ูููุง - ูุตููู ุฃุญุงุฏู ุงูุจุนุฏ.
* `path` ูุดูุฑ ุฅูู ูููุน ููู ุงูุตูุช.
* ูุดูุฑ `sampling_rate` ุฅูู ุนุฏุฏ ููุงุท ุงูุจูุงูุงุช ูู ุฅุดุงุฑุฉ ุงูููุงู ุงูุชู ูุชู ููุงุณูุง ูู ุงูุซุงููุฉ.

ุจุงููุณุจุฉ ููุฐุง ุงูุจุฑูุงูุฌ ุงูุชุนููููุ ุณุชุณุชุฎุฏู ูููุฐุฌ [Wav2Vec2](https://huggingface.co/facebook/wav2vec2-base). ุงูู ูุธุฑุฉ ุนูู ุจุทุงูุฉ ุงููููุฐุฌุ ูุณุชุชุนูู ุฃู Wav2Vec2 ููุฏุฑุจ ูุณุจููุง ุนูู ุงูููุงู ุงูุตูุชู ุงูุฐู ุชู ุฃุฎุฐ ุนููุงุช ููู ุจูุนุฏู 16 ูููู ูุฑุชุฒ. ูู ุงูููู ุฃู ุชุชุทุงุจู ูุนุฏู ุงูุนููุงุช ูู ุจูุงูุงุช ุงูุตูุช ูุน ูุนุฏู ุงูุนููุงุช ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงููุณุชุฎุฏูุฉ ูุชุฏุฑูุจ ุงููููุฐุฌ ูุณุจููุง. ุฅุฐุง ูู ููู ูุนุฏู ุงูุนููุงุช ุงูุฎุงุต ุจุจูุงูุงุชู ูู ููุณูุ ููุฌุจ ุนููู ุฅุนุงุฏุฉ ุฃุฎุฐ ุนููุงุช ูู ุจูุงูุงุชู.

1. ุงุณุชุฎุฏู ุทุฑููุฉ ["~datasets.Dataset.cast_column"] ูู ๐ค Datasets ูุฅุนุงุฏุฉ ุฃุฎุฐ ุงูุนููุงุช ูู ูุนุฏู ุงูุนููุงุช ุฅูู 16 ูููู ูุฑุชุฒ:

```py
>>> dataset = dataset.cast_column("audio", Audio(sampling_rate=16_000))
```

2. ุงุณุชุฏุนุงุก ุนููุฏ "audio" ูุฑุฉ ุฃุฎุฑู ูุฅุนุงุฏุฉ ุฃุฎุฐ ุนููุงุช ูู ููู ุงูุตูุช:

```py
>>> dataset[0]["audio"]
{'array': array([ 2.3443763e-05,  2.1729663e-04,  2.2145823e-04, ...,
3.8356509e-05, -7.3497440e-06, -2.1754686e-05], dtype=float32),
'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav',
'sampling_rate': 1600Multiplier: 16000,
'bits_per_sample': 32,
'format': 'wav',
'subtype': 'PCM_SIGNED'}
```

ุจุนุฏ ุฐููุ ูู ุจุชุญููู ูุณุชุฎุฑุฌ ุงูููุฒุงุช ูุชุทุจูุน ูุฅุถุงูุฉ ูุณุงุฆุฏ ุงููุฏุฎูุงุช. ุนูุฏ ุฅุถุงูุฉ ูุณุงุฆุฏ ุฅูู ุงูุจูุงูุงุช ุงููุตูุฉุ ุชุชู ุฅุถุงูุฉ "0" ููุชุณูุณูุงุช ุงูุฃูุตุฑ. ุชูุทุจู ููุณ ุงูููุฑุฉ ุนูู ุงูุจูุงูุงุช ุงูุตูุชูุฉ. ูุถูู ูุณุชุฎุฑุฌ ุงูููุฒุงุช "0" - ุงูุฐู ูุชู ุชูุณูุฑู ุนูู ุฃูู ุตูุช - ุฅูู "array".

ูู ุจุชุญููู ูุณุชุฎุฑุฌ ุงูููุฒุงุช ุจุงุณุชุฎุฏุงู ["AutoFeatureExtractor.from_pretrained"]:

```py
>>> from transformers import AutoFeatureExtractor

>>> feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base")
```

ูุฑุฑ ุตููู "audio" ุฅูู ูุณุชุฎุฑุฌ ุงูููุฒุงุช. ููุง ููุตู ุจุฅุถุงูุฉ ุญุฌุฉ "sampling_rate" ูู ูุณุชุฎุฑุฌ ุงูููุฒุงุช ูู ุฃุฌู ุชุตุญูุญ ุงูุฃุฎุทุงุก ุงูุตุงูุชุฉ ุงูุชู ูุฏ ุชุญุฏุซ ุจุดูู ุฃูุถู.

```py
>>> audio_input = [dataset[0]["audio"]["array"]]
>>> feature_extractor(audio_input, sampling_rate=16000)
{'input_values': [array([ 3.8106556e-04,  2.7506407e-03,  2.8015103e-03, ...,
5.6335266e-04,  4.6588284e-06, -1.7142107e-04], dtype=float32)]}
```

ููุซู ุงููุญูู ุงููุบููุ ููููู ุชุทุจูู ุงููุณุงุฆุฏ ุฃู ุงูุงูุชุทุงุน ููุชุนุงูู ูุน ุงูุชุณูุณูุงุช ุงููุชุบูุฑุฉ ูู ุฏูุนุฉ. ุงูู ูุธุฑุฉ ุนูู ุทูู ุงูุชุณูุณู ููุงุชูู ุงูุนููุชูู ุงูุตูุชูุชูู:

```py
>>> dataset[0]["audio"]["array"].shape
(173398,)

>>> dataset[1]["audio"]["array"].shape
(106496,)
```

ูู ุจุฅูุดุงุก ุฏุงูุฉ ููุนุงูุฌุฉ ูุฌููุนุฉ ุงูุจูุงูุงุช ุจุญูุซ ุชููู ุนููุงุช ุงูุตูุช ุจููุณ ุงูุฃุทูุงู. ุญุฏุฏ ุทูู ุนููุฉ ูุตููุ ูุณูููู ูุณุชุฎุฑุฌ ุงูููุฒุงุช ุฅูุง ุจุฅุถุงูุฉ ูุณุงุฆุฏ ุฃู ุงูุชุทุงุน ุงูุชุณูุณูุงุช ููุทุงุจูุชูุง:

```py
>>> def preprocess_function(examples):
...     audio_arrays = [x["array"] for x in examples["audio"]]
...     inputs = feature_extractor(
...         audio_arrays,
...         sampling_rate=16000,
...         padding=True,
...         max_length=100000,
...         truncation=True,
...     )
...     return inputs
```

ูู ุจุชุทุจูู `preprocess_function` ุนูู ุฃูู ุจุถุน ุฃูุซูุฉ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช:

```py
>>> processed_dataset = preprocess_function(dataset[:5])
```

ุฃุทูุงู ุงูุนููุงุช ุงูุขู ูุชุทุงุจูุฉ ูุชุทุงุจู ุงูุทูู ุงูุฃูุตู ุงููุญุฏุฏ. ููููู ุงูุขู ุชูุฑูุฑ ูุฌููุนุฉ ุงูุจูุงูุงุช ุงููุนุงูุฌุฉ ุฅูู ุงููููุฐุฌ!

```py
>>> processed_dataset["input_values"][0].shape
(100000,)

>>> processed_dataset["input_values"][1].shape
(100000,)
```
## ุฑุคูุฉ ุงูููุจููุชุฑ

ุจุงููุณุจุฉ ูููุงู ุฑุคูุฉ ุงูููุจููุชุฑุ ุณุชุญุชุงุฌ ุฅูู ูุนุงูุฌ ุตูุฑ ูุชุญุถูุฑ ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจู ููููุฐุฌุฉ. ุชุชููู ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ููุตูุฑ ูู ุนุฏุฉ ุฎุทูุงุช ูุชุญููู ุงูุตูุฑ ุฅูู ุงููุฏุฎูุงุช ุงููุชููุนุฉ ูู ุงููููุฐุฌ. ูุชุดูู ูุฐู ุงูุฎุทูุงุชุ ุนูู ุณุจูู ุงููุซุงู ูุง ุงูุญุตุฑุ ุชุบููุฑ ุงูุญุฌูุ ูุงูุชุทุจูุนุ ูุชุตุญูุญ ููุงุฉ ุงูุฃููุงูุ ูุชุญููู ุงูุตูุฑ ุฅูู ุชูุณูุฑุงุช.

ุบุงูุจูุง ูุง ุชุชุจุน ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ููุตูุฑ ุจุนุถ ุฃุดูุงู ุฒูุงุฏุฉ ุงูุตูุฑ. ูู ูู ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ููุตูุฑ ูุฒูุงุฏุฉ ุงูุตูุฑ ุชุญููู ุจูุงูุงุช ุงูุตูุฑุ ูููููุง ุชุฎุฏู ุฃุบุฑุงุถูุง ูุฎุชููุฉ:

- ุชุบููุฑ ุงูุตูุฑุฉ: ูุนุฏู ุงูุตูุฑ ุจุทุฑููุฉ ูููู ุฃู ุชุณุงุนุฏ ูู ููุน ุงูุฅูุฑุงุท ูู ุงูุชุฌููุฒ ูุฒูุงุฏุฉ ูุชุงูุฉ ุงููููุฐุฌ. ููููู ุฃู ุชููู ูุจุฏุนูุง ูู ููููุฉ ุฒูุงุฏุฉ ุจูุงูุงุชู - ุถุจุท ุงูุณุทูุน ูุงูุฃููุงูุ ูุงููุญุงุตููุ ูุงูุฏูุฑุงูุ ุชุบููุฑ ุงูุญุฌูุ ุงูุชูุจูุฑุ ููุง ุฅูู ุฐูู. ููุน ุฐููุ ูู ุญุฐุฑูุง ูู ุนุฏู ุชุบููุฑ ูุนูู ุงูุตูุฑ ุจุงุณุชุฎุฏุงู ุงูุฒูุงุฏุงุช ุงูุฎุงุตุฉ ุจู.

- ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ููุตูุฑ: ุชุถูู ุฃู ุงูุตูุฑ ุชุชุทุงุจู ูุน ุชูุณูู ุงูุฅุฏุฎุงู ุงููุชููุน ูู ุงููููุฐุฌ. ุนูุฏ ุถุจุท ูููุฐุฌ ุฑุคูุฉ ุงูููุจููุชุฑ ุจุฏูุฉุ ูุฌุจ ูุนุงูุฌุฉ ุงูุตูุฑ ุจุงูุถุจุท ููุง ุชู ุชุฏุฑูุจ ุงููููุฐุฌ ูู ุงูุจุฏุงูุฉ.

ููููู ุงุณุชุฎุฏุงู ุฃู ููุชุจุฉ ุชุฑูุฏูุง ูุฒูุงุฏุฉ ุงูุตูุฑ. ุจุงููุณุจุฉ ูููุนุงูุฌุฉ ุงููุณุจูุฉ ููุตูุฑุ ุงุณุชุฎุฏู `ImageProcessor` ุงููุฑุชุจุท ุจุงููููุฐุฌ.

ูู ุจุชุญููู ูุฌููุนุฉ ุจูุงูุงุช `food101` (ุฑุงุฌุน ุชุนูููุงุช `Datasets` ููุญุตูู ุนูู ูุฒูุฏ ูู ุงูุชูุงุตูู ุญูู ููููุฉ ุชุญููู ูุฌููุนุฉ ุจูุงูุงุช) ููุนุฑูุฉ ููู ููููู ุงุณุชุฎุฏุงู ูุนุงูุฌ ุงูุตูุฑ ูุน ูุฌููุนุงุช ุจูุงูุงุช ุฑุคูุฉ ุงูููุจููุชุฑ:

ุงุณุชุฎุฏู ูุนููุฉ `split` ูู `Datasets` ูุชุญููู ุนููุฉ ุตุบูุฑุฉ ููุท ูู ุงูุงููุณุงู ุงูุชุฏุฑูุจู ูุธุฑูุง ูุฃู ูุฌููุนุฉ ุงูุจูุงูุงุช ูุจูุฑุฉ ุฌุฏูุง!

```ุจุงูุซูู
>>> from datasets import load_dataset

>>> dataset = load_dataset("food101", split="train[:100]")
```

ุจุนุฏ ุฐููุ ุงูู ูุธุฑุฉ ุนูู ุงูุตูุฑุฉ ุจุงุณุชุฎุฏุงู ููุฒุฉ `Image` ูู `Datasets`:

```ุจุงูุซูู
>>> dataset[0]["image"]
```

ูู ุจุชุญููู ูุนุงูุฌ ุงูุตูุฑ ุจุงุณุชุฎุฏุงู `AutoImageProcessor.from_pretrained`:

```ุจุงูุซูู
>>> from transformers import AutoImageProcessor

>>> image_processor = AutoImageProcessor.from_pretrained("google/vit-base-patch16-224")
```

ุฃููุงูุ ุฏุนูุง ูุถูู ุจุนุถ ุงูุฒูุงุฏุฉ ูู ุงูุตูุฑ. ููููู ุงุณุชุฎุฏุงู ุฃู ููุชุจุฉ ุชูุถููุงุ ูููู ูู ูุฐุง ุงูุจุฑูุงูุฌ ุงูุชุนููููุ ุณูุณุชุฎุฏู ูุญุฏุฉ `transforms` ูู `torchvision`. ุฅุฐุง ููุช ููุชููุง ุจุงุณุชุฎุฏุงู ููุชุจุฉ ุฒูุงุฏุฉ ุจูุงูุงุช ุฃุฎุฑูุ ูุชุนุฑู ุนูู ููููุฉ ุงูููุงู ุจุฐูู ูู ุฏูุงุชุฑ ููุงุญุธุงุช `Albumentations` ุฃู `Kornia`.

1. ููุง ูุณุชุฎุฏู `Compose` ูุฑุจุท ุจุนุถ ุงูุชุญูููุงุช - `RandomResizedCrop` ู`ColorJitter`. ูุงุญุธ ุฃูู ุจุงููุณุจุฉ ูุชุบููุฑ ุงูุญุฌูุ ูููููุง ุงูุญุตูู ุนูู ูุชุทูุจุงุช ุญุฌู ุงูุตูุฑุฉ ูู `image_processor`. ุจุงููุณุจุฉ ูุจุนุถ ุงูููุงุฐุฌุ ูู ุงููุชููุน ุงุฑุชูุงุน ูุนุฑุถ ูุญุฏุฏููุ ูุจุงููุณุจุฉ ููุขุฎุฑููุ ูุชู ุชุนุฑูู `shortest_edge` ููุท.

```ุจุงูุซูู
>>> from torchvision.transforms import RandomResizedCrop, ColorJitter, Compose

>>> size = (
...     image_processor.size["shortest_edge"]
...     if "shortest_edge" in image_processor.size
...     else (image_processor.size["height"], image_processor.size["width"])
... )

>>> _transforms = Compose([RandomResizedCrop(size), ColorJitter(brightness=0.5, hue=0.5)])
```

2. ููุจู ุงููููุฐุฌ `pixel_values` ููุฏุฎูุงุช ูู. ูููู ูู `ImageProcessor` ุงูุชุนุงูู ูุน ุชุทุจูุน ุงูุตูุฑุ ูุชูููุฏ ุงูุชูุณูุฑุงุช ุงูููุงุณุจุฉ. ูู ุจุฅูุดุงุก ุฏุงูุฉ ุชุฌูุน ุจูู ุฒูุงุฏุฉ ุงูุตูุฑ ูุงููุนุงูุฌุฉ ุงููุณุจูุฉ ููุตูุฑ ููุฌููุนุฉ ูู ุงูุตูุฑ ูุชููุฏ `pixel_values`:

```ุจุงูุซูู
>>> def transforms(examples):
...     images = [_transforms(img.convert("RGB")) for img in examples["image"]]
...     examples["pixel_values"] = image_processor(images, do_resize=False, return_tensors="pt")["pixel_values"]
...     return examples
```

ูู ุงููุซุงู ุฃุนูุงูุ ูููุง ุจุชุนููู `do_resize=False` ูุฃููุง ูููุง ุจุงููุนู ุจุชุบููุฑ ุญุฌู ุงูุตูุฑ ูู ุชุญููู ุฒูุงุฏุฉ ุงูุตูุฑุ ูุงุณุชูุฏูุง ูู ุฎุงุตูุฉ `size` ูู `image_processor` ุงูููุงุณุจ. ุฅุฐุง ูู ุชูู ุจุชุบููุฑ ุญุฌู ุงูุตูุฑ ุฃุซูุงุก ุฒูุงุฏุฉ ุงูุตูุฑุ ููู ุจุชุฑู ูุฐุง ุงููุนููุฉ. ุจุดูู ุงูุชุฑุงุถูุ ุณูู ูุชุนุงูู `ImageProcessor` ูุน ุชุบููุฑ ุงูุญุฌู.

ุฅุฐุง ููุช ุชุฑุบุจ ูู ุชุทุจูุน ุงูุตูุฑ ูุฌุฒุก ูู ุชุญููู ุฒูุงุฏุฉ ุงูุตูุฑุ ูุงุณุชุฎุฏู ููู `image_processor.image_mean` ู`image_processor.image_std`.

3. ุซู ุงุณุชุฎุฏู `datasets.Dataset.set_transform` ูุชุทุจูู ุงูุชุญูููุงุช ุฃุซูุงุก ุงูุชููู:

```ุจุงูุซูู
>>> dataset.set_transform(transforms)
```

4. ุงูุขู ุนูุฏ ุงููุตูู ุฅูู ุงูุตูุฑุฉุ ุณุชูุงุญุธ ุฃู ูุนุงูุฌ ุงูุตูุฑ ูุฏ ุฃุถุงู `pixel_values`. ููููู ุงูุขู ุชูุฑูุฑ ูุฌููุนุฉ ุงูุจูุงูุงุช ุงููุนุงูุฌุฉ ุฅูู ุงููููุฐุฌ!

```ุจุงูุซูู
>>> dataset[0].keys()
```

ููุฐุง ุชุจุฏู ุงูุตูุฑุฉ ุจุนุฏ ุชุทุจูู ุงูุชุญูููุงุช. ุชู ุงูุชุตุงุต ุงูุตูุฑุฉ ุนุดูุงุฆููุง ูุชุฎุชูู ุฎุตุงุฆุต ุงูุฃููุงู ุจูุง.

```ุจุงูุซูู
>>> import numpy as np
>>> import matplotlib.pyplot as plt

>>> img = dataset[0]["pixel_values"]
>>> plt.imshow(img.permute(1, 2, 0))
```

ุจุงููุณุจุฉ ููููุงู ูุซู ุงููุดู ุนู ุงูุฃุดูุงุกุ ูุงูุชุฌุฒุฆุฉ ุงูุฏูุงููุฉุ ูุงูุชุฌุฒุฆุฉ ุงููุซุงููุฉุ ูุงูุชุฌุฒุฆุฉ ุงูุดุงููุฉุ ูููุฑ `ImageProcessor` ุทุฑู ูุง ุจุนุฏ ุงููุนุงูุฌุฉ. ุชุญูู ูุฐู ุงูุทุฑู ุงููุฎุฑุฌุงุช ุงูุฎุงู ูููููุฐุฌ ุฅูู ุชูุจุคุงุช ุฐุงุช ูุนูู ูุซู ุตูุงุฏูู ุงูุญุฏูุฏุ ุฃู ุฎุฑุงุฆุท ุงูุชุฌุฒุฆุฉ.

## ุจุงุฏ

ูู ุจุนุถ ุงูุญุงูุงุชุ ุนูู ุณุจูู ุงููุซุงูุ ุนูุฏ ุถุจุท ูููุฐุฌ `DETR` ุจุฏูุฉุ ูุทุจู ุงููููุฐุฌ ุฒูุงุฏุฉ ุงููููุงุณ ูู ููุช ุงูุชุฏุฑูุจ. ูุฏ ูุชุณุจุจ ูุฐุง ูู ุงุฎุชูุงู ุฃุญุฌุงู ุงูุตูุฑ ูู ุฏูุนุฉ. ููููู ุงุณุชุฎุฏุงู `DetrImageProcessor.pad` ูู `DetrImageProcessor` ูุชุนุฑูู `collate_fn` ูุฎุตุต ูุฏูุฌ ุงูุตูุฑ ูุนูุง.

```ุจุงูุซูู
>>> def collate_fn(batch):
...     pixel_values = [item["pixel_values"] for item in batch]
...     encoding = image_processor.pad(pixel_values, return_tensors="pt")
...     labels = [item["labels"] for item in batch]
...     batch = {}
...     batch["pixel_values"] = encoding["pixel_values"]
...     batch["pixel_mask"] = encoding["pixel_mask"]
...     batch["labels"] = labels
...     return batch
```

## ูุชุนุฏุฏ ุงููุณุงุฆุท

ุจุงููุณุจุฉ ููููุงู ุงูุชู ุชุชุถูู ูุฏุฎูุงุช ูุชุนุฏุฏุฉ ุงููุณุงุฆุทุ ุณุชุญุชุงุฌ ุฅูู ูุนุงูุฌ ูุชุญุถูุฑ ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจู ููููุฐุฌุฉ. ููุฑู ุงููุนุงูุฌ ุจูู ูุงุฆููู ูุนุงูุฌูู ูุซู ุงููุนุงูุฌ ูุงููุญูู ุงููููุฒ.

ูู ุจุชุญููู ูุฌููุนุฉ ุจูุงูุงุช `LJ Speech` (ุฑุงุฌุน ุชุนูููุงุช `Datasets` ููุญุตูู ุนูู ูุฒูุฏ ูู ุงูุชูุงุตูู ุญูู ููููุฉ ุชุญููู ูุฌููุนุฉ ุจูุงูุงุช) ููุนุฑูุฉ ููู ููููู ุงุณุชุฎุฏุงู ูุนุงูุฌ ููุชุนุฑู ุงูุชููุงุฆู ุนูู ุงูููุงู (ASR):

```ุจุงูุซูู
>>> from datasets import load_dataset

>>> lj_speech = load_dataset("lj_speech", split="train")
```

ุจุงููุณุจุฉ ูู ASRุ ูุฃูุช ุชุฑูุฒ ุจุดูู ุฃุณุงุณู ุนูู `audio` ู`text` ูุฐุง ููููู ุฅุฒุงูุฉ ุงูุฃุนูุฏุฉ ุงูุฃุฎุฑู:

```ุจุงูุซูู
>>> lj_speech = lj_speech.map(remove_columns=["file", "id", "normalized_text"])
```

ุงูุขู ุงูู ูุธุฑุฉ ุนูู ุฃุนูุฏุฉ `audio` ู`text`:

```ุจุงูุซูู
>>> lj_speech[0]["audio"]
{'array': array([-7.3242188e-04, -7.6293945e-04, -6.4086914e-04, ...,
7.3242188e-04,  2.1362305e-04,  6.1035156e-05], dtype=float32),
'path': '/root/.cache/huggingface/datasets/downloads/extracted/917ece08c95cf0c4115e45294e3cd0dee724a1165b7fc11798369308a465bd26/LJSpeech-1.1/wavs/LJ001-0001.wav',
'sampling_rate': 22050}

>>> lj_speech[0]["text"]
'Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition'
```

ุชุฐูุฑ ุฃูู ูุฌุจ ุนููู ุฏุงุฆููุง ุฅุนุงุฏุฉ ุฃุฎุฐ ุนููุงุช ูู ูุนุฏู ุนููุงุช ูุฌููุนุฉ ุจูุงูุงุช ุงูุตูุช ุงูุฎุงุตุฉ ุจู ููุทุงุจูุฉ ูุนุฏู ุงูุนููุงุช ููุฌููุนุฉ ุงูุจูุงูุงุช ุงููุณุชุฎุฏูุฉ ูุชุฏุฑูุจ ุงููููุฐุฌ ูุณุจููุง!

```ุจุงูุซูู
>>> lj_speech = lj_speech.cast_column("audio", Audio(sampling_rate=16_000))
```

ูู ุจุชุญููู ูุนุงูุฌ ุจุงุณุชุฎุฏุงู `AutoProcessor.from_pretrained`:

```ุจุงูุซูู
>>> from transformers import AutoProcessor

>>> processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")
```

1. ูู ุจุฅูุดุงุก ุฏุงูุฉ ููุนุงูุฌุฉ ุจูุงูุงุช ุงูุตูุช ุงูููุฌูุฏุฉ ูู `array` ุฅูู `input_values`ุ ููุนุงูุฌุฉ `text` ุฅูู `labels`. ูุฐู ูู ุงููุฏุฎูุงุช ูููููุฐุฌ:

```ุจุงูุซูู
>>> def prepare_dataset(example):
...     audio = example["audio"]

...     example.update(processor(audio=audio["array"], text=example["text"], sampling_rate=16000))

...     return example
```

2. ูู ุจุชุทุจูู ุฏุงูุฉ `prepare_dataset` ุนูู ุนููุฉ:

```ุจุงูุซูู
>>> prepare_dataset(lj_speech[0])
```

ููุฏ ุฃุถุงู ุงููุนุงูุฌ ุงูุขู `input_values` ู`labels`ุ ูุชู ุฃูุถูุง ุฅุนุงุฏุฉ ุฃุฎุฐ ุงูุนููุงุช ูู ูุนุฏู ุงูุนููุงุช ุจุดูู ุตุญูุญ ุฅูู 16 ูููู ูุฑุชุฒ. ููููู ุงูุขู ุชูุฑูุฑ ูุฌููุนุฉ ุงูุจูุงูุงุช ุงููุนุงูุฌุฉ ุฅูู ุงููููุฐุฌ!