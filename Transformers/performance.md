# الأداء وقابلية التوسع 

يمكن أن يواجه تدريب نماذج المحول الكبيرة ونشرها في الإنتاج تحديات مختلفة. أثناء التدريب، قد يحتاج النموذج إلى المزيد من ذاكرة GPU أكثر مما هو متاح أو قد يظهر سرعة تدريب بطيئة. في مرحلة النشر، قد يناضل النموذج للتعامل مع الإنتاجية المطلوبة في بيئة الإنتاج.

تهدف هذه الوثيقة إلى مساعدتك في التغلب على هذه التحديات وإيجاد الإعداد الأمثل لحالتك الاستخدامية. تم تقسيم الأدلة إلى قسمي التدريب والاستنتاج، حيث يأتي كل منهما مع تحديات وحلول مختلفة.

داخل كل قسم، ستجد أدلة منفصلة لتكوينات الأجهزة المختلفة، مثل GPU واحدة مقابل متعددة GPUs للتدريب أو CPU مقابل GPU للاستدلال. استخدم هذه الوثيقة كنقطة انطلاق للانتقال إلى الأساليب التي تتوافق مع سيناريوهاتك.

## التدريب 

يتطلب تدريب نماذج المحول الكبيرة بكفاءة مسرعًا مثل GPU أو TPU. الحالة الأكثر شيوعًا هي عندما يكون لديك GPU واحدة. يمكن توسيع نطاق الأساليب التي يمكنك تطبيقها لتحسين كفاءة التدريب على GPU واحدة إلى إعدادات أخرى مثل عدة GPUs. ومع ذلك، هناك أيضًا تقنيات محددة لتدريب GPU أو CPU متعددة. نغطيها في أقسام منفصلة.

* [أساليب وأدوات للتدريب الفعال على GPU واحدة](perf_train_gpu_one): ابدأ من هنا لمعرفة النهج الشائعة التي يمكن أن تساعد في تحسين استخدام ذاكرة GPU، وتسريع التدريب، أو كليهما.

* [قسم تدريب متعدد الـ GPUs](perf_train_gpu_many): استكشف هذا القسم للتعرف على أساليب التحسين الإضافية التي تنطبق على إعدادات متعددة GPUs، مثل موازاة البيانات والموترات والأنابيب.

* [قسم التدريب على وحدة المعالجة المركزية](perf_train_cpu): تعرف على التدريب عالي الدقة على وحدة المعالجة المركزية.

* [التدريب الفعال على وحدات معالجة مركزية متعددة](perf_train_cpu_many): تعرف على التدريب الموزع على وحدة المعالجة المركزية.

* [التدريب على TPU مع TensorFlow](perf_train_tpu_tf): إذا كنت جديدًا في وحدات معالجة الرسوميات، فراجع هذا القسم للحصول على مقدمة حول التدريب على وحدات معالجة الرسوميات واستخدام XLA.

* [الأجهزة المخصصة للتدريب](perf_hardware): احصل على نصائح وحيل عند بناء جهاز التعلم العميق الخاص بك.

* [البحث عن أفضل فرضية باستخدام واجهة برمجة تطبيقات المدرب](hpo_train)

## الاستنتاج 

يمكن أن يكون الاستدلال الفعال باستخدام النماذج الكبيرة في بيئة إنتاج بنفس صعوبة تدريبها. في الأقسام التالية، نمر عبر الخطوات لتشغيل الاستدلال على إعدادات وحدة المعالجة المركزية ووحدة معالجة الرسوميات (GPU) واحدة/متعددة.

* [الاستدلال على وحدة المعالجة المركزية واحدة](perf_infer_cpu)

* [الاستدلال على GPU واحدة](perf_infer_gpu_one)

* [الاستدلال متعدد الـ GPUs](perf_infer_gpu_many)

* [تكامل XLA لنماذج TensorFlow](tf_xla)

## التدريب والاستدلال 

ستجد هنا تقنيات ونصائح وحيل تنطبق سواء كنت تدرب نموذجًا أو تقوم بالاستدلال باستخدامه.

* [إنشاء مثيل لنموذج كبير](big_models)

* [استكشاف أخطاء مشكلات الأداء وإصلاحها](debugging)

## المساهمة 

هذه الوثيقة أبعد ما تكون عن الاكتمال، ولا يزال هناك الكثير مما يجب إضافته، لذا إذا كان لديك إضافات أو تصحيحات لإجرائها، فلا تتردد في فتح PR أو إذا لم تكن متأكدًا، ابدأ مناقشة Issue ويمكننا مناقشة التفاصيل هناك.

عند تقديم مساهمات تفيد بأن A أفضل من B، يرجى محاولة تضمين معيار قابل للتكرار و/أو رابط لمصدر تلك المعلومات (ما لم تأت مباشرة منك).