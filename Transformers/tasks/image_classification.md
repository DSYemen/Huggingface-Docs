## ØªØµÙ†ÙŠÙ Ø§Ù„ØµÙˆØ±

ÙŠÙØ®ØµØµ ØªØµÙ†ÙŠÙ Ø§Ù„ØµÙˆØ± Ø¹Ù„Ø§Ù…Ø© Ø£Ùˆ ÙØ¦Ø© Ù„ØµÙˆØ±Ø© Ù…Ø¹ÙŠÙ†Ø©. ÙˆØ¹Ù„Ù‰ Ø¹ÙƒØ³ ØªØµÙ†ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ Ø£Ùˆ Ø§Ù„ØµÙˆØªÙŠØ§ØªØŒ ÙØ¥Ù† Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ù‡ÙŠ Ù‚ÙŠÙ… Ø§Ù„Ø¨ÙƒØ³Ù„ Ø§Ù„ØªÙŠ ØªØªÙƒÙˆÙ† Ù…Ù†Ù‡Ø§ Ø§Ù„ØµÙˆØ±Ø©. Ù‡Ù†Ø§Ùƒ Ø§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ù„ØªØµÙ†ÙŠÙ Ø§Ù„ØµÙˆØ±ØŒ Ù…Ø«Ù„ Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„Ø£Ø¶Ø±Ø§Ø± Ø¨Ø¹Ø¯ ÙˆÙ‚ÙˆØ¹ ÙƒØ§Ø±Ø«Ø© Ø·Ø¨ÙŠØ¹ÙŠØ©ØŒ Ø£Ùˆ Ù…Ø±Ø§Ù‚Ø¨Ø© ØµØ­Ø© Ø§Ù„Ù…Ø­Ø§ØµÙŠÙ„ØŒ Ø£Ùˆ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙŠ ÙØ­Øµ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø·Ø¨ÙŠØ© Ù„Ù„ÙƒØ´Ù Ø¹Ù† Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ù…Ø±Ø¶.

ÙŠÙˆØ¶Ø­ Ù‡Ø°Ø§ Ø§Ù„Ø¯Ù„ÙŠÙ„ ÙƒÙŠÙÙŠØ©:

1. Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ [ViT](model_doc/vit) Ø¨Ø¯Ù‚Ø© Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª [Food-101](https://huggingface.co/datasets/food101) Ù„ØªØµÙ†ÙŠÙ Ø¹Ù†ØµØ± ØºØ°Ø§Ø¦ÙŠ ÙÙŠ ØµÙˆØ±Ø©.
2. Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¶Ø¨ÙˆØ· Ø¨Ø¯Ù‚Ø© Ù„Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬.

Ù‚Ø¨Ù„ Ø£Ù† ØªØ¨Ø¯Ø£ØŒ ØªØ£ÙƒØ¯ Ù…Ù† ØªØ«Ø¨ÙŠØª Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ø¶Ø±ÙˆØ±ÙŠØ©:

```bash
pip install transformers datasets evaluate accelerate pillow torchvision scikit-learn
```

Ù†Ø­Ù† Ù†Ø´Ø¬Ø¹Ùƒ Ø¹Ù„Ù‰ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø¥Ù„Ù‰ Ø­Ø³Ø§Ø¨ Hugging Face Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ Ù„ØªØ­Ù…ÙŠÙ„ ÙˆÙ…Ø´Ø§Ø±ÙƒØ© Ù†Ù…ÙˆØ°Ø¬Ùƒ Ù…Ø¹ Ø§Ù„Ù…Ø¬ØªÙ…Ø¹. Ø¹Ù†Ø¯Ù…Ø§ ÙŠÙØ·Ù„Ø¨ Ù…Ù†Ùƒ Ø°Ù„ÙƒØŒ Ø£Ø¯Ø®Ù„ Ø±Ù…Ø²Ùƒ Ù„Ù„Ø¯Ø®ÙˆÙ„:

```py
>>> from huggingface_hub import notebook_login

>>> notebook_login()
```

## ØªØ­Ù…ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Food-101

Ø§Ø¨Ø¯Ø£ Ø¨ØªØ­Ù…ÙŠÙ„ Ø¬Ø²Ø¡ ÙØ±Ø¹ÙŠ Ø£ØµØºØ± Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Food-101 Ù…Ù† Ù…ÙƒØªØ¨Ø© ðŸ¤— Datasets. Ø³ÙŠØ¹Ø·ÙŠÙƒ Ù‡Ø°Ø§ ÙØ±ØµØ© Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† ÙƒÙ„ Ø´ÙŠØ¡ ÙŠØ¹Ù…Ù„ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­ Ù‚Ø¨Ù„ Ù‚Ø¶Ø§Ø¡ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ÙˆÙ‚Øª ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒØ§Ù…Ù„Ø©.

```py
>>> from datasets import load_dataset

>>> food = load_dataset("food101", split="train[:5000]")
```

Ù‚Ø³ÙÙ‘Ù… Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª ÙØ±Ø¹ÙŠØ© Ù„Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø·Ø±ÙŠÙ‚Ø© [`~datasets.Dataset.train_test_split`]:

```py
>>> food = food.train_test_split(test_size=0.2)
```

Ø«Ù… Ø§Ù„Ù‚ Ù†Ø¸Ø±Ø© Ø¹Ù„Ù‰ Ù…Ø«Ø§Ù„:

```py
>>> food["train"][0]
{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x512 at 0x7F52AFC8AC50>,
'label': 79}
```

ÙŠØ­ØªÙˆÙŠ ÙƒÙ„ Ù…Ø«Ø§Ù„ ÙÙŠ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ù„Ù‰ Ø­Ù‚Ù„ÙŠÙ†:

- `image`: ØµÙˆØ±Ø© PIL Ù„Ø¹Ù†ØµØ± Ø§Ù„Ø·Ø¹Ø§Ù…
- `label`: ÙØ¦Ø© Ø§Ù„ØªØµÙ†ÙŠÙ Ù„Ø¹Ù†ØµØ± Ø§Ù„Ø·Ø¹Ø§Ù…

Ù„Ø¬Ø¹Ù„ Ø§Ù„Ø£Ù…Ø± Ø£Ø³Ù‡Ù„ Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ø³Ù… Ø§Ù„ØªØµÙ†ÙŠÙ Ù…Ù† Ù…Ø¹Ø±Ù Ø§Ù„ØªØµÙ†ÙŠÙØŒ Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ù…ÙˆØ³ ÙŠØ­Ø¯Ø¯ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª Ø¥Ù„Ù‰ Ù‚ÙŠÙ…Ø© Ø¹Ø¯Ø¯ÙŠØ© ÙˆØ§Ù„Ø¹ÙƒØ³:

```py
>>> labels = food["train"].features["label"].names
>>> label2id, id2label = dict(), dict()
>>> for i, label in enumerate(labels):
...     label2id[label] = str(i)
...     id2label[str(i)] = label
```

Ø§Ù„Ø¢Ù† ÙŠÙ…ÙƒÙ†Ùƒ ØªØ­ÙˆÙŠÙ„ Ù…Ø¹Ø±Ù Ø§Ù„ØªØµÙ†ÙŠÙ Ø¥Ù„Ù‰ Ø§Ø³Ù… Ø§Ù„ØªØµÙ†ÙŠÙ:

```py
>>> id2label[str(79)]
'prime_rib'
```

## Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø³Ø¨Ù‚Ø©

Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„ØªØ§Ù„ÙŠØ© Ù‡ÙŠ ØªØ­Ù…ÙŠÙ„ Ù…Ø¹Ø§Ù„Ø¬ ØµÙˆØ± ViT Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© ÙˆØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ø¥Ù„Ù‰ Ù…ØµÙÙˆÙØ©:

```py
>>> from transformers import AutoImageProcessor

>>> checkpoint = "google/vit-base-patch16-224-in21k"
>>> image_processor = AutoImageProcessor.from_pretrained(checkpoint)
```

<frameworkcontent>
<pt>
Ù‚Ù… Ø¨ØªØ·Ø¨ÙŠÙ‚ Ø¨Ø¹Ø¶ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ± Ù„Ø¬Ø¹Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£ÙƒØ«Ø± Ù‚ÙˆØ© Ø¶Ø¯ Ø§Ù„Ø¥ÙØ±Ø§Ø· ÙÙŠ Ø§Ù„ØªØ®ØµÙŠØµ. Ù‡Ù†Ø§ØŒ Ø³ØªØ³ØªØ®Ø¯Ù… ÙˆØ­Ø¯Ø© [`transforms`](https://pytorch.org/vision/stable/transforms.html) Ù…Ù† Ù…ÙƒØªØ¨Ø© torchvisionØŒ ÙˆÙ„ÙƒÙ† ÙŠÙ…ÙƒÙ†Ùƒ Ø£ÙŠØ¶Ù‹Ø§ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£ÙŠ Ù…ÙƒØªØ¨Ø© ØµÙˆØ± ØªÙØ¶Ù„Ù‡Ø§.

Ø§Ù‚ØªØµ Ø¬Ø²Ø¡Ù‹Ø§ Ø¹Ø´ÙˆØ§Ø¦ÙŠÙ‹Ø§ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø©ØŒ ÙˆÙ‚Ù… Ø¨ØªØºÙŠÙŠØ± Ø­Ø¬Ù…Ù‡Ø§ØŒ ÙˆØ·Ø¨ÙÙ‘Ø¹Ù‡Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ØªÙˆØ³Ø· ÙˆØ§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ Ù„Ù„ØµÙˆØ±Ø©:

```py
>>> from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor

>>> normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)
>>> size = (
...     image_processor.size["shortest_edge"]
...     if "shortest_edge" in image_processor.size
...     else (image_processor.size["height"], image_processor.size["width"])
... )
>>> _transforms = Compose([RandomResizedCrop(size), ToTensor(), normalize])
```

Ø«Ù… Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø¯Ø§Ù„Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø³Ø¨Ù‚Ø© Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª ÙˆØ¥Ø±Ø¬Ø§Ø¹ `pixel_values` - Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ø¥Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ - Ù„Ù„ØµÙˆØ±Ø©:

```py
>>> def transforms(examples):
...     examples["pixel_values"] = [_transforms(img.convert("RGB")) for img in examples["image"]]
...     del examples["image"]
...     return examples
```

Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¯Ø§Ù„Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³Ø¨Ù‚Ø© Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø£ÙƒÙ…Ù„Ù‡Ø§ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø·Ø±ÙŠÙ‚Ø© [`~datasets.Dataset.with_transform`] Ù…Ù† Ù…ÙƒØªØ¨Ø© ðŸ¤— Datasets. ÙŠØªÙ… ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªÙ†Ù‚Ù„ Ø¹Ù†Ø¯ ØªØ­Ù…ÙŠÙ„ Ø¹Ù†ØµØ± Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:

```py
>>> food = food.with_transform(transforms)
```

Ø§Ù„Ø¢Ù† Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø¯ÙØ¹Ø© Ù…Ù† Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`DefaultDataCollator`]. Ø¹Ù„Ù‰ Ø¹ÙƒØ³ Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø¬Ù…Ø¹ Ø§Ù„Ø£Ø®Ø±Ù‰ ÙÙŠ Ù…ÙƒØªØ¨Ø© ðŸ¤— TransformersØŒ ÙØ¥Ù† `DefaultDataCollator` Ù„Ø§ ØªØ·Ø¨Ù‚ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø³Ø¨Ù‚Ø© Ø¥Ø¶Ø§ÙÙŠØ© Ù…Ø«Ù„ Ø§Ù„ØªÙˆØ³ÙŠØ¯.

```py
>>> from transformers import DefaultDataCollator

>>> data_collator = DefaultDataCollator()
```

</pt>
</frameworkcontent>

<frameworkcontent>
<tf>
Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ø¥ÙØ±Ø§Ø· ÙÙŠ Ø§Ù„ØªØ®ØµÙŠØµ ÙˆØ¬Ø¹Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£ÙƒØ«Ø± Ù‚ÙˆØ©ØŒ Ø£Ø¶Ù Ø¨Ø¹Ø¶ Ø§Ù„ØªØ¹Ø²ÙŠØ²Ø§Øª Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ÙŠ Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.

Ù‡Ù†Ø§ØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø·Ø¨Ù‚Ø§Øª Ù…Ø§ Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù† Keras Ù„ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (Ø¨Ù…Ø§ ÙÙŠ Ø°Ù„Ùƒ Ø§Ù„ØªØ¹Ø²ÙŠØ²Ø§Øª)ØŒ ÙˆØ§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ù‚Ù‚ (Ø§Ù„Ø§Ù‚ØªØµØ§Øµ Ø§Ù„Ù…Ø±ÙƒØ²ÙŠ ÙÙ‚Ø·ØŒ ØªØºÙŠÙŠØ± Ø§Ù„Ø­Ø¬Ù…ØŒ ÙˆØ§Ù„ØªÙˆØ­ÙŠØ¯). ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… `tf.image` Ø£Ùˆ Ø£ÙŠ Ù…ÙƒØªØ¨Ø© Ø£Ø®Ø±Ù‰ ØªÙØ¶Ù„Ù‡Ø§.

```py
>>> from tensorflow import keras
>>> from tensorflow.keras import layers

>>> size = (image_processor.size["height"], image_processor.size["width"])

>>> train_data_augmentation = keras.Sequential(
...     [
...         layers.RandomCrop(size[0], size[1]),
...         layers.Rescaling(scale=1.0 / 127.5, offset=-1),
...         layersMultiplier
...         layers.RandomFlip("horizontal"),
...         layers.RandomRotation(factor=0.02),
...         layers.RandomZoom(height_factor=0.2, width_factor=0.2),
...     ],
...     name="train_data_augmentation",
... )

>>> val_data_augmentation = keras.Sequential(
...     [
...         layers.CenterCrop(size[0], size[1]),
...         layers.Rescaling(scale=1.0 / 127.5, offset=-1),
...     ],
...     name="val_data_augmentation",
... )
```

Ø¨Ø¹Ø¯ Ø°Ù„ÙƒØŒ Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø¯ÙˆØ§Ù„ Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ø¹Ù„Ù‰ Ø¯ÙØ¹Ø© Ù…Ù† Ø§Ù„ØµÙˆØ±ØŒ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† ØµÙˆØ±Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙŠ ÙƒÙ„ Ù…Ø±Ø©.

```py
>>> import numpy as np
>>> import tensorflow as tf
>>> from PIL import Image


>>> def convert_to_tf_tensor(image: Image):
...     np_image = np.array(image)
...     tf_image = tf.convert_to_tensor(np_image)
...     # `expand_dims()` is used to add a batch dimension since
...     # the TF augmentation layers operates on batched inputs.
...     return tf.expand_dims(tf_image, 0)


>>> def preprocess_train(example_batch):
...     """Apply train_transforms across a batch."""
...     images = [
...         train_data_augmentation(convert_to_tf_tensor(image.convert("RGB"))) for image in example_batch["image"]
...     ]
...     example_batch["pixel_values"] = [tf.transpose(tf.squeeze(image)) for image in images]
...     return example_batch


... def preprocess_val(example_batch):
...     """Apply val_transforms across a batch."""
...     images = [
...         val_data_augmentation(convert_to_tf_tensor(image.convert("RGB"))) for image in example_batch["image"]
...     ]
...     example_batch["pixel_values"] = [tf.transpose(tf.squeeze(image)) for image in images]
...     return example_batch
```

Ø§Ø³ØªØ®Ø¯Ù… Ø·Ø±ÙŠÙ‚Ø© [`~datasets.Dataset.set_transform`] Ù…Ù† Ù…ÙƒØªØ¨Ø© ðŸ¤— Datasets Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªÙ†Ù‚Ù„:

```py
food["train"].set_transform(preprocess_train)
food["test"].set_transform(preprocess_val)
```

ÙˆÙƒØ®Ø·ÙˆØ© Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø³Ø¨Ù‚Ø© Ù†Ù‡Ø§Ø¦ÙŠØ©ØŒ Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø¯ÙØ¹Ø© Ù…Ù† Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… `DefaultDataCollator`. Ø¹Ù„Ù‰ Ø¹ÙƒØ³ Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø¬Ù…Ø¹ Ø§Ù„Ø£Ø®Ø±Ù‰ ÙÙŠ Ù…ÙƒØªØ¨Ø© ðŸ¤— TransformersØŒ ÙØ¥Ù† `DefaultDataCollator` Ù„Ø§ ØªØ·Ø¨Ù‚ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø³Ø¨Ù‚Ø© Ø¥Ø¶Ø§ÙÙŠØ©ØŒ Ù…Ø«Ù„ Ø§Ù„ØªÙˆØ³ÙŠØ¯.

```py
>>> from transformers import DefaultDataCollator

>>> data_collator = DefaultDataCollator(return_tensors="tf")
```

</tf>
</frameworkcontent>

## ØªÙ‚ÙŠÙŠÙ…

ØºØ§Ù„Ø¨Ù‹Ø§ Ù…Ø§ ÙŠÙƒÙˆÙ† ØªØ¶Ù…ÙŠÙ† Ù…Ù‚ÙŠØ§Ø³ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù…ÙÙŠØ¯Ù‹Ø§ Ù„ØªÙ‚ÙŠÙŠÙ… Ø£Ø¯Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬Ùƒ. ÙŠÙ…ÙƒÙ†Ùƒ ØªØ­Ù…ÙŠÙ„ Ø·Ø±ÙŠÙ‚Ø© ØªÙ‚ÙŠÙŠÙ… Ø¨Ø³Ø±Ø¹Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙƒØªØ¨Ø© ðŸ¤— [Evaluate](https://huggingface.co/docs/evaluate/index). Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù‡Ù…Ø©ØŒ Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ù…Ù‚ÙŠØ§Ø³ [Ø§Ù„Ø¯Ù‚Ø©](https://huggingface.co/spaces/evaluate-metric/accuracy) (Ø±Ø§Ø¬Ø¹ Ø§Ù„Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø³Ø±ÙŠØ¹ Ù„Ù€ ðŸ¤— Evaluate [quick tour](https://huggingface.co/docs/evaluate/a_quick_tour) Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯ Ø­ÙˆÙ„ ÙƒÙŠÙÙŠØ© ØªØ­Ù…ÙŠÙ„ ÙˆØ­Ø³Ø§Ø¨ Ù…Ù‚ÙŠØ§Ø³):

```py
>>> import evaluate

>>> accuracy = evaluate.load("accuracy")
```

Ø«Ù… Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø¯Ø§Ù„Ø© ØªÙ…Ø±Ø± ØªÙ†Ø¨Ø¤Ø§ØªÙƒ ÙˆØªØµÙ†ÙŠÙØ§ØªÙƒ Ø¥Ù„Ù‰ [`~evaluate.EvaluationModule.compute`] Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø©:

```py
>>> import numpy as np


>>> def compute_metrics(eval_pred):
...     predictions, labels = eval_pred
...     predictions = np.argmax(predictions, axis=1)
...     return accuracy.compute(predictions=predictions, references=labels)
```

Ø§Ù„Ø¢Ù† Ø£ØµØ¨Ø­Øª Ø¯Ø§Ù„Ø© `compute_metrics` Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ Ø¬Ø§Ù‡Ø²Ø© Ù„Ù„Ø¹Ù…Ù„ØŒ ÙˆØ³ØªØ¹ÙˆØ¯ Ø¥Ù„ÙŠÙ‡Ø§ Ø¹Ù†Ø¯ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ¯Ø±ÙŠØ¨.
Ø¨Ø§Ù„ØªØ£ÙƒÙŠØ¯! ÙÙŠÙ…Ø§ ÙŠÙ„ÙŠ ØªØ±Ø¬Ù…Ø© Ù„Ù„Ø¬Ø²Ø¡ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ù…Ù† Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©:

## Ø§Ù„ØªØ¯Ø±ÙŠØ¨

Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…Ø¹ØªØ§Ø¯Ø§Ù‹ Ø¹Ù„Ù‰ Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`Trainer`]ØŒ ÙØ±Ø§Ø¬Ø¹ Ø§Ù„Ø¯Ù„ÙŠÙ„ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ [Ù‡Ù†Ø§] (../training#train-with-pytorch-trainer)

Ø§Ù„Ø¢Ù† Ø£Ù†Øª Ù…Ø³ØªØ¹Ø¯ Ù„Ø¨Ø¯Ø¡ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬Ùƒ! Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ ViT Ù…Ø¹ [`AutoModelForImageClassification`]. Ø­Ø¯Ø¯ Ø¹Ø¯Ø¯ Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª Ø¬Ù†Ø¨Ù‹Ø§ Ø¥Ù„Ù‰ Ø¬Ù†Ø¨ Ù…Ø¹ Ø¹Ø¯Ø¯ Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©ØŒ ÙˆØªØ®Ø·ÙŠØ· Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª:

```py
>>> from transformers import AutoModelForImageClassification, TrainingArguments, Trainer

>>> model = AutoModelForImageClassification.from_pretrained(
...     checkpoint,
...     num_labels=len(labels),
...     id2label=id2label,
...     label2id=label2id,
... )
```

ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø­Ù„Ø©ØŒ Ù„Ù… ÙŠØªØ¨Ù‚ Ø³ÙˆÙ‰ Ø«Ù„Ø§Ø« Ø®Ø·ÙˆØ§Øª:

1. Ø­Ø¯Ø¯ ÙØ±Ø· Ù…Ø¹Ù„Ù…Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ ÙÙŠ [`TrainingArguments`]. Ù…Ù† Ø§Ù„Ù…Ù‡Ù… Ø£Ù„Ø§ ØªÙ‚ÙˆÙ… Ø¨Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ØºÙŠØ± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© Ù„Ø£Ù† Ø°Ù„Ùƒ Ø³ÙŠØ¤Ø¯ÙŠ Ø¥Ù„Ù‰ Ø¥Ø³Ù‚Ø§Ø· Ø¹Ù…ÙˆØ¯ "Ø§Ù„ØµÙˆØ±Ø©". Ø¨Ø¯ÙˆÙ† Ø¹Ù…ÙˆØ¯ "Ø§Ù„ØµÙˆØ±Ø©"ØŒ Ù„Ø§ ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ù†Ø´Ø§Ø¡ "pixel_values". Ù‚Ù… Ø¨ØªØ¹ÙŠÙŠÙ† `remove_unused_columns=False` Ù„Ù…Ù†Ø¹ Ù‡Ø°Ø§ Ø§Ù„Ø³Ù„ÙˆÙƒ! Ø§Ù„Ù…Ø¹Ù„Ù…Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ø§Ù„ÙˆØ­ÙŠØ¯Ø© Ø§Ù„Ø£Ø®Ø±Ù‰ Ù‡ÙŠ `output_dir` Ø§Ù„ØªÙŠ ØªØ­Ø¯Ø¯ Ù…ÙƒØ§Ù† Ø­ÙØ¸ Ù†Ù…ÙˆØ°Ø¬Ùƒ. Ø³ÙˆÙ ØªÙ‚ÙˆÙ… Ø¨Ø¥Ø±Ø³Ø§Ù„ Ù‡Ø°Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø­ÙˆØ± Ø¹Ù† Ø·Ø±ÙŠÙ‚ ØªØ¹ÙŠÙŠÙ† `push_to_hub=True` (ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ù…Ø³Ø¬Ù„Ø§Ù‹ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø¥Ù„Ù‰ Hugging Face Ù„ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬Ùƒ). ÙÙŠ Ù†Ù‡Ø§ÙŠØ© ÙƒÙ„ Ø­Ù‚Ø¨Ø©ØŒ Ø³ÙŠÙ‚ÙˆÙ… [`Trainer`] Ø¨ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¯Ù‚Ø© ÙˆØ­ÙØ¸ Ù†Ù‚Ø·Ø© ØªÙØªÙŠØ´ Ø§Ù„ØªØ¯Ø±ÙŠØ¨.

2. Ù…Ø±Ø± Ø­ÙØ¬Ø¬ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¥Ù„Ù‰ [`Trainer`] Ø¬Ù†Ø¨Ù‹Ø§ Ø¥Ù„Ù‰ Ø¬Ù†Ø¨ Ù…Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆÙ…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆÙ…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø±Ù…ÙˆØ² ÙˆÙ…Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆÙˆØ¸ÙŠÙØ© `compute_metrics`.

3. Ø§ØªØµÙ„ Ø¨Ù€ [`~Trainer.train`] Ù„Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬Ùƒ.

```py
>>> training_args = TrainingArguments(
...     output_dir="my_awesome_food_model"ØŒ
...     remove_unused_columns=False,
...     eval_strategy="epoch"ØŒ
...     save_strategy="epoch"ØŒ
...     learning_rate=5e-5ØŒ
...     per_device_train_batch_size=16ØŒ
...     gradient_accumulation_steps=4ØŒ
...     per_device_eval_batch_size=16ØŒ
...     num_train_epochs=3ØŒ
...     warmup_ratio=0.1ØŒ
...     logging_steps=10ØŒ
...     load_best_model_at_end=TrueØŒ
...     metric_for_best_model="accuracy"ØŒ
...     push_to_hub=TrueØŒ
... )

>>> trainer = Trainer(
...     model=modelØŒ
...     args=training_argsØŒ
...     data_collator=data_collatorØŒ
...     train_dataset=food["train"]ØŒ
...     eval_dataset=food["test"]ØŒ
...     tokenizer=image_processorØŒ
...     compute_metrics=compute_metricsØŒ
... )

>>> trainer.train()
```

Ø¨Ù…Ø¬Ø±Ø¯ Ø§ÙƒØªÙ…Ø§Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ØŒ Ø´Ø§Ø±Ùƒ Ù†Ù…ÙˆØ°Ø¬Ùƒ Ù…Ø¹ Ø§Ù„Ù…Ø­ÙˆØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø·Ø±ÙŠÙ‚Ø© [`~transformers.Trainer.push_to_hub`] Ø­ØªÙ‰ ÙŠØªÙ…ÙƒÙ† Ø§Ù„Ø¬Ù…ÙŠØ¹ Ù…Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬Ùƒ:

```py
>>> trainer.push_to_hub()
```

Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…Ø¹ØªØ§Ø¯Ù‹Ø§ Ø¹Ù„Ù‰ Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… KerasØŒ ÙØ±Ø§Ø¬Ø¹ [Ø§Ù„Ø¯Ù„ÙŠÙ„ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ] (./training#train-a-tensorflow-model-with-keras) Ø£ÙˆÙ„Ø§Ù‹!

Ù„Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ TensorFlowØŒ Ø§ØªØ¨Ø¹ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©:

1. Ø­Ø¯Ø¯ ÙØ±Ø· Ù…Ø¹Ù„Ù…Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ØŒ ÙˆÙ‚Ù… Ø¨Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø­Ø³Ù† ÙˆØ¬Ø¯ÙˆÙ„ Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ¹Ù„Ù….

2. Ù‚Ù… Ø¨ØªÙ†ÙÙŠØ° Ù†Ù…ÙˆØ°Ø¬ Ù…ÙØ¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§.

3. Ù‚Ù… Ø¨ØªØ­ÙˆÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª ðŸ¤— Ø¥Ù„Ù‰ `tf.data.Dataset`.

4. Ù‚Ù… Ø¨ØªØ¬Ù…ÙŠØ¹ Ù†Ù…ÙˆØ°Ø¬Ùƒ.

5. Ø£Ø¶Ù Ø§Ø³ØªØ¯Ø¹Ø§Ø¡Ø§Øª Ø§Ù„Ø±Ø¬ÙˆØ¹ ÙˆØ§Ø³ØªØ®Ø¯Ù… Ø·Ø±ÙŠÙ‚Ø© `fit()` Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨.

6. Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬Ùƒ Ø¥Ù„Ù‰ ðŸ¤— Hub Ù„Ù…Ø´Ø§Ø±ÙƒØªÙ‡ Ù…Ø¹ Ø§Ù„Ù…Ø¬ØªÙ…Ø¹.

Ø§Ø¨Ø¯Ø£ Ø¨ØªØ­Ø¯ÙŠØ¯ ÙØ±Ø· Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª ÙˆØ§Ù„Ù…Ø­Ø³Ù† ÙˆØ¬Ø¯ÙˆÙ„ Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ¹Ù„Ù…:

```py
>>> from transformers import create_optimizer

>>> batch_size = 16
>>> num_epochs = 5
>>> num_train_steps = len(food["train"]) * num_epochs
>>> learning_rate = 3e-5
>>> weight_decay_rate = 0.01

>>> optimizer, lr_schedule = create_optimizer(
...     init_lr=learning_rateØŒ
...     num_train_steps=num_train_stepsØŒ
...     weight_decay_rate=weight_decay_rateØŒ
...     num_warmup_steps=0ØŒ
... )
```

Ø«Ù… Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ ViT Ù…Ø¹ [`TFAutoModelForImageClassification`] Ø¬Ù†Ø¨Ù‹Ø§ Ø¥Ù„Ù‰ Ø¬Ù†Ø¨ Ù…Ø¹ ØªØ®Ø·ÙŠØ· Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª:

```py
>>> from transformers import TFAutoModelForImageClassification

>>> model = TFAutoModelForImageClassification.from_pretrained(
...     checkpointØŒ
...     id2label=id2labelØŒ
...     label2id=label2idØŒ
... )
```

Ù‚Ù… Ø¨ØªØ­ÙˆÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ `tf.data.Dataset` Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`~datasets.Dataset.to_tf_dataset`] Ùˆ`data_collator` Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ:

```py
>>> # ØªØ­ÙˆÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù†Ø§ Ø¥Ù„Ù‰ tf.data.Dataset
>>> tf_train_dataset = food["train"].to_tf_dataset(
...     columns="pixel_values"ØŒ label_cols="label"ØŒ shuffle=TrueØŒ batch_size=batch_sizeØŒ collate_fn=data_collator
... )

>>> # ØªØ­ÙˆÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù†Ø§ Ø¥Ù„Ù‰ tf.data.Dataset
>>> tf_eval_dataset = food["test"].to_tf_dataset(
...     columns="pixel_values"ØŒ label_cols="label"ØŒ shuffle=TrueØŒ batch_size=batch_sizeØŒ collate_fn=data_collator
... )
```

Ù‚Ù… Ø¨ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… `compile()`

```py
>>> from tensorflow.keras.losses import SparseCategoricalCrossentropy

>>> loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
>>> model.compile(optimizer=optimizer, loss=loss)
```

Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø© Ù…Ù† Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª ÙˆØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬Ùƒ Ø¥Ù„Ù‰ ðŸ¤— HubØŒ Ø§Ø³ØªØ®Ø¯Ù… [Keras callbacks] (../main_classes/keras_callbacks).

Ù…Ø±Ø± ÙˆØ¸ÙŠÙØ© `compute_metrics` Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ Ø¥Ù„Ù‰ [KerasMetricCallback] (../main_classes/keras_callbacks#transformers.KerasMetricCallback)ØŒ

ÙˆØ§Ø³ØªØ®Ø¯Ù… [PushToHubCallback] (../main_classes/keras_callbacks#transformers.PushToHubCallback) Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:

```py
>>> from transformers.keras_callbacks import KerasMetricCallback, PushToHubCallback

>>> metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_eval_dataset)
>>> push_to_hub_callback = PushToHubCallback(
...     output_dir="food_classifier"ØŒ
...     tokenizer=image_processorØŒ
...     save_strategy="no"ØŒ
... )
>>> callbacks = [metric_callback, push_to_hub_callback]
```

Ø£Ø®ÙŠØ±Ù‹Ø§ØŒ Ø£Ù†Øª Ù…Ø³ØªØ¹Ø¯ Ù„ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬Ùƒ! Ø§ØªØµÙ„ Ø¨Ù€ `fit()` Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØµØ­Ø© Ø§Ù„Ø®Ø§ØµØ© Ø¨ÙƒØŒ ÙˆØ¹Ø¯Ø¯ Ø§Ù„Ø­Ù‚Ø¨Ø§ØªØŒ

ÙˆØ§Ø³ØªØ¯Ø¹Ø§Ø¡Ø§Øª Ø§Ù„Ø±Ø¬ÙˆØ¹ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ Ù„Ø¶Ø¨Ø· Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:

```py
>>> model.fit(tf_train_dataset, validation_data=tf_eval_dataset, epochs=num_epochs, callbacks=callbacks)
Ø­Ù‚Ø¨Ø© 1/5
250/250 [==============================] - 313s 1s/step - loss: 2.5623 - val_loss: 1.4161 - accuracy: 0.9290
Ø­Ù‚Ø¨Ø© 2/5
250/250 [==============================] - 265s 1s/step - loss: 0.9181 - val_loss: 0.6808 - accuracy: 0.9690
Ø­Ù‚Ø¨Ø© 3/5
250/250 [==============================] - 252s 1s/step - loss: 0.3910 - val_loss: 0.4303 - accuracy: 0.9820
Ø­Ù‚Ø¨Ø© 4/5
250/250 [==============================] - 251s 1s/step - loss: 0.2028 - val_loss: 0.3191 - accuracy: 0.9900
Ø­Ù‚Ø¨Ø© 5/5
250/250 [==============================] - 238s 949ms/step - loss: 0.1232 - val_loss: 0.3259 - accuracy: 0.9890
```

ØªÙ‡Ø§Ù†ÙŠÙ†Ø§! Ù„Ù‚Ø¯ Ø¶Ø¨Ø·Øª Ù†Ù…ÙˆØ°Ø¬Ùƒ ÙˆØ´Ø§Ø±ÙƒØªÙ‡ Ø¹Ù„Ù‰ ðŸ¤— Hub. ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¢Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ Ù„Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬!

Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø«Ø§Ù„ Ø£ÙƒØ«Ø± ØªÙØµÙŠÙ„Ø§Ù‹ Ø­ÙˆÙ„ ÙƒÙŠÙÙŠØ© Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ Ù„ØªØµÙ†ÙŠÙ Ø§Ù„ØµÙˆØ±ØŒ Ø±Ø§Ø¬Ø¹ Ø§Ù„Ø¯ÙØªØ± Ø§Ù„Ù…Ø°ÙƒØ±Ø© PyTorch Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„ [Ù‡Ù†Ø§] (https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb).

## Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬

Ø±Ø§Ø¦Ø¹ØŒ Ø§Ù„Ø¢Ù† Ø¨Ø¹Ø¯ Ø£Ù† Ø¶Ø¨Ø·Øª Ù†Ù…ÙˆØ°Ø¬Ù‹Ø§ØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ Ù„Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬!

Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ ØµÙˆØ±Ø© ØªØ±ÙŠØ¯ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø¹Ù„ÙŠÙ‡Ø§:

```py
>>> ds = load_dataset("food101"ØŒ split="validation[:10]")
>>> image = ds["image"][0]
```

Ø£Ø¨Ø³Ø· Ø·Ø±ÙŠÙ‚Ø© Ù„ØªØ¬Ø±Ø¨Ø© Ù†Ù…ÙˆØ°Ø¬Ùƒ Ø§Ù„Ù…Ø¶Ø¨ÙˆØ· Ù„Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ù‡ÙŠ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ ÙÙŠ [`pipeline`]. Ù‚Ù… Ø¨ØªÙ†ÙÙŠØ° `pipeline` Ù„ØªØµÙ†ÙŠÙ Ø§Ù„ØµÙˆØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ÙƒØŒ ÙˆÙ…Ø±Ø± ØµÙˆØ±ØªÙƒ Ø¥Ù„ÙŠÙ‡:

```py
>>> from transformers import pipeline

>>> classifier = pipeline("image-classification"ØŒ model="my_awesome_food_model")
>>> classifier(image)
[{'score': 0.31856709718704224ØŒ 'label': 'beignets'}ØŒ
{'score': 0.015232225880026817ØŒ 'label': 'bruschetta'}ØŒ
{'score': 0.01519392803311348ØŒ 'label': 'chicken_wings'}ØŒ
{'score': 0.013022331520915031ØŒ 'label': 'pork_chop'}ØŒ
{'score': 0.012728818692266941ØŒ 'label': 'prime_rib'}]
```

ÙŠÙ…ÙƒÙ†Ùƒ Ø£ÙŠØ¶Ù‹Ø§ ÙŠØ¯ÙˆÙŠÙ‹Ø§ ØªÙƒØ±Ø§Ø± Ù†ØªØ§Ø¦Ø¬ `pipeline` Ø¥Ø°Ø§ Ø£Ø±Ø¯Øª:

Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ù…Ø¹Ø§Ù„Ø¬ ØµÙˆØ±Ø© Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© ÙˆØ¥Ø±Ø¬Ø§Ø¹ `input` ÙƒØ±Ù…ÙˆØ² PyTorch:

```py
>>> from transformers import AutoImageProcessor
>>> import torch

>>> image_processor = AutoImageProcessor.from_pretrained("my_awesome_food_model")
>>> inputs = image_processor(image, return_tensors="pt")
```

Ù…Ø±Ø± Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ø¥Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ£Ø¹Ø¯ Ø§Ù„Ù„ÙˆØºØ§Ø±ÙŠØªÙ…Ø§Øª:

```py
>>> from transformers import AutoModelForImageClassification

>>> model = AutoModelForImageClassification.from_pretrained("my_awesome_food_model")
>>> with torch.no_grad():
...     logits = model(**inputs).logits
```

Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ Ù…Ø¹ Ø£Ø¹Ù„Ù‰ Ø§Ø­ØªÙ…Ø§Ù„ØŒ ÙˆØ§Ø³ØªØ®Ø¯Ù… ØªØ®Ø·ÙŠØ· `id2label` Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„ØªØ­ÙˆÙŠÙ„Ù‡ Ø¥Ù„Ù‰ ØªØµÙ†ÙŠÙ:

```py
>>> predicted_label = logits.argmax(-1).item()
>>> model.config.id2label[predicted_label]
'beignets'
```

Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ù…Ø¹Ø§Ù„Ø¬ ØµÙˆØ±Ø© Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© ÙˆØ¥Ø±Ø¬Ø§Ø¹ `input` ÙƒØ±Ù…ÙˆØ² TensorFlow:

```py
>>> from transformers import AutoImageProcessor

>>> image_processor = AutoImageProcessor.from_pretrained("MariaK/food_classifier")
>>> inputs = image_processor(image, return_tensors="tf")
```

Ù…Ø±Ø± Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ø¥Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ£Ø¹Ø¯ Ø§Ù„Ù„ÙˆØºØ§Ø±ÙŠØªÙ…Ø§Øª:

```py
>>> from transformers import TFAutoModelForImageClassification

>>> model = TFAutoModelForImageClassification.from_pretrained("MariaK/food_classifier")
>>> logits = model(**inputs).logits
```

Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ ØªØµÙ†ÙŠÙ Ù…ØªÙˆÙ‚Ø¹ Ø¨Ø£Ø¹Ù„Ù‰ Ø§Ø­ØªÙ…Ø§Ù„ØŒ ÙˆØ§Ø³ØªØ®Ø¯Ù… ØªØ®Ø·ÙŠØ· `id2label` Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„ØªØ­ÙˆÙŠÙ„Ù‡ Ø¥Ù„Ù‰ ØªØµÙ†ÙŠÙ:

```py
>>> predicted_class_id = int(tf.math.argmax(logits, axis=-1)[0])
>>> model.config.id2label[predicted_class_id]
'beignets'
```