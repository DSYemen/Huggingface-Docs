## ุชุญููู ุงููุต ุฅูู ููุงู 

ุชุญููู ุงููุต ุฅูู ููุงู (TTS) ูู ูููุฉ ุฅูุดุงุก ููุงู ุทุจูุนู ูู ูุต ููุชูุจุ ุญูุซ ูููู ุชูููุฏ ุงูููุงู ุจุนุฏุฉ ูุบุงุช ููุนุฏุฉ ูุชุญุฏุซูู. ููุงู ุงูุนุฏูุฏ ูู ููุงุฐุฌ ุชุญููู ุงููุต ุฅูู ููุงู ุงููุชุงุญุฉ ุญุงูููุง ูู ููุชุจุฉ ๐ค Transformersุ ูุซู Bark ูMMS ูVITS ูSpeechT5.

ููููู ุจุณูููุฉ ุฅูุดุงุก ุตูุช ุจุงุณุชุฎุฏุงู ุฎุท ุงูุฃูุงุจูุจ "text-to-audio" (ุฃู "text-to-speech"). ูููู ูุจุนุถ ุงูููุงุฐุฌุ ูุซู Barkุ ุฃูุถูุง ุฃู ุชููู ูุดุฑูุทุฉ ูุชูููุฏ ุงุชุตุงูุงุช ุบูุฑ ููุธูุฉ ูุซู ุงูุถุญู ูุงูุชููุฏ ูุงูุจูุงุกุ ุฃู ุญุชู ุฅุถุงูุฉ ุงูููุณููู.

ูููุง ููู ูุซุงู ุนูู ููููุฉ ุงุณุชุฎุฏุงู ุฎุท ุฃูุงุจูุจ "text-to-speech" ูุน Bark:

```py
>>> from transformers import pipeline

>>> pipe = pipeline("text-to-speech", model="suno/bark-small")
>>> text = "[clears throat] This is a test ... and I just took a long pause."
>>> output = pipe(text)
```

ูุฐู ููุชุทูุงุช ูู ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉ ุงูุชู ููููู ุงุณุชุฎุฏุงููุง ููุงุณุชูุงุน ุฅูู ุงูุตูุช ุงููุงุชุฌ ูู ุฏูุชุฑ ุงูููุงุญุธุงุช:

```python
>>> from IPython.display import Audio
>>> Audio(output["audio"], rate=output["sampling_rate"])
```

ููุญุตูู ุนูู ุงููุฒูุฏ ูู ุงูุฃูุซูุฉ ุนูู ูุง ูููู ุฃู ุชูุนูู Bark ูููุงุฐุฌ TTS ุงูุฃุฎุฑู ุงูููุฏุฑุจุฉ ูุณุจููุงุ ุฑุงุฌุน [ุฏูุฑุฉ ุงูุตูุช](https://huggingface.co/learn/audio-course/chapter6/pre-trained_models).

ุฅุฐุง ููุช ุชุฑุบุจ ูู ุถุจุท ูููุฐุฌ TTSุ ูุฅู ุงููููุฐุฌูู ุงููุญูุฏูู ูุชุญููู ุงููุต ุฅูู ููุงู ุงููุชุงุญูู ุญุงูููุง ูู ููุชุจุฉ ๐ค Transformers ููุง SpeechT5 ูFastSpeech2Conformerุ ุนูู ุงูุฑุบู ูู ุฃูู ุณูุชู ุฅุถุงูุฉ ุงููุฒูุฏ ูู ุงููุณุชูุจู. ุชู ุชุฏุฑูุจ SpeechT5 ูุณุจููุง ุนูู ูุฒูุฌ ูู ุจูุงูุงุช ุชุญููู ุงูููุงู ุฅูู ูุต ูุชุญููู ุงููุต ุฅูู ููุงูุ ููุง ูุณูุญ ูู ุจุชุนูู ูุณุงุญุฉ ููุญุฏุฉ ูู ุงูุชูุซููุงุช ุงููุฎููุฉ ุงููุดุชุฑูุฉ ุจูู ุงููุต ูุงูููุงู. ููุฐุง ูุนูู ุฃูู ูููู ุถุจุท ููุณ ุงููููุฐุฌ ุงูููุฏุฑุจ ูุณุจููุง ูููุงู ูุฎุชููุฉ. ุนูุงูุฉ ุนูู ุฐููุ ูุฏุนู SpeechT5 ูุชุญุฏุซูู ูุชุนุฏุฏูู ูู ุฎูุงู ุชุถููู ุงููุชููู x.

ููุถุญ ุจุงูู ูุฐุง ุงูุฏููู ููููุฉ:

1. ุถุจุท ูููุฐุฌ SpeechT5 ุงูุฐู ุชู ุชุฏุฑูุจู ูู ุงูุฃุตู ุนูู ุงูููุงู ุจุงููุบุฉ ุงูุฅูุฌููุฒูุฉ ุนูู ุงูุฌุฒุก ุงููุฑุนู ุจุงููุบุฉ ุงูููููุฏูุฉ (`nl`) ูู ูุฌููุนุฉ ุจูุงูุงุช VoxPopuli.
2. ุงุณุชุฎุฏุงู ุงููููุฐุฌ ุงููุญุณู ููุงุณุชูุชุงุฌ ุจุทุฑููุชูู: ุจุงุณุชุฎุฏุงู ุฎุท ุงูุฃูุงุจูุจ ุฃู ูุจุงุดุฑุฉ.

ูุจู ุงูุจุฏุกุ ุชุฃูุฏ ูู ุชุซุจูุช ุฌููุน ุงูููุชุจุงุช ุงูุถุฑูุฑูุฉ:

```bash
pip install datasets soundfile speechbrain accelerate
```

ูู ุจุชุซุจูุช ๐ค Transformers ูู ุงููุตุฏุฑ ุญูุซ ูู ูุชู ุฏูุฌ ุฌููุน ููุฒุงุช SpeechT5 ูู ุฅุตุฏุงุฑ ุฑุณูู ุจุนุฏ:

```bash
pip install git+https://github.com/huggingface/transformers.git
```

<Tip>

ูุฅููุงู ูุฐุง ุงูุฏูููุ ุณุชุญุชุงุฌ ุฅูู ูุญุฏุฉ ูุนุงูุฌุฉ ุฑุณููุงุช (GPU). ุฅุฐุง ููุช ุชุนูู ูู ุฏูุชุฑ ููุงุญุธุงุชุ ูุดุบูู ุงูุณุทุฑ ุงูุชุงูู ููุชุญูู ูู ุชููุฑ ูุญุฏุฉ GPU:

```bash
!nvidia-smi
```

ุฃู ุจุฏูู ููุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณููุงุช AMD:

```bash
!rocm-smi
```

</Tip>

ูุญู ูุดุฌุนู ุนูู ุชุณุฌูู ุงูุฏุฎูู ุฅูู ุญุณุงุจ Hugging Face ุงูุฎุงุต ุจู ูุชุญููู ููุดุงุฑูุฉ ูููุฐุฌู ูุน ุงููุฌุชูุน. ุนูุฏูุง ููุทูุจ ููู ุฐููุ ุฃุฏุฎู ุฑูุฒู ููุชุณุฌูู:

```py
>>> from huggingface_hub import notebook_login

>>> notebook_login()
```

## ุชุญููู ูุฌููุนุฉ ุงูุจูุงูุงุช

VoxPopuli ุนุจุงุฑุฉ ุนู ูุฌููุนุฉ ุจูุงูุงุช ุตูุชูุฉ ูุชุนุฏุฏุฉ ุงููุบุงุช ูุงุณุนุฉ ุงููุทุงู ุชุชููู ูู ุจูุงูุงุช ูุณุชุฎุฑุฌุฉ ูู ุชุณุฌููุงุช ุฃุญุฏุงุซ ุงูุจุฑููุงู ุงูุฃูุฑูุจู ูู ุนุงู 2009 ุฅูู ุนุงู 2020. ูุญุชูู ุนูู ุจูุงูุงุช ุตูุชูุฉ-ูุตูุฉ ูููุณูุฉ ูู 15 ูุบุฉ ุฃูุฑูุจูุฉ. ูู ูุฐุง ุงูุฏูููุ ูุณุชุฎุฏู ุงูุฌุฒุก ุงููุฑุนู ุจุงููุบุฉ ุงูููููุฏูุฉุ ูููู ููููู ุงุฎุชูุงุฑ ุฌุฒุก ูุฑุนู ุขุฎุฑ.

ูุงุญุธ ุฃู VoxPopuli ุฃู ุฃู ูุฌููุนุฉ ุจูุงูุงุช ุฃุฎุฑู ููุชุนุฑู ุงูุชููุงุฆู ุนูู ุงูููุงู (ASR) ูุฏ ูุง ุชููู ุงูุฎูุงุฑ ุงูุฃูุณุจ ูุชุฏุฑูุจ ููุงุฐุฌ TTS. ุงูููุฒุงุช ุงูุชู ุชุฌุนููุง ูููุฏุฉ ูู ASRุ ูุซู ุงูุถูุถุงุก ุงูุฎูููุฉ ุงูููุฑุทุฉุ ุบูุฑ ูุฑุบูุจ ูููุง ุนุงุฏุฉู ูู TTS. ููุน ุฐููุ ูููู ุฃู ูููู ุงูุนุซูุฑ ุนูู ูุฌููุนุงุช ุจูุงูุงุช TTS ุนุงููุฉ ุงูุฌูุฏุฉ ููุชุนุฏุฏุฉ ุงููุบุงุช ููุชุนุฏุฏุฉ ุงููุชุญุฏุซูู ุฃูุฑูุง ุตุนุจูุง ููุบุงูุฉ.

ุฏุนูุง ูุญูู ุงูุจูุงูุงุช:

```py
>>> from datasets import load_dataset, Audio

>>> dataset = load_dataset("facebook/voxpopuli", "nl", split="train")
>>> len(dataset)
20968
```

20968 ูุซุงู ูุฌุจ ุฃู ูููู ูุงูููุง ููุถุจุท ุงูุฏููู. ูุชููุน SpeechT5 ุฃู ูููู ููุฌููุนุฉ ุงูุจูุงูุงุช ูุนุฏู ุฃุฎุฐ ุนููุงุช ูุจูุบ 16 ูููู ูุฑุชุฒุ ูุฐุง ุชุฃูุฏ ูู ุฃู ุงูุฃูุซูุฉ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุชูุจู ูุฐุง ุงูุดุฑุท:

```py
dataset = dataset.cast_column("audio", Audio(sampling_rate=16000))
```

## ูุนุงูุฌุฉ ุงูุจูุงูุงุช ูุณุจููุง

ุฏุนูุง ูุจุฏุฃ ุจุชุญุฏูุฏ ููุทุฉ ุชูุชูุด ุงููููุฐุฌ ูุชุญููููุง ูุชุญููู ุงููุนุงูุฌ ุงูููุงุณุจ:

```py
>>> from transformers import SpeechT5Processor

>>> checkpoint = "microsoft/speecht5_tts"
>>> processor = SpeechT5Processor.from_pretrained(checkpoint)
```

### ุชูุธูู ุงููุต ูุชูููุฏู SpeechT5

ุงุจุฏุฃ ุจุชูุธูู ุจูุงูุงุช ุงููุต. ุณุชุญุชุงุฌ ุฅูู ุงูุฌุฒุก ุงููุนุงูุฌ ูู ุงููุนุงูุฌ ููุนุงูุฌุฉ ุงููุต:

```py
>>> tokenizer = processor.tokenizer
```

ุชุญุชูู ุฃูุซูุฉ ูุฌููุนุฉ ุงูุจูุงูุงุช ุนูู ููุฒุงุช `raw_text` ู`normalized_text`. ุนูุฏ ุงุชุฎุงุฐ ูุฑุงุฑ ุจุดุฃู ุงูููุฒุฉ ุงูุชู ุณูุชู ุงุณุชุฎุฏุงููุง ูุฅุฏุฎุงู ูุตูุ ุถุน ูู ุงุนุชุจุงุฑู ุฃู ูุนุงูุฌ SpeechT5 ูุง ูุญุชูู ุนูู ุฃู ุฑููุฒ ููุฃุฑูุงู. ูู `normalized_text`ุ ูุชู ูุชุงุจุฉ ุงูุฃุฑูุงู ููุต. ูุจุงูุชุงููุ ููู ููุงุณุจ ุจุดูู ุฃูุถูุ ูููุตู ุจุงุณุชุฎุฏุงู `normalized_text` ูุฅุฏุฎุงู ูุตู.

ูุธุฑูุง ูุฃู SpeechT5 ุชู ุชุฏุฑูุจู ุนูู ุงููุบุฉ ุงูุฅูุฌููุฒูุฉุ ููุฏ ูุง ูุชุนุฑู ุนูู ุฃุญุฑู ูุนููุฉ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูููููุฏูุฉ. ุฅุฐุง ุชูุฑูุช ููุง ููุ ูุณูุชู ุชุญููู ูุฐู ุงูุฃุญุฑู ุฅูู ุฑููุฒ `<unk>`. ููุน ุฐููุ ูู ุงููุบุฉ ุงูููููุฏูุฉุ ุชูุณุชุฎุฏู ุฃุญุฑู ูุนููุฉ ูุซู `ร` ููุชุดุฏูุฏ ุนูู ุงูููุงุทุน. ููุญูุงุธ ุนูู ูุนูู ุงููุตุ ูููููุง ุงุณุชุจุฏุงู ูุฐุง ุงูุญุฑู ุจู "a" ุนุงุฏู.

ูุชุญุฏูุฏ ุงูุฑููุฒ ุบูุฑ ุงููุฏุนููุฉุ ุงุณุชุฎุฑุฌ ุฌููุน ุงูุฃุญุฑู ุงููุฑูุฏุฉ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุจุงุณุชุฎุฏุงู `SpeechT5Tokenizer` ุงูุฐู ูุนูู ูุน ุงูุฃุญุฑู ูุฑููุฒ. ููููุงู ุจุฐููุ ุงูุชุจ ุฏุงูุฉ `extract_all_chars` ุงูุชู ุชููู ุจุชูุตูู ุงููุณุฎ ุงููุตูุฉ ูู ุฌููุน ุงูุฃูุซูุฉ ูู ุณูุณูุฉ ูุงุญุฏุฉ ูุชุญููููุง ุฅูู ูุฌููุนุฉ ูู ุงูุฃุญุฑู.

ุชุฃูุฏ ูู ุชุนููู `batched=True` ู`batch_size=-1` ูู `dataset.map()` ุจุญูุซ ุชููู ุฌููุน ุงููุณุฎ ุงููุตูุฉ ูุชุงุญุฉ ูุฑุฉ ูุงุญุฏุฉ ูุฏุงูุฉ ุงูุฎุฑูุทุฉ.

```py
>>> def extract_all_chars(batch):
...     all_text = " ".join(batch["normalized_text"])
...     vocab = list(set(all_text))
...     return {"vocab": [vocab], "all_text": [all_text]}


>>> vocabs = dataset.map(
...     extract_all_chars,
...     batched=True,
...     batch_size=-1,
...     keep_in_memory=True,
...     remove_columns=dataset.column_names,
... )

>>> dataset_vocab = set(vocabs["vocab"][0])
>>> tokenizer_vocab = {k for k, _ in tokenizer.get_vocab().items()}
```

ุงูุขู ูุฏูู ูุฌููุนุชุงู ูู ุงูุฃุญุฑู: ูุงุญุฏุฉ ุจููุฑุฏุงุช ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ูุงูุฃุฎุฑู ุจููุฑุฏุงุช ูู ุงููุนุงูุฌ. ูุชุญุฏูุฏ ุฃู ุฃุญุฑู ุบูุฑ ูุฏุนููุฉ ูู ูุฌููุนุฉ ุงูุจูุงูุงุชุ ููููู ุฃุฎุฐ ุงููุฑู ุจูู ูุงุชูู ุงููุฌููุนุชูู. ุณุชุชููู ุงููุฌููุนุฉ ุงููุงุชุฌุฉ ูู ุงูุฃุญุฑู ุงูููุฌูุฏุฉ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ูููู ููุณ ูู ุงููุนุงูุฌ.

```py
>>> dataset_vocab - tokenizer_vocab
{' ', 'ร', 'รง', 'รจ', 'รซ', 'รญ', 'รฏ', 'รถ', 'รผ'}
```

ููุชุนุงูู ูุน ุงูุฃุญุฑู ุบูุฑ ุงููุฏุนููุฉ ุงูุชู ุชู ุชุญุฏูุฏูุง ูู ุงูุฎุทูุฉ ุงูุณุงุจูุฉุ ุญุฏุฏ ุฏุงูุฉ ุชููู ุจุชุนููู ูุฐู ุงูุฃุญุฑู ุฅูู ุฑููุฒ ุตุงูุญุฉ. ูุงุญุธ ุฃู ุงููุณุงูุงุช ูุชู ุงุณุชุจุฏุงููุง ุจุงููุนู ุจู `โ` ูู ุงููุนุงูุฌ ููุง ุชุญุชุงุฌ ุฅูู ุงูุชุนุงูู ูุนูุง ุจุดูู ูููุตู.

```py
>>> replacements = [
...     ("ร", "a"),
...     ("รง", "c"),
...     ("รจ", "e"),
...     ("รซ", "e"),
...     ("รญ", "i"),
...     ("รฏ", "i"),
...     ("รถ", "o"),
...     ("รผ", "u"),
... ]


>>> def cleanup_text(inputs):
...     for src, dst in replacements:
...         inputs["normalized_text"] = inputs["normalized_text"].replace(src, dst)
...     return inputs


>>> dataset = dataset.map(cleanup_text)
```

ุงูุขู ุจุนุฏ ุฃู ุชุนุงููุช ูุน ุงูุฃุญุฑู ุงูุฎุงุตุฉ ูู ุงููุตุ ุญุงู ุงูููุช ููุชุฑููุฒ ุนูู ุจูุงูุงุช ุงูุตูุช.
### ุงููุชุญุฏุซูู

ุชุชุถูู ูุฌููุนุฉ ุจูุงูุงุช VoxPopuli ุฎุทุงุจุงุช ูู ูุชุญุฏุซูู ูุชุนุฏุฏููุ ูููู ูู ุนุฏุฏ ุงููุชุญุฏุซูู ุงูููุซููู ูู ูุฌููุนุฉ ุงูุจูุงูุงุชุ ูุชุญุฏูุฏ ุฐููุ ูููููุง ุญุณุงุจ ุนุฏุฏ ุงููุชุญุฏุซูู ุงููููุฒูู ูุนุฏุฏ ุงูุฃูุซูุฉ ุงูุชู ูุณุงูู ุจูุง ูู ูุชุญุฏุซ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช. ุจูุนุฑูุฉ ุฃู ุฅุฌูุงูู ุนุฏุฏ ุงูุฃูุซูุฉ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ูุจูุบ 20,968ุ ุณุชููุญูุง ูุฐู ุงููุนูููุงุช ููููุง ุฃูุถู ูุชูุฒูุน ุงููุชุญุฏุซูู ูุงูุฃูุซูุฉ ูู ุงูุจูุงูุงุช.

ุนู ุทุฑูู ุฑุณู ูุฎุทุท ุชูุฒูุนูุ ููููู ูุนุฑูุฉ ููุฏุงุฑ ุงูุจูุงูุงุช ุงููุชููุฑุฉ ููู ูุชุญุฏุซ.

ููุดู ุงููุฎุทุท ุงูุชูุฒูุนู ุฃู ุญูุงูู ุซูุซ ุงููุชุญุฏุซูู ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ูุฏููู ุฃูู ูู 100 ูุซุงูุ ูู ุญูู ุฃู ุญูุงูู ุนุดุฑุฉ ูุชุญุฏุซูู ูุฏููู ุฃูุซุฑ ูู 500 ูุซุงู. ูุชุญุณูู ููุงุกุฉ ุงูุชุฏุฑูุจ ูุชุญููู ุงูุชูุงุฒู ูู ูุฌููุนุฉ ุงูุจูุงูุงุชุ ูููููุง ุชูููุฏ ุงูุจูุงูุงุช ุจุงููุชุญุฏุซูู ุงูุฐูู ูุฏููู ูุง ุจูู 100 ู400 ูุซุงู.

ุฏุนููุง ูุชุญูู ูู ุนุฏุฏ ุงููุชุญุฏุซูู ุงููุชุจููู:

ููุฑู ูู ุนุฏุฏ ุงูุฃูุซูุฉ ุงููุชุจููุฉ:

ุชุจูู ูุฏูู ุฃูู ุจูููู ูู 10,000 ูุซุงู ูู ุญูุงูู 40 ูุชุญุฏุซูุง ูููุฒูุงุ ููู ูุง ูุฌุจ ุฃู ูููู ูุงูููุง. ูุงุญุธ ุฃูู ูุฏ ูููู ูุฏู ุจุนุถ ุงููุชุญุฏุซูู ุงูุฐูู ูุฏููู ุนุฏุฏ ูููู ูู ุงูุฃูุซูุฉ ูู ุงููุงูุน ุงููุฒูุฏ ูู ุงูุตูุช ุงููุชุงุญ ุฅุฐุง ูุงูุช ุงูุฃูุซูุฉ ุทูููุฉ. ููุน ุฐููุ ูุฅู ุชุญุฏูุฏ ุฅุฌูุงูู ูููุฉ ุงูุตูุช ููู ูุชุญุฏุซ ูุชุทูุจ ูุญุต ูุฌููุนุฉ ุงูุจูุงูุงุช ุจุฃููููุงุ ููู ุนูููุฉ ุชุณุชุบุฑู ููุชูุง ุทูููุงู ูุชูุทูู ุนูู ุชุญููู ููู ุชุดููุฑ ูู ููู ุตูุชู. ูุฐููุ ูุฑุฑูุง ุชุฎุทู ูุฐู ุงูุฎุทูุฉ ููุง.

### ุชุถููู ุงููุชุญุฏุซ

ูุชูููู ูููุฐุฌ TTS ูู ุงูุชูููุฒ ุจูู ูุชุญุฏุซูู ูุชุนุฏุฏููุ ุณุชุญุชุงุฌ ุฅูู ุฅูุดุงุก ุชุถููู ูุชุญุฏุซ ููู ูุซุงู. ุฅู ุชุถููู ุงููุชุญุฏุซ ูู ุฅุฏุฎุงู ุฅุถุงูู ูู ุงููููุฐุฌ ุงูุฐู ููุชูุท ุฎุตุงุฆุต ุตูุช ูุชุญุฏุซ ูุนูู.

ูุฅูุดุงุก ูุฐู ุงูุชุถูููุงุช ูููุชุญุฏุซููุ ุงุณุชุฎุฏู ูููุฐุฌ [spkrec-xvect-voxceleb](https://huggingface.co/speechbrain/spkrec-xvect-voxceleb) ุงูููุฏุฑุจ ูุณุจููุง ูู SpeechBrain.

ุฃูุดุฆ ุฏุงูุฉ `create_speaker_embedding()` ุงูุชู ุชุฃุฎุฐ ููุฌุฉ ุตูุช ุฅุฏุฎุงู ูุชุฎุฑุฌ ูุชุฌููุง ูููููุง ูู 512 ุนูุตุฑูุง ูุญุชูู ุนูู ุชุถููู ุงููุชุญุฏุซ ุงูููุงุจู.

ูู ุงูููู ููุงุญุธุฉ ุฃู ูููุฐุฌ `speechbrain/spkrec-xvect-voxceleb` ุชู ุชุฏุฑูุจู ุนูู ุงูููุงู ุจุงููุบุฉ ุงูุฅูุฌููุฒูุฉ ูู ูุฌููุนุฉ ุจูุงูุงุช VoxCelebุ ูู ุญูู ุฃู ุฃูุซูุฉ ุงูุชุฏุฑูุจ ูู ูุฐุง ุงูุฏููู ุจุงููุบุฉ ุงูููููุฏูุฉ. ูู ุญูู ุฃููุง ูุนุชูุฏ ุฃู ูุฐุง ุงููููุฐุฌ ุณูุธู ูููุฏ ุชุถูููุงุช ูุชุญุฏุซ ูุนูููุฉ ููุฌููุนุฉ ุงูุจูุงูุงุช ุงูููููุฏูุฉ ุงูุฎุงุตุฉ ุจูุงุ ููุฏ ูุง ูููู ูุฐุง ุงูุงูุชุฑุงุถ ุตุญูุญูุง ูู ุฌููุน ุงูุญุงูุงุช.

ููุญุตูู ุนูู ูุชุงุฆุฌ ูุซุงููุฉุ ููุตู ุจุชุฏุฑูุจ ูููุฐุฌ X-vector ุนูู ููุงู ุงููุฏู ุฃููุงู. ุณูุถูู ุฐูู ุฃู ุงููููุฐุฌ ูุงุฏุฑ ุจุดูู ุฃูุถู ุนูู ุงูุชูุงุท ุฎุตุงุฆุต ุงูุตูุช ุงููุฑูุฏุฉ ุงูููุฌูุฏุฉ ูู ุงููุบุฉ ุงูููููุฏูุฉ.

### ูุนุงูุฌุฉ ูุฌููุนุฉ ุงูุจูุงูุงุช

ุฃุฎูุฑูุงุ ุฏุนููุง ูููู ุจูุนุงูุฌุฉ ุงูุจูุงูุงุช ุฅูู ุงูุชูุณูู ุงูุฐู ูุชููุนู ุงููููุฐุฌ. ูู ุจุฅูุดุงุก ุฏุงูุฉ `prepare_dataset` ุชุฃุฎุฐ ูุซุงููุง ูุงุญุฏูุง ูุชุณุชุฎุฏู ูุงุฆู `SpeechT5Processor` ูุชุญููู ูุต ุงูุฅุฏุฎุงู ุฅูู ุฑููุฒ ูุชุญููู ุงูุตูุช ุงููุณุชูุฏู ุฅูู ูุฎุทุท Mel-spectrogram. ูุฌุจ ุฃู ุชุถูู ุฃูุถูุง ุชุถูููุงุช ุงููุชุญุฏุซูู ูุฅุฏุฎุงู ุฅุถุงูู.

ุชุญูู ูู ุตุญุฉ ุงููุนุงูุฌุฉ ุนู ุทุฑูู ุงููุธุฑ ูู ูุซุงู ูุงุญุฏ:

ููุจุบู ุฃู ุชููู ุชุถูููุงุช ุงููุชุญุฏุซูู ุนุจุงุฑุฉ ุนู ูุชุฌู ูููู ูู 512 ุนูุตุฑูุง:

ููุจุบู ุฃู ุชููู ุงูุชุณููุงุช ูุฎุทุท Mel-spectrogram ูุน 80 ูุงูุฐุฉ Mel.

ููุงุญุธุฉ ุฌุงูุจูุฉ: ุฅุฐุง ูุฌุฏุช ุฃู ูุฐุง ุงููุฎุทุท ุงูุทููู ูุฑุจููุงุ ููุฏ ูููู ุฐูู ุจุณุจุจ ูุนุฑูุชู ุจุงุชูุงููุฉ ูุถุน ุงูุชุฑุฏุฏุงุช ุงูููุฎูุถุฉ ูู ุงูุฃุณูู ูุงูุชุฑุฏุฏุงุช ุงูุนุงููุฉ ูู ุงูุฌุฒุก ุงูุนููู ูู ุงููุฎุทุท. ููุน ุฐููุ ุนูุฏ ุฑุณู ุงููุฎุทุทุงุช ุงูุทูููุฉ ูุตูุฑุฉ ุจุงุณุชุฎุฏุงู ููุชุจุฉ matplotlibุ ูุชู ููุจ ุงููุญูุฑ y ููุธูุฑ ุงููุฎุทุท ุงูุทููู ููููุจูุง.

ุงูุขู ูู ุจุชุทุจูู ุฏุงูุฉ ุงููุนุงูุฌุฉ ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุจุฃููููุง. ุณูุณุชุบุฑู ุฐูู ูุง ุจูู 5 ู10 ุฏูุงุฆู.

ุณุชุดุงูุฏ ุชุญุฐูุฑูุง ูููุฏ ุจุฃู ุจุนุถ ุงูุฃูุซูุฉ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุฃุทูู ูู ุทูู ุงูุฅุฏุฎุงู ุงูุฃูุตู ุงูุฐู ูููู ุฃู ูุชุนุงูู ูุนู ุงููููุฐุฌ (600 ุฑูุฒูุง). ุงุญุฐู ุชูู ุงูุฃูุซูุฉ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช. ููุง ูุฐูุจ ุฅูู ุฃุจุนุฏ ูู ุฐูู ูุญุชู ูุณูุญ ุจุฃุญุฌุงู ุฏูุนุงุช ุฃูุจุฑุ ูููู ุจุฅุฒุงูุฉ ุฃู ุดูุก ูุฒูุฏ ุนู 200 ุฑูุฒูุง.

ุจุนุฏ ุฐููุ ูู ุจุฅูุดุงุก ุชูุณูู ุฃุณุงุณู ููุชุฏุฑูุจ/ุงูุงุฎุชุจุงุฑ:

### ุฌุงูุน ุงูุจูุงูุงุช

ูู ุฃุฌู ุฏูุฌ ุฃูุซูุฉ ูุชุนุฏุฏุฉ ูู ุฏูุนุฉุ ููุฒูู ุชุญุฏูุฏ ุฌุงูุน ุจูุงูุงุช ูุฎุตุต. ุณูููู ุฌุงูุน ุงูุจูุงูุงุช ูุฐุง ุจููุก ุงูุชุณูุณูุงุช ุงูุฃูุตุฑ ุจุฑููุฒ ุงูููุกุ ููุง ูุถูู ุฃู ูููู ูุฌููุน ุงูุฃูุซูุฉ ููุณ ุงูุทูู. ุจุงููุณุจุฉ ุฅูู ุชุณููุงุช ุงููุฎุทุท ุงูุทูููุ ูุชู ุงุณุชุจุฏุงู ุงูุฃุฌุฒุงุก ุงูููููุกุฉ ุจุงููููุฉ ุงูุฎุงุตุฉ "-100". ุชุนูู ูุฐู ุงููููุฉ ุงูุฎุงุตุฉ ุงููููุฐุฌ ุจุชุฌุงูู ูุฐุง ุงูุฌุฒุก ูู ุงููุฎุทุท ุงูุทููู ุนูุฏ ุญุณุงุจ ููุฏุงู ุงููุฎุทุท ุงูุทููู.

ูู SpeechT5ุ ูุชู ุชูููู ุฅุฏุฎุงู ุงูุฌุฒุก ูู ุงูุชุฑููุฒ ูู ุงููููุฐุฌ ุจุนุงูู 2. ูุจุนุจุงุฑุฉ ุฃุฎุฑูุ ูุฅูู ูุชุฎูุต ูู ูู ุฎุทูุฉ ุฒูููุฉ ุฃุฎุฑู ูู ุงูุชุณูุณู ุงููุณุชูุฏู. ุจุนุฏ ุฐููุ ูุชูุจุฃ ูู ุงูุชุฑููุฒ ุจุชุณูุณู ูุจูุบ ุถุนู ุทููู. ูุธุฑูุง ูุฃู ุทูู ุงูุชุณูุณู ุงููุณุชูุฏู ุงูุฃุตูู ูุฏ ูููู ูุฑุฏููุงุ ูุฅู ุฌุงูุน ุงูุจูุงูุงุช ูุชุฃูุฏ ูู ุชูุฑูุจ ุงูุทูู ุงูุฃูุตู ููุฏูุนุฉ ูุฃุณูู ููููู ูุถุงุนููุง ููุนุฏุฏ 2.

ูู ุจุฅูุดุงุก ุฌุงูุน ุจูุงูุงุช:
## ุชุฏุฑูุจ ุงููููุฐุฌ

ูู ุจุชุญููู ุงููููุฐุฌ ุงูููุฏุฑุจ ูุณุจููุง ูู ููุณ ููุทุฉ ุงูุชูุชูุด ุงูุชู ุงุณุชุฎุฏูุชูุง ูุชุญููู ุงููุนุงูุฌ:

ูู ุจุชุนุทูู ุงูุฎูุงุฑ `use_cache=True` ููู ุบูุฑ ูุชูุงูู ูุน ุงูุชุฏุฑุฌ ุงูุญุงุณูุจู. ูู ุจุชุนุทููู ุฃุซูุงุก ุงูุชุฏุฑูุจ.

ูู ุจุชุนุฑูู ุญุฌุฌ ุงูุชุฏุฑูุจ. ููุงุ ูู ูููู ุจุญุณุงุจ ุฃู ููุงููุณ ุชูููู ุฃุซูุงุก ุนูููุฉ ุงูุชุฏุฑูุจ. ุจุฏูุงู ูู ุฐููุ ุณููุธุฑ ููุท ุฅูู ุงูุฎุณุงุฑุฉ:

```python
>>> from transformers import Seq2SeqTrainingArguments

>>> training_args = Seq2SeqTrainingArguments(
...     output_dir="speecht5_finetuned_voxpopuli_nl"ุ  # ูู ุจุชุบููุฑู ุฅูู ุงุณู ูุณุชูุฏุน ูู ุงุฎุชูุงุฑู
...     per_device_train_batch_size=4ุ
...     gradient_accumulation_steps=8ุ
...     learning_rate=1e-5ุ
...     warmup_steps=500ุ
...     max_steps=4000ุ
...     gradient_checkpointing=Trueุ
...     fp16=Trueุ
...     eval_strategy="steps"ุ
...     per_device_eval_batch_size=2ุ
...     save_steps=1000ุ
...     eval_steps=1000ุ
...     logging_steps=25ุ
...     report_to=["tensorboard"]ุ
...     load_best_model_at_end=Trueุ
...     greater_is_better=Falseุ
...     label_names=["labels"]ุ
...     push_to_hub=Trueุ
... )
```

ูู ุจุชูููุฐ ูุงุฆู `Trainer` ููุฑุฑ ุฅููู ุงููููุฐุฌ ููุฌููุนุฉ ุงูุจูุงูุงุช ููุฌูุน ุงูุจูุงูุงุช:

```py
>>> from transformers import Seq2SeqTrainer

>>> trainer = Seq2SeqTrainer(
...     args=training_argsุ
...     model=modelุ
...     train_dataset=dataset["train"]ุ
...     eval_dataset=dataset["test"]ุ
...     data_collator=data_collatorุ
...     tokenizer=processorุ
... )
```

ูุงูุขูุ ุฃูุช ูุณุชุนุฏ ูุจุฏุก ุงูุชุฏุฑูุจ! ุณูุณุชุบุฑู ุงูุชุฏุฑูุจ ุนุฏุฉ ุณุงุนุงุช. ูุงุนุชูุงุฏูุง ุนูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU) ูุฏููุ ููุฏ ุชูุงุฌู ุฎุทุฃ "ููุงุฏ ุงูุฐุงูุฑุฉ" CUDA ุนูุฏ ุจุฏุก ุงูุชุฏุฑูุจ. ูู ูุฐู ุงูุญุงูุฉุ ููููู ุชูููู `per_device_train_batch_size` ุจุดูู ุชุฏุฑูุฌู ุนู ุทุฑูู ุนูุงูู 2 ูุฒูุงุฏุฉ `gradient_accumulation_steps` ุจููุฏุงุฑ 2x ููุชุนููุถ.

```py
>>> trainer.train()
```

ูุงุณุชุฎุฏุงู ููุทุฉ ุงูุชูุชูุด ุงูุฎุงุตุฉ ุจู ูุน ุฎุท ุฃูุงุจูุจุ ุชุฃูุฏ ูู ุญูุธ ุงููุนุงูุฌ ูุน ููุทุฉ ุงูุชูุชูุด:

```py
>>> processor.save_pretrained("YOUR_ACCOUNT_NAME/speecht5_finetuned_voxpopuli_nl")
```

ุฃุฑุณู ุงููููุฐุฌ ุงูููุงุฆู ุฅูู ๐ค Hub:

```py
>>> trainer.push_to_hub()
```

## ุงูุงุณุชูุชุงุฌ

### ุงูุงุณุชูุชุงุฌ ุจุงุณุชุฎุฏุงู ุฎุท ุฃูุงุจูุจ

ุงูุขู ุจุนุฏ ุฃู ููุช ุจุถุจุท ูููุฐุฌูุ ููููู ุงุณุชุฎุฏุงูู ููุงุณุชูุชุงุฌ!

ุฃููุงูุ ุฏุนููุง ูุฑู ููู ููููู ุงุณุชุฎุฏุงูู ูุน ุฎุท ุฃูุงุจูุจ ูุทุงุจู. ุฏุนููุง ูููู ุจุฅูุดุงุก ุฎุท ุฃูุงุจูุจ `"text-to-speech"` ูุน ููุทุฉ ุงูุชูุชูุด ุงูุฎุงุตุฉ ุจู:

```py
>>> from transformers import pipeline

>>> pipe = pipeline("text-to-speech"ุ model="YOUR_ACCOUNT_NAME/speecht5_finetuned_voxpopuli_nl")
```

ุงุฎุชุฑ ูุทุนุฉ ูุต ุจุงููุบุฉ ุงูููููุฏูุฉ ุงูุชู ุชุฑูุฏ ุณุฑุฏูุงุ ุนูู ุณุจูู ุงููุซุงู:

```py
>>> text = "hallo allemaal, ik praat nederlands. groetjes aan iedereen!"
```

ูุงุณุชุฎุฏุงู SpeechT5 ูุน ุฎุท ุงูุฃูุงุจูุจุ ุณุชุญุชุงุฌ ุฅูู ุชุถููู ุตูุช ุงููุชุญุฏุซ. ุฏุนููุง ูุญุตู ุนููู ูู ูุซุงู ูู ูุฌููุนุฉ ุงูุงุฎุชุจุงุฑ:

```py
>>> example = dataset["test"][304]
>>> speaker_embeddings = torch.tensor(example["speaker_embeddings"]).unsqueeze(0)
```

ุงูุขู ููููู ุชูุฑูุฑ ุงููุต ูุชุถููู ุงููุชุญุฏุซ ุฅูู ุฎุท ุงูุฃูุงุจูุจุ ูุณูุชููู ุจููุฉ ุงููููุฉ:

```py
>>> forward_params = {"speaker_embeddings": speaker_embeddings}
>>> output = pipe(text, forward_params=forward_params)
>>> output
{'audio': array([-6.82714235e-05, -4.26525949e-04, 1.06134125e-04, ...,
-1.22392643e-03, -7.76011671e-04, 3.29112721e-04], dtype=float32)ุ
'sampling_rate': 16000}
```

ููููู ุจุนุฏ ุฐูู ุงูุงุณุชูุงุน ุฅูู ุงููุชูุฌุฉ:

```py
>>> from IPython.display import Audio
>>> Audio(output['audio'], rate=output['sampling_rate'])
```

### ุชุดุบูู ุงูุงุณุชูุชุงุฌ ูุฏูููุง

ููููู ุชุญููู ููุณ ูุชุงุฆุฌ ุงูุงุณุชูุชุงุฌ ุจุฏูู ุงุณุชุฎุฏุงู ุฎุท ุงูุฃูุงุจูุจุ ูููู ุณุชููู ููุงู ุญุงุฌุฉ ุฅูู ูุฒูุฏ ูู ุงูุฎุทูุงุช.

ูู ุจุชุญููู ุงููููุฐุฌ ูู ๐ค Hub:

```py
>>> model = SpeechT5ForTextToSpeech.from_pretrained("YOUR_ACCOUNT/speecht5_finetuned_voxpopuli_nl")
```

ุงุฎุชุฑ ูุซุงูุงู ูู ูุฌููุนุฉ ุงูุงุฎุชุจุงุฑ ููุญุตูู ุนูู ุชุถููู ุตูุช ุงููุชุญุฏุซ.

```py
>>> example = dataset["test"][304]
>>> speaker_embeddings = torch.tensor(example["speaker_embeddings"]).unsqueeze(0)
```

ูู ุจุชุนุฑูู ูุต ุงูุฅุฏุฎุงู ููุนุงูุฌุชู:

```py
>>> text = "hallo allemaal, ik praat nederlands. groetjes aan iedereen!"
>>> inputs = processor(text=text, return_tensors="pt")
```

ูู ุจุฅูุดุงุก ูุฎุทุท ุทููู ูุน ูููุฐุฌู:

```py
>>> spectrogram = model.generate_speech(inputs["input_ids"], speaker_embeddings)
```

ูู ุจุชุตูุฑ ุงููุฎุทุท ุงูุทูููุ ุฅุฐุง ุฃุฑุฏุช:

```py
>>> plt.figure()
>>> plt.imshow(spectrogram.T)
>>> plt.show()
```

ุฃุฎูุฑูุงุ ุงุณุชุฎุฏู ุงููุญูู ุงูุชูุงุธุฑู ุงูุฑููู ูุชุญููู ุงููุฎุทุท ุงูุทููู ุฅูู ุตูุช:

```py
>>> with torch.no_grad():
...     speech = vocoder(spectrogram)

>>> from IPython.display import Audio

>>> Audio(speech.numpy(), rate=16000)
```

ูู ุชุฌุฑุจุชูุงุ ูุฏ ูููู ูู ุงูุตุนุจ ุงูุญุตูู ุนูู ูุชุงุฆุฌ ูุฑุถูุฉ ูู ูุฐุง ุงููููุฐุฌ. ุชุจุฏู ุฌูุฏุฉ ุชุถููู ุงููุชุญุฏุซ ุนุงูููุง ููููุง. ูุธุฑูุง ูุฃู SpeechT5 ุชู ุชุฏุฑูุจู ูุณุจููุง ุจุงุณุชุฎุฏุงู x-vectors ุจุงููุบุฉ ุงูุฅูุฌููุฒูุฉุ ูุฅูู ูุนูู ุจุดูู ุฃูุถู ุนูุฏ ุงุณุชุฎุฏุงู ุชุถููู ุตูุช ุงููุชุญุฏุซ ุจุงููุบุฉ ุงูุฅูุฌููุฒูุฉ. ุฅุฐุง ูุงู ุงูููุงู ุงูููุฎูููู ูุจุฏู ุฑุฏูุฆูุงุ ูุฌุฑูุจ ุงุณุชุฎุฏุงู ุชุถููู ุตูุช ูุชุญุฏุซ ูุฎุชูู.

ููู ุงููุฑุฌุญ ุฃู ูุคุฏู ุฒูุงุฏุฉ ูุฏุฉ ุงูุชุฏุฑูุจ ุฅูู ุชุญุณูู ุฌูุฏุฉ ุงููุชุงุฆุฌ. ููุน ุฐููุ ููู ุงููุงุถุญ ุฃู ุงูููุงู ุจุงููุบุฉ ุงูููููุฏูุฉ ุจุฏูุงู ูู ุงูุฅูุฌููุฒูุฉุ ููุชู ุงูุชูุงุท ุฎุตุงุฆุต ุตูุช ุงููุชุญุฏุซ (ููุงุฑูุฉ ุจุงูุตูุช ุงูุฃุตูู ูู ุงููุซุงู).

ุดูุก ุขุฎุฑ ูููู ุชุฌุฑุจุชู ูู ุชูููู ุงููููุฐุฌ. ุนูู ุณุจูู ุงููุซุงูุ ุฌุฑุจ ุงุณุชุฎุฏุงู `config.reduction_factor = 1` ููุนุฑูุฉ ูุง ุฅุฐุง ูุงู ูุฐุง ูุญุณู ุงููุชุงุฆุฌ.

ุฃุฎูุฑูุงุ ูู ุงูุถุฑูุฑู ูุฑุงุนุงุฉ ุงูุงุนุชุจุงุฑุงุช ุงูุฃุฎูุงููุฉ. ุนูู ุงูุฑุบู ูู ุฃู ุชูููุฉ TTS ูุฏููุง ุงูุนุฏูุฏ ูู ุงูุชุทุจููุงุช ุงููููุฏุฉุ ุฅูุง ุฃูู ูููู ุฃูุถูุง ุงุณุชุฎุฏุงููุง ูุฃุบุฑุงุถ ุฎุจูุซุฉุ ูุซู ุงูุชุญุงู ุตูุช ุดุฎุต ูุง ุฏูู ูุนุฑูุชู ุฃู ููุงููุชู. ูุฑุฌู ุงุณุชุฎุฏุงู TTS ุจุญููุฉ ูุจุดูู ูุณุคูู.