## Ø§Ù„ØªØ¹Ø±Ù Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…

ÙŠØ­ÙˆÙ„ Ø§Ù„ØªØ¹Ø±Ù Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… Ø¥Ø´Ø§Ø±Ø© Ø§Ù„ÙƒÙ„Ø§Ù… Ø¥Ù„Ù‰ Ù†ØµØŒ Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø±Ø³Ù… Ø®Ø±ÙŠØ·Ø© Ù„Ø³Ù„Ø³Ù„Ø© Ù…Ù† Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„ØµÙˆØªÙŠØ© Ø¥Ù„Ù‰ Ù…Ø®Ø±Ø¬Ø§Øª Ù†ØµÙŠØ©. ÙŠØ³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ÙˆÙ† Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠÙˆÙ† Ù…Ø«Ù„ Siri ÙˆAlexa Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† ÙŠÙˆÙ…ÙŠÙ‹Ø§ØŒ ÙˆÙ‡Ù†Ø§Ùƒ Ø§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ù…ÙÙŠØ¯Ø© Ø§Ù„Ø£Ø®Ø±Ù‰ Ø§Ù„ØªÙŠ ØªØªÙØ§Ø¹Ù„ Ù…Ø¹ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ø«Ù„ Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„ÙÙˆØ±ÙŠØ© ÙˆØªØ¯ÙˆÙŠÙ† Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹Ø§Øª.

Ø³ÙŠÙˆØ¶Ø­ Ù‡Ø°Ø§ Ø§Ù„Ø¯Ù„ÙŠÙ„ Ù„Ùƒ ÙƒÙŠÙÙŠØ©:

1. Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ Wav2Vec2 Ø§Ù„Ø¯Ù‚ÙŠÙ‚ Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª MInDS-14 Ù„Ù†Ø³Ø® Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ.
2. Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¯Ù‚ÙŠÙ‚ Ù„Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬.

Ù‚Ø¨Ù„ Ø£Ù† ØªØ¨Ø¯Ø£ØŒ ØªØ£ÙƒØ¯ Ù…Ù† ØªØ«Ø¨ÙŠØª Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ø¶Ø±ÙˆØ±ÙŠØ©:

```bash
pip install transformers datasets evaluate jiwer
```

Ù†Ø­Ù† Ù†Ø´Ø¬Ø¹Ùƒ Ø¹Ù„Ù‰ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø¥Ù„Ù‰ Ø­Ø³Ø§Ø¨ Hugging Face Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ Ø­ØªÙ‰ ØªØªÙ…ÙƒÙ† Ù…Ù† ØªØ­Ù…ÙŠÙ„ ÙˆÙ…Ø´Ø§Ø±ÙƒØ© Ù†Ù…ÙˆØ°Ø¬Ùƒ Ù…Ø¹ Ø§Ù„Ù…Ø¬ØªÙ…Ø¹. Ø¹Ù†Ø¯Ù…Ø§ ÙŠÙØ·Ù„Ø¨ Ù…Ù†Ùƒ Ø°Ù„ÙƒØŒ Ø£Ø¯Ø®Ù„ Ø±Ù…Ø²Ùƒ Ù„Ù„ØªØ³Ø¬ÙŠÙ„:

```py
>>> from huggingface_hub import notebook_login

>>> notebook_login()
```

## ØªØ­Ù…ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª MInDS-14

Ø§Ø¨Ø¯Ø£ Ø¨ØªØ­Ù…ÙŠÙ„ Ø¬Ø²Ø¡ ÙØ±Ø¹ÙŠ Ø£ØµØºØ± Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) Ù…Ù† Ù…ÙƒØªØ¨Ø© Datasets ðŸ¤—. Ø³ÙŠØ¹Ø·ÙŠÙƒ Ù‡Ø°Ø§ ÙØ±ØµØ© Ù„ØªØ¬Ø±Ø¨Ø© ÙˆØ§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† ÙƒÙ„ Ø´ÙŠØ¡ ÙŠØ¹Ù…Ù„ Ù‚Ø¨Ù„ Ù‚Ø¶Ø§Ø¡ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ÙˆÙ‚Øª ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒØ§Ù…Ù„Ø©.

```py
>>> from datasets import load_dataset, Audio

>>> minds = load_dataset("PolyAI/minds14", name="en-US", split="train[:100]")
```

Ù‚Ø³ÙÙ‘Ù… Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ£Ø®Ø±Ù‰ Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø·Ø±ÙŠÙ‚Ø© [`~Dataset.train_test_split`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.train_test_split):

```py
>>> minds = minds.train_test_split(test_size=0.2)
```

Ø«Ù… Ø§Ù„Ù‚ Ù†Ø¸Ø±Ø© Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:

```py
>>> minds
DatasetDict({
train: Dataset({
features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],
num_rows: 16
})
test: Dataset({
features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],
num_rows: 4
})
})
```

Ø¹Ù„Ù‰ Ø§Ù„Ø±ØºÙ… Ù…Ù† Ø£Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„ÙƒØ«ÙŠØ± Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ÙÙŠØ¯Ø©ØŒ Ù…Ø«Ù„ `lang_id` Ùˆ`english_transcription`ØŒ Ø¥Ù„Ø§ Ø£Ù†Ùƒ Ø³ØªØ±ÙƒØ² Ø¹Ù„Ù‰ `audio` Ùˆ`transcription` ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø¯Ù„ÙŠÙ„. Ù‚Ù… Ø¨Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø£Ø®Ø±Ù‰ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø·Ø±ÙŠÙ‚Ø© [`~datasets.Dataset.remove_columns`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.remove_columns):

```py
>>> minds = minds.remove_columns(["english_transcription", "intent_class", "lang_id"])
```

Ø§Ù„Ù‚ Ù†Ø¸Ø±Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø«Ø§Ù„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰:

```py
>>> minds["train"][0]
{'audio': {'array': array([-0.00024414,  0.        ,  0.        , ...,  0.00024414,
0.00024414,  0.00024414], dtype=float32),
'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602ba9e2963e11ccd901cd4f.wav',
'sampling_rate': 8000},
'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602ba9e2963e11ccd901cd4f.wav',
'transcription': "hi I'm trying to use the banking app on my phone and currently my checking and savings account balance is not refreshing"}
```

Ù‡Ù†Ø§Ùƒ Ø­Ù‚Ù„Ø§Ù†:

- `audio`: Ù…ØµÙÙˆÙØ© Ø£Ø­Ø§Ø¯ÙŠØ© Ø§Ù„Ø¨Ø¹Ø¯ Ù„Ø¥Ø´Ø§Ø±Ø© Ø§Ù„ÙƒÙ„Ø§Ù… Ø§Ù„ØªÙŠ ÙŠØ¬Ø¨ Ø§Ø³ØªØ¯Ø¹Ø§Ø¤Ù‡Ø§ Ù„ØªØ­Ù…ÙŠÙ„ ÙˆØ¥Ø¹Ø§Ø¯Ø© Ø£Ø®Ø° Ø¹ÙŠÙ†Ø§Øª Ù…Ù„Ù Ø§Ù„ØµÙˆØª.
- `transcription`: Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù.

## Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø³Ø¨Ù‚Ø©

Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„ØªØ§Ù„ÙŠØ© Ù‡ÙŠ ØªØ­Ù…ÙŠÙ„ Ù…Ø¹Ø§Ù„Ø¬ Wav2Vec2 Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¥Ø´Ø§Ø±Ø© Ø§Ù„ØµÙˆØª:

```py
>>> from transformers import AutoProcessor

>>> processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base")
```

ØªØ­ØªÙˆÙŠ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª MInDS-14 Ø¹Ù„Ù‰ Ù…Ø¹Ø¯Ù„ Ø£Ø®Ø° Ø¹ÙŠÙ†Ø§Øª ÙŠØ¨Ù„Øº 8000 ÙƒÙŠÙ„Ùˆ Ù‡Ø±ØªØ² (ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙÙŠ [Ø¨Ø·Ø§Ù‚Ø© Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª](https://huggingface.co/datasets/PolyAI/minds14) Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù‡Ø§)ØŒ Ù…Ù…Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù†Ùƒ Ø³ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø¥Ø¹Ø§Ø¯Ø© Ø£Ø®Ø° Ø¹ÙŠÙ†Ø§Øª Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ 16000 ÙƒÙŠÙ„Ùˆ Ù‡Ø±ØªØ² Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Wav2Vec2 Ø§Ù„Ù…ÙØ¯Ø±ÙŽÙ‘Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§:

```py
>>> minds = minds.cast_column("audio", Audio(sampling_rate=16_000))
>>> minds["train"][0]
{'audio': {'array': array([-2.38064706e-04, -1.58618059e-04, -5.43987835e-06, ...,
2.78103951e-04,  2.38446111e-04,  1.18740834e-04], dtype=float32),
'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602ba9e2963e11ccd901cd4f.wav',
'sampling_rate': 16000},
'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602ba9e2963e11ccd901cd4f.wav',
'transcription': "hi I'm trying to use the banking app on my phone and currently my checking and savings account balance is not refreshing"}
```

ÙƒÙ…Ø§ Ù‡Ùˆ Ù…ÙˆØ¶Ø­ ÙÙŠ `transcription` Ø£Ø¹Ù„Ø§Ù‡ØŒ ÙŠØ­ØªÙˆÙŠ Ø§Ù„Ù†Øµ Ø¹Ù„Ù‰ Ù…Ø²ÙŠØ¬ Ù…Ù† Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„ÙƒØ¨ÙŠØ±Ø© ÙˆØ§Ù„ØµØºÙŠØ±Ø©. ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ù…Ø¹Ø¬Ù… Wav2Vec2 Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„ÙƒØ¨ÙŠØ±Ø© ÙÙ‚Ø·ØŒ Ù„Ø°Ù„Ùƒ Ø³ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù†Øµ ÙŠØªØ·Ø§Ø¨Ù‚ Ù…Ø¹ Ù…ÙØ±Ø¯Ø§Øª Ø§Ù„Ù…Ø¹Ø¬Ù…:

```py
>>> def uppercase(example):
...     return {"transcription": example["transcription"].upper()}


>>> minds = minds.map(uppercase)
```

Ø§Ù„Ø¢Ù† Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø¯Ø§Ù„Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø³Ø¨Ù‚Ø© ØªÙ‚ÙˆÙ… Ø¨Ù…Ø§ ÙŠÙ„ÙŠ:

1. Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø¹Ù…ÙˆØ¯ `audio` Ù„ØªØ­Ù…ÙŠÙ„ ÙˆØ¥Ø¹Ø§Ø¯Ø© Ø£Ø®Ø° Ø¹ÙŠÙ†Ø§Øª Ù…Ù„Ù Ø§Ù„ØµÙˆØª.
2. Ø§Ø³ØªØ®Ø±Ø§Ø¬ `input_values` Ù…Ù† Ù…Ù„Ù Ø§Ù„ØµÙˆØª ÙˆØ±Ù‚Ù…Ù†Ø© Ø¹Ù…ÙˆØ¯ `transcription` Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬.

```py
>>> def prepare_dataset(batch):
...     audio = batch["audio"]
...     batch = processor(audio["array"], sampling_rate=audio["sampling_rate"], text=batch["transcription"])
...     batch["input_length"] = len(batch["input_values"][0])
...     return batch
```

Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¯Ø§Ù„Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³Ø¨Ù‚Ø© Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø£ÙƒÙ…Ù„Ù‡Ø§ØŒ Ø§Ø³ØªØ®Ø¯Ù… ÙˆØ¸ÙŠÙØ© [`~datasets.Dataset.map`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.map) ÙÙŠ Ù…ÙƒØªØ¨Ø© Datasets ðŸ¤—. ÙŠÙ…ÙƒÙ†Ùƒ ØªØ³Ø±ÙŠØ¹ `map` Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø²ÙŠØ§Ø¯Ø© Ø¹Ø¯Ø¯ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹Ù„Ù…Ø© `num_proc`:

```py
>>> encoded_minds = minds.map(prepare_dataset, remove_columns=minds.column_names["train"], num_proc=4)
```

Ù„Ø§ ØªØ­ØªÙˆÙŠ Ù…ÙƒØªØ¨Ø© ðŸ¤— Transformers Ø¹Ù„Ù‰ Ø¬Ø§Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ¹Ø±Ù Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…ØŒ Ù„Ø°Ù„Ùƒ Ø³ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªÙƒÙŠÙŠÙ [`DataCollatorWithPadding`](https://huggingface.co/docs/transformers/main_classes/data_collator) Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø¯ÙØ¹Ø© Ù…Ù† Ø§Ù„Ø£Ù…Ø«Ù„Ø©. ÙƒÙ…Ø§ Ø£Ù†Ù‡ Ø³ÙŠÙ‚ÙˆÙ… Ø£ÙŠØ¶Ù‹Ø§ Ø¨ØªØ¨Ø·ÙŠÙ† Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ Ù„Ù†ØµÙƒ ÙˆØªØ³Ù…ÙŠØ§ØªÙƒ Ø¥Ù„Ù‰ Ø·ÙˆÙ„ Ø§Ù„Ø¹Ù†ØµØ± Ø§Ù„Ø£Ø·ÙˆÙ„ ÙÙŠ Ø¯ÙØ¹ØªÙ‡Ø§ (Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø£ÙƒÙ…Ù„Ù‡Ø§) Ø¨Ø­ÙŠØ« ÙŠÙƒÙˆÙ† Ù„Ù‡Ø§ Ø·ÙˆÙ„ Ù…ÙˆØ­Ø¯. ÙÙŠ Ø­ÙŠÙ† Ø£Ù†Ù‡ Ù…Ù† Ø§Ù„Ù…Ù…ÙƒÙ† ØªØ¨Ø·ÙŠÙ† Ù†ØµÙƒ ÙÙŠ Ø¯Ø§Ù„Ø© `tokenizer` Ø¹Ù† Ø·Ø±ÙŠÙ‚ ØªØ¹ÙŠÙŠÙ† `padding=True`ØŒ ÙØ¥Ù† Ø§Ù„ØªØ¨Ø·ÙŠÙ† Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ Ø£ÙƒØ«Ø± ÙƒÙØ§Ø¡Ø©.

Ø¹Ù„Ù‰ Ø¹ÙƒØ³ Ø¬Ø§Ù…Ø¹ÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¢Ø®Ø±ÙŠÙ†ØŒ ÙŠØ­ØªØ§Ø¬ Ø¬Ø§Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù‡Ø°Ø§ Ø¥Ù„Ù‰ ØªØ·Ø¨ÙŠÙ‚ Ø·Ø±ÙŠÙ‚Ø© ØªØ¨Ø·ÙŠÙ† Ù…Ø®ØªÙ„ÙØ© Ø¹Ù„Ù‰ `input_values` Ùˆ`labels`:

```py
>>> import torch

>>> from dataclasses import dataclass, field
>>> from typing import Any, Dict, List, Optional, Union


>>> @dataclass
... class DataCollatorCTCWithPadding:
...     processor: AutoProcessor
...     padding: Union[bool, str] = "longest"

...     def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:
...         # split inputs and labels since they have to be of different lengths and need
...         # different padding methods
...         input_features = [{"input_values": feature["input_values"][0]} for feature in features]
...         label_features = [{"input_ids": feature["labels"]} for feature in features]

...         batch = self.processor.pad(input_features, padding=self.padding, return_tensors="pt")

...         labels_batch = self.processor.pad(labels=label_features, padding=self.padding, return_tensors="pt")

...         # replace padding with -100 to ignore loss correctly
...         labels = labels_batch["input_ids"].masked_fill(labels_batch.attention_mask.ne(1), -100)

...         batch["labels"] = labels

...         return batch
```

Ø§Ù„Ø¢Ù† Ù‚Ù… Ø¨ØªÙ†ÙÙŠØ° Ø¬Ø§Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª `DataCollatorForCTCWithPadding`:

```py
>>> data_collator = DataCollatorCTCWithPadding(processor=processor, padding="longest")
```

## ØªÙ‚ÙŠÙŠÙ…

ØºØ§Ù„Ø¨Ù‹Ø§ Ù…Ø§ ÙŠÙƒÙˆÙ† ØªØ¶Ù…ÙŠÙ† Ù…Ù‚ÙŠØ§Ø³ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù…ÙÙŠØ¯Ù‹Ø§ Ù„ØªÙ‚ÙŠÙŠÙ… Ø£Ø¯Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬Ùƒ. ÙŠÙ…ÙƒÙ†Ùƒ ØªØ­Ù…ÙŠÙ„ Ø·Ø±ÙŠÙ‚Ø© ØªÙ‚ÙŠÙŠÙ… Ø¨Ø³Ø±Ø¹Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙƒØªØ¨Ø© [Evaluate](https://huggingface.co/docs/evaluate/index) ðŸ¤—. Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù‡Ù…Ø©ØŒ Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ù…Ù‚ÙŠØ§Ø³ [Ø®Ø·Ø£ ÙƒÙ„Ù…Ø©](https://huggingface.co/spaces/evaluate-metric/wer) (WER) (Ø±Ø§Ø¬Ø¹ Ø¬ÙˆÙ„Ø© ðŸ¤— Evaluate [Ø§Ù„Ø³Ø±ÙŠØ¹Ø©](https://huggingface.co/docs/evaluate/a_quick_tour) Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯ Ø­ÙˆÙ„ ÙƒÙŠÙÙŠØ© ØªØ­Ù…ÙŠÙ„ ÙˆØ­Ø³Ø§Ø¨ Ù…Ù‚ÙŠØ§Ø³):

```py
>>> import evaluate

>>> wer = evaluate.load("wer")
```

Ø«Ù… Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø¯Ø§Ù„Ø© ØªÙ…Ø±Ø± ØªÙ†Ø¨Ø¤Ø§ØªÙƒ ÙˆØªØ³Ù…ÙŠØ§ØªÙƒ Ø¥Ù„Ù‰ [`~evaluate.EvaluationModule.compute`](https://huggingface.co/docs/evaluate/main_classes/evaluation_module#computemetrics) Ù„Ø­Ø³Ø§Ø¨ WER:

```py
>>> import numpy as np


>>> def compute_metrics(pred):
...     pred_logits = pred.predictions
...     pred_ids = np.argmax(pred_logits, axis=-1)

...     pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id

...     pred_str = processor.batch_decode(pred_ids)
...     label_str = processor.batch_decode(pred.label_ids, group_tokens=False)

...     wer = wer.compute(predictions=pred_str, references=label_str)

...     return {"wer": wer}
```

Ø¯Ø§Ù„ØªÙƒ `compute_metrics` Ø¬Ø§Ù‡Ø²Ø© Ø§Ù„Ø¢Ù†ØŒ ÙˆØ³ØªØ¹ÙˆØ¯ Ø¥Ù„ÙŠÙ‡Ø§ Ø¹Ù†Ø¯ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ.
Ø¨Ø§Ù„ØªØ£ÙƒÙŠØ¯! ÙÙŠÙ…Ø§ ÙŠÙ„ÙŠ ØªØ±Ø¬Ù…Ø© Ù„Ù„Ù†Øµ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„ÙÙ‚Ø±Ø§Øª ÙˆØ§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†ØŒ Ù…Ø¹ Ø§ØªØ¨Ø§Ø¹ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„ØªÙŠ Ù‚Ø¯Ù…ØªÙ‡Ø§:

## Ø§Ù„ØªØ¯Ø±ÙŠØ¨

Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…Ø¹ØªØ§Ø¯Ù‹Ø§ Ø¹Ù„Ù‰ Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`Trainer`]ØŒ ÙØ±Ø§Ø¬Ø¹ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ [Ù‡Ù†Ø§] (../training#train-with-pytorch-trainer)

Ø£Ù†Øª Ø§Ù„Ø¢Ù† Ø¹Ù„Ù‰ Ø§Ø³ØªØ¹Ø¯Ø§Ø¯ Ù„Ø¨Ø¯Ø¡ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬Ùƒ! Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Wav2Vec2 Ù…Ø¹ [`AutoModelForCTC`]. Ø­Ø¯Ø¯ Ø§Ù„ØªØ®ÙÙŠØ¶ Ø§Ù„Ø°ÙŠ Ø³ÙŠØªÙ… ØªØ·Ø¨ÙŠÙ‚Ù‡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹Ù„Ù…Ø© `ctc_loss_reduction`. ØºØ§Ù„Ø¨Ù‹Ø§ Ù…Ø§ ÙŠÙƒÙˆÙ† Ù…Ù† Ø§Ù„Ø£ÙØ¶Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ØªÙˆØ³Ø· Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„Ø¬Ù…Ø¹ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ:

```py
>>> from transformers import AutoModelForCTC, TrainingArguments, Trainer

>>> model = AutoModelForCTC.from_pretrained(
...     "facebook/wav2vec2-base",
...     ctc_loss_reduction="mean",
...     pad_token_id=processor.tokenizer.pad_token_id,
... )
```

ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø­Ù„Ø©ØŒ Ù„Ù… ÙŠØªØ¨Ù‚ Ø³ÙˆÙ‰ Ø«Ù„Ø§Ø« Ø®Ø·ÙˆØ§Øª:

1. Ø­Ø¯Ø¯ ÙØ±Ø· Ù…Ø¹Ù„Ù…Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ ÙÙŠ [`TrainingArguments`]. Ø§Ù„Ù…Ø¹Ù„Ù…Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ø§Ù„ÙˆØ­ÙŠØ¯Ø© Ù‡ÙŠ `output_dir` Ø§Ù„ØªÙŠ ØªØ­Ø¯Ø¯ Ø£ÙŠÙ† Ø³ÙŠØªÙ… Ø­ÙØ¸ Ù†Ù…ÙˆØ°Ø¬Ùƒ. Ø³ØªÙ‚ÙˆÙ… Ø¨ØªØ­Ù…ÙŠÙ„ Ù‡Ø°Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø­ÙˆØ± Ø¹Ù† Ø·Ø±ÙŠÙ‚ ØªØ¹ÙŠÙŠÙ† `push_to_hub=True` (ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ù…Ø³Ø¬Ù„Ø§Ù‹ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø¥Ù„Ù‰ Hugging Face Ù„ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬Ùƒ). ÙÙŠ Ù†Ù‡Ø§ÙŠØ© ÙƒÙ„ Ø­Ù‚Ø¨Ø©ØŒ Ø³ÙŠÙ‚ÙˆÙ… [`Trainer`] Ø¨ØªÙ‚ÙŠÙŠÙ… WER ÙˆØ­ÙØ¸ Ù†Ù‚Ø·Ø© ØªÙØªÙŠØ´ Ø§Ù„ØªØ¯Ø±ÙŠØ¨.

2. Ù‚Ù… Ø¨ØªÙ…Ø±ÙŠØ± Ø§Ù„Ø­Ø¬Ø¬ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ÙŠØ© Ø¥Ù„Ù‰ [`Trainer`] Ø¬Ù†Ø¨Ù‹Ø§ Ø¥Ù„Ù‰ Ø¬Ù†Ø¨ Ù…Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆÙ…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„Ù…Ø­Ù„Ù„ Ø§Ù„Ù„ØºÙˆÙŠ ÙˆÙ…Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆÙˆØ¸ÙŠÙØ© `compute_metrics`.

3. Ø§ØªØµÙ„ [`~Trainer.train`] Ù„Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬Ùƒ.

```py
>>> training_args = TrainingArguments(
...     output_dir="my_awesome_asr_mind_model"ØŒ
...     per_device_train_batch_size=8ØŒ
...     gradient_accumulation_steps=2ØŒ
...     learning_rate=1e-5ØŒ
...     warmup_steps=500ØŒ
...     max_steps=2000ØŒ
...     gradient_checkpointing=TrueØŒ
...     fp16=TrueØŒ
...     group_by_length=TrueØŒ
...     eval_strategy="steps"ØŒ
...     per_device_eval_batch_size=8ØŒ
...     save_steps=1000ØŒ
...     eval_steps=1000ØŒ
...     logging_steps=25ØŒ
...     load_best_model_at_end=TrueØŒ
...     metric_for_best_model="wer"ØŒ
...     greater_is_better=FalseØŒ
...     push_to_hub=TrueØŒ
... )

>>> trainer = Trainer(
...     model=modelØŒ
...     args=training_argsØŒ
...     train_dataset=encoded_minds["train"]ØŒ
...     eval_dataset=encoded_minds["test"]ØŒ
...     tokenizer=processorØŒ
...     data_collator=data_collatorØŒ
...     compute_metrics=compute_metricsØŒ
... )

>>> trainer.train()
```

Ø¨Ù…Ø¬Ø±Ø¯ Ø§ÙƒØªÙ…Ø§Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ØŒ Ø´Ø§Ø±Ùƒ Ù†Ù…ÙˆØ°Ø¬Ùƒ ÙÙŠ Ø§Ù„Ù…Ø­ÙˆØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø·Ø±ÙŠÙ‚Ø© [`~transformers.Trainer.push_to_hub`] Ø­ØªÙ‰ ÙŠØªÙ…ÙƒÙ† Ø§Ù„Ø¬Ù…ÙŠØ¹ Ù…Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬Ùƒ:

```py
>>> trainer.push_to_hub()
```

Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø«Ø§Ù„ Ø£ÙƒØ«Ø± ØªÙØµÙŠÙ„Ø§Ù‹ Ø­ÙˆÙ„ ÙƒÙŠÙÙŠØ© Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„ØªØ¹Ø±Ù Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…ØŒ Ø±Ø§Ø¬Ø¹ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¯ÙˆÙ†Ø© [Ø§Ù„Ù…Ù†Ø´ÙˆØ±] (https://huggingface.co/blog/fine-tune-wav2vec2-english) Ù„Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© ÙˆÙ‡Ø°Ø§ [Ø§Ù„Ù…Ù†Ø´ÙˆØ±] (https://huggingface.co/blog/fine-tune-xlsr-wav2vec2) Ù„Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù„ØºØ§Øª.

## Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬

Ø±Ø§Ø¦Ø¹ØŒ Ø§Ù„Ø¢Ù† Ø¨Ø¹Ø¯ Ø£Ù† Ø¶Ø¨Ø·Øª Ù†Ù…ÙˆØ°Ø¬Ù‹Ø§ØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ Ù„Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬!

Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù ØµÙˆØªÙŠ ØªØ±ÙŠØ¯ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø¹Ù„ÙŠÙ‡. ØªØ°ÙƒØ± Ø¥Ø¹Ø§Ø¯Ø© Ø£Ø®Ø° Ù…Ø¹Ø¯Ù„ Ø¹ÙŠÙ†Ø© Ù…Ø¹Ø¯Ù„ Ø¹ÙŠÙ†Ø© Ù…Ù„Ù Ø§Ù„ØµÙˆØª Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ù…Ø¹Ø¯Ù„ Ø¹ÙŠÙ†Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±!

```py
>>> from datasets import load_dataset, Audio

>>> dataset = load_dataset("PolyAI/minds14", "en-US", split="train")
>>> dataset = dataset.cast_column("audio", Audio(sampling_rate=16000))
>>> sampling_rate = dataset.features["audio"].sampling_rate
>>> audio_file = dataset[0]["audio"]["path"]
```

Ø£Ø¨Ø³Ø· Ø·Ø±ÙŠÙ‚Ø© Ù„ØªØ¬Ø±Ø¨Ø© Ù†Ù…ÙˆØ°Ø¬Ùƒ Ø§Ù„Ù…Ø¶Ø¨ÙˆØ· Ù„Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ù‡ÙŠ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ ÙÙŠ [`pipeline`]. Ù‚Ù… Ø¨ØªÙ†ÙÙŠØ° Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ù„Ù„ØªØ¹Ø±Ù Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ÙƒØŒ ÙˆÙ…Ø±Ø± Ù…Ù„Ù Ø§Ù„ØµÙˆØª Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ Ø¥Ù„ÙŠÙ‡:

```py
>>> from transformers import pipeline

>>> transcriber = pipeline("automatic-speech-recognition", model="stevhliu/my_awesome_asr_minds_model")
>>> transcriber(audio_file)
{'text': 'I WOUD LIKE TO SET UP JOINT ACCOUNT WITH MY PARTNER'}
```

ÙŠÙ…ÙƒÙ†Ùƒ Ø£ÙŠØ¶Ù‹Ø§ Ø¥Ø¹Ø§Ø¯Ø© Ø¥Ù†ØªØ§Ø¬ Ù†ØªØ§Ø¦Ø¬ `pipeline` ÙŠØ¯ÙˆÙŠÙ‹Ø§ Ø¥Ø°Ø§ Ø£Ø±Ø¯Øª:

Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ù…Ø¹Ø§Ù„Ø¬ Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ù Ø§Ù„ØµÙˆØª ÙˆØ§Ù„Ù†Ø³Ø® Ø§Ù„Ù†ØµÙŠ ÙˆØ¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ ÙƒÙ…ÙˆØªØ±Ø§Øª PyTorch:

```py
>>> from transformers import AutoProcessor

>>> processor = AutoProcessor.from_pretrained("stevhliu/my_awesome_asr_mind_model")
>>> inputs = processor(dataset[0]["audio"]["array"], sampling_rate=sampling_rate, return_tensors="pt")
```

Ù…Ø±Ø± Ø¥Ø¯Ø®Ø§Ù„Ø§ØªÙƒ Ø¥Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ£Ø¹Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬:

```py
>>> from transformers import AutoModelForCTC

>>> model = AutoModelForCTC.from_pretrained("stevhliu/my_awesome_asr_mind_model")
>>> with torch.no_grad():
...     logits = model(**inputs).logits
```

Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ `input_ids` Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ Ù…Ø¹ Ø£Ø¹Ù„Ù‰ Ø§Ø­ØªÙ…Ø§Ù„ØŒ ÙˆØ§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ Ù„ØªØ±Ù…ÙŠØ² `input_ids` Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ø¥Ù„Ù‰ Ù†Øµ:

```py
>>> import torch

>>> predicted_ids = torch.argmax(logits, dim=-1)
>>> transcription = processor.batch_decode(predicted_ids)
>>> transcription
['I WOULD LIKE TO SET UP JOINT ACCOUNT WITH MY PARTNER']
```