# ุฏููู ููุงู ุงูุตูุฑุฉ ุฅูู ุงูุตูุฑุฉ

ุชูุซู ูููุฉ ุงูุตูุฑุฉ ุฅูู ุงูุตูุฑุฉ ุงููููุฉ ุงูุชู ูุชููู ูููุง ุงูุชุทุจูู ุตูุฑุฉ ููุฎุฑุฌ ุตูุฑุฉ ุฃุฎุฑู. ูููุฐู ุงููููุฉ ููุงู ูุฑุนูุฉ ูุฎุชููุฉุ ุจูุง ูู ุฐูู ุชุญุณูู ุงูุตูุฑุฉ (ุงูุงุณุชุจุงูุฉ ุงููุงุฆูุฉุ ูุชุญุณูู ุงูุฅุถุงุกุฉ ุงูุฎุงูุชุฉุ ูุฅุฒุงูุฉ ุงููุทุฑุ ูุบูุฑ ุฐูู)ุ ูุฑุณู ุงูุตูุฑุ ูุฃูุซุฑ ูู ุฐูู.

ุณููุถุญ ูุฐุง ุงูุฏููู ููููุฉ:

- ุงุณุชุฎุฏุงู ุฎุท ุฃูุงุจูุจ ุงูุตูุฑุฉ ุฅูู ุงูุตูุฑุฉ ููููุฉ ุงูุงุณุชุจุงูุฉ ุงููุงุฆูุฉ.
- ุชุดุบูู ููุงุฐุฌ ุงูุตูุฑุฉ ุฅูู ุงูุตูุฑุฉ ูููููุฉ ููุณูุง ุจุฏูู ุฎุท ุฃูุงุจูุจ.

ูุงุญุธ ุฃูู ุงุนุชุจุงุฑูุง ูู ููุช ุฅุตุฏุงุฑ ูุฐุง ุงูุฏูููุ ูุฏุนู ุฎุท ุฃูุงุจูุจ "ุงูุตูุฑุฉ ุฅูู ุงูุตูุฑุฉ" ูููุฉ ุงูุงุณุชุจุงูุฉ ุงููุงุฆูุฉ ููุท.

ุฏุนููุง ูุจุฏุฃ ุจุชุซุจูุช ุงูููุชุจุงุช ุงููุงุฒูุฉ.

```bash
pip install transformers
```

ูููููุง ุงูุขู ุชููุฆุฉ ุฎุท ุงูุฃูุงุจูุจ ุจุงุณุชุฎุฏุงู ูููุฐุฌ [Swin2SR](https://huggingface.co/caidas/swin2SR-lightweight-x2-64). ุจุนุฏ ุฐููุ ูููููุง ุงูุงุณุชูุชุงุฌ ุจุงุณุชุฎุฏุงู ุฎุท ุงูุฃูุงุจูุจ ุนู ุทุฑูู ุงุณุชุฏุนุงุฆู ูุน ุตูุฑุฉ. ูู ุงูููุช ุงูุญุงููุ ูุง ุชูุฏุนู ุณูู ููุงุฐุฌ [Swin2SR](https://huggingface.co/models?sort=trending&search=swin2sr) ูู ูุฐุง ุงูุฎุท.

```python
from transformers import pipeline

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
pipe = pipeline(task="image-to-image", model="caidas/swin2SR-lightweight-x2-64", device=device)
```

ุงูุขูุ ุฏุนููุง ูููู ุจุชุญููู ุตูุฑุฉ.

```python
from PIL import Image
import requests

url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/cat.jpg"
image = Image.open(requests.get(url, stream=True).raw)

print(image.size)
```

```bash
# (532, 432)
```

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/cat.jpg" alt="ุตูุฑุฉ ููุทุฉ"/>
</div>

ูููููุง ุงูุขู ุฅุฌุฑุงุก ุงูุงุณุชุฏูุงู ุจุงุณุชุฎุฏุงู ุฎุท ุงูุฃูุงุจูุจ. ุณูุญุตู ุนูู ูุณุฎุฉ ููุจุฑุฉ ูู ุตูุฑุฉ ุงููุทุฉ.

```python
upscaled = pipe(image)
print(upscaled.size)
```

```bash
# (1072, 880)
```

ุฅุฐุง ููุช ุชุฑุบุจ ูู ุฅุฌุฑุงุก ุงูุงุณุชุฏูุงู ุจููุณู ุจุฏูู ุฎุท ุฃูุงุจูุจุ ูููููู ุงุณุชุฎุฏุงู ุงููุฆุงุช `Swin2SRForImageSuperResolution` ู`Swin2SRImageProcessor` ูู ููุชุจุฉ `transformers`. ุณูุณุชุฎุฏู ููุณ ููุทุฉ ุชูุชูุด ุงููููุฐุฌ ููุฐุง ุงูุบุฑุถ. ุฏุนููุง ูููู ุจุชููุฆุฉ ุงููููุฐุฌ ูุงููุนุงูุฌ.

```python
from transformers import Swin2SRForImageSuperResolution, Swin2SRImageProcessor

model = Swin2SRForImageSuperResolution.from_pretrained("caidas/swin2SR-lightweight-x2-64").to(device)
processor = Swin2SRImageProcessor("caidas/swin2SR-lightweight-x2-64")
```

ูููู `pipeline` ุจุชุจุณูุท ุฎุทูุงุช ูุง ูุจู ุงููุนุงูุฌุฉ ููุง ุจุนุฏ ุงููุนุงูุฌุฉ ุงูุชู ูุชุนูู ุนูููุง ุงูููุงู ุจูุง ุจุฃููุณูุงุ ูุฐูู ุฏุนููุง ูููู ุจูุนุงูุฌุฉ ุงูุตูุฑุฉ ูุณุจููุง. ุณููุฑุฑ ุงูุตูุฑุฉ ุฅูู ุงููุนุงูุฌ ุซู ูููู ุจููู ููู ุงูุจูุณู ุฅูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU).

```python
pixel_values = processor(image, return_tensors="pt").pixel_values
print(pixel_values.shape)

pixel_values = pixel_values.to(device)
```

ูููููุง ุงูุขู ุงุณุชูุชุงุฌ ุงูุตูุฑุฉ ุนู ุทุฑูู ุชูุฑูุฑ ููู ุงูุจูุณู ุฅูู ุงููููุฐุฌ.

```python
import torch

with torch.no_grad():
    outputs = model(pixel_values)
```

ุงููุงุชุฌ ุนุจุงุฑุฉ ุนู ูุงุฆู ูู ุงูููุน `ImageSuperResolutionOutput` ูุจุฏู ููุง ููู ๐

```
(loss=None, reconstruction=tensor([[[[0.8270, 0.8269, 0.8275, ..., 0.7463, 0.7446, 0.7453],
[0.8287, 0.8278, 0.8283, ..., 0.7451, 0.7448, 0.7457],
[0.8280, 0.8273, 0.8269, ..., 0.7447, 0.7446, 0.7452],
...,
[0.5923, 0.5933, 0.5924, ..., 0.0697, 0.0695, 0.0706],
[0.5926, 0.5932, 0.5926, ..., 0.0673, 0.0687, 0.0705],
[0.5927, 0.5914, 0.5922, ..., 0.0664, 0.0694, 0.0718]]]],
device='cuda:0'), hidden_states=None, attentions=None)
```

ูุญู ุจุญุงุฌุฉ ุฅูู ุงูุญุตูู ุนูู `reconstruction` ููุนุงูุฌุชูุง ุจุนุฏ ุฐูู ููุชุตูุฑ. ุฏุนููุง ูุฑู ููู ุชุจุฏู.

```python
outputs.reconstruction.data.shape
# torch.Size([1, 3, 880, 1072])
```

ูุญู ุจุญุงุฌุฉ ุฅูู ุถุบุท ุงูุฅุฎุฑุงุฌ ูุงูุชุฎูุต ูู ุงููุญูุฑ 0ุ ููุต ุงููููุ ุซู ุชุญููููุง ุฅูู float ูููุจู. ุจุนุฏ ุฐููุ ุณูููู ุจุชุฑุชูุจ ุงููุญุงูุฑ ุจุญูุซ ูููู ุงูุดูู [1072ุ 880]ุ ูุฃุฎูุฑุงูุ ุณูุนูุฏ ุงูุฅุฎุฑุงุฌ ุฅูู ุงููุทุงู [0ุ 255].

```python
import numpy as np

# ุถุบุทุ ูุงูุงูุชูุงู ุฅูู ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉุ ููุต ุงูููู
output = outputs.reconstruction.data.squeeze().cpu().clamp_(0, 1).numpy()
# ุฅุนุงุฏุฉ ุชุฑุชูุจ ุงููุญุงูุฑ
output = np.moveaxis(output, source=0, destination=-1)
# ุฅุนุงุฏุฉ ุงูููู ุฅูู ูุทุงู ููู ุงูุจูุณู
output = (output * 255.0).round().astype(np.uint8)
Image.fromarray(output)
```

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/cat_upscaled.png" alt="ุตูุฑุฉ ููุจุฑุฉ ููุทุฉ"/>
</div>