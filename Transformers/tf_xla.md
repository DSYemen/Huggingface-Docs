# ุชูุงูู XLA ูููุงุฐุฌ TensorFlow

ุชุนุฏ Accelerated Linear Algebraุ ุงูุชู ูุทูู ุนูููุง XLAุ ูุชุฑุฌููุง ูุชุณุฑูุน ููุช ุงูุชุดุบูู ูููุงุฐุฌ TensorFlow. ูู [ุงููุซุงุฆู ุงูุฑุณููุฉ](https://www.tensorflow.org/xla):

XLA (Accelerated Linear Algebra) ูู ูุชุฑุฌู ุฎุงุต ุจุงููุฌุงู ููุฌุจุฑ ุงูุฎุทู ููููู ุชุณุฑูุน ููุงุฐุฌ TensorFlow ุฏูู ุฃู ุชุบููุฑุงุช ูุญุชููุฉ ูู ููุฏ ุงููุตุฏุฑ.

ุฅู ุงุณุชุฎุฏุงู XLA ูู TensorFlow ุฃูุฑ ุจุณูุท - ููู ูุฃุชู ูุถูููุง ุฏุงุฎู ููุชุจุฉ "ุชูุณูุฑููู"ุ ููููู ุชุดุบููู ุจุงุณุชุฎุฏุงู ูุณูุท "jit_compile" ูู ุฃู ุฏุงูุฉ ูุฅูุดุงุก ุงูุฑุณู ุงูุจูุงูู ูุซู ["tf.function"](https://www.tensorflow.org/guide/intro_to_graphs). ุนูุฏ ุงุณุชุฎุฏุงู ุฃุณุงููุจ Keras ูุซู "fit()" ู"predict()"ุ ููููู ุชูููู XLA ุจุจุณุงุทุฉ ุนู ุทุฑูู ุชูุฑูุฑ ูุณูุท "jit_compile" ุฅูู "model.compile()". ููุน ุฐููุ ูุง ุชูุชุตุฑ XLA ุนูู ูุฐู ุงูุฃุณุงููุจ - ูููู ุฃูุถูุง ุงุณุชุฎุฏุงููุง ูุชุณุฑูุน ุฃู ุฏุงูุฉ "tf.function" ุนุดูุงุฆูุฉ.

ุฃุนูุฏ ูุชุงุจุฉ ุงูุนุฏูุฏ ูู ุฃุณุงููุจ TensorFlow ูู ููุชุจุฉ ๐ค Transformers ูุชููู ูุชูุงููุฉ ูุน XLAุ ุจูุง ูู ุฐูู ุชูููุฏ ุงููุตูุต ูููุงุฐุฌ ูุซู [GPT2](https://huggingface.co/docs/transformers/model_doc/gpt2) ู[T5](https://huggingface.co/docs/transformers/model_doc/t5) ู[OPT](https://huggingface.co/docs/transformers/model_doc/opt)ุ ุจุงูุฅุถุงูุฉ ุฅูู ูุนุงูุฌุฉ ุงูููุงู ูููุงุฐุฌ ูุซู [Whisper](https://huggingface.co/docs/transformers/model_doc/whisper).

ูู ุญูู ุฃู ููุฏุงุฑ ุงูุชุณุฑูุน ูุนุชูุฏ ุชูุงููุง ุนูู ุงููููุฐุฌุ ููุฏ ูุงุญุธูุง ุชุณุฑูุนูุง ูุจูุบ ุญูุงูู 100 ุถุนููุง ูููุงุฐุฌ ุชูููุฏ ุงููุตูุต TensorFlow ุฏุงุฎู ููุชุจุฉ ๐ค Transformers. ุณุชุดุฑุญ ูุฐู ุงููุซููุฉ ููููุฉ ุงุณุชุฎุฏุงู XLA ููุฐู ุงูููุงุฐุฌ ููุญุตูู ุนูู ุฃูุตู ูุฏุฑ ูู ุงูุฃุฏุงุก. ููุง ุณููุฏู ุฑูุงุจุท ูููุงุฑุฏ ุฅุถุงููุฉ ุฅุฐุง ููุช ููุชููุง ุจูุนุฑูุฉ ุงููุฒูุฏ ุญูู ุงููุนุงููุฑ ุงูููุงุณูุฉ ูููุณูุฉ ุงูุชุตููู ุงูุฎุงุตุฉ ุจูุง ูุฑุงุก ุชูุงูู XLA.

## ุชุดุบูู ูุธุงุฆู TensorFlow ุจุงุณุชุฎุฏุงู XLA

ููุฃุฎุฐ ูู ุงูุงุนุชุจุงุฑ ุงููููุฐุฌ ุงูุชุงูู ูู TensorFlow:

```py
import tensorflow as tf

model = tf.keras.Sequential(
[tf.keras.layers.Dense(10, input_shape=(10,), activation="relu"), tf.keras.layers.Dense(5, activation="softmax")]
)
```

ููุจู ุงููููุฐุฌ ุฃุนูุงู ุฅุฏุฎุงูุงุช ุฐุงุช ุจุนุฏ `(10, )`. ูููููุง ุงุณุชุฎุฏุงู ุงููููุฐุฌ ูุชุดุบูู ุชูุฑูุฑ ููุฃูุงู ูุซู ูุง ููู:

```py
# Generate random inputs for the model.
batch_size = 16
input_vector_dim = 10
random_inputs = tf.random.normal((batch_size, input_vector_dim))

# Run a forward pass.
_ = model(random_inputs)
```

ูุชุดุบูู ุงูุชูุฑูุฑ ููุฃูุงู ุจุงุณุชุฎุฏุงู ุฏุงูุฉ ูุฌูุนุฉ ุจูุงุณุทุฉ XLAุ ุณูุญุชุงุฌ ุฅูู ุงูููุงู ุจูุง ููู:

```py
xla_fn = tf.function(model, jit_compile=True)
_ = xla_fn(random_inputs)
```

ุชูุณุชุฎุฏู ุฏุงูุฉ "call()" ุงูุงูุชุฑุงุถูุฉ ูููููุฐุฌ ูุชุฌููุน ุฑุณู ุจูุงูู ูู XLA. ูููู ุฅุฐุง ูุงู ููุงู ุฃู ุฏุงูุฉ ุฃุฎุฑู ูููููุฐุฌ ุชุฑูุฏ ุชุฌููุนูุง ูู XLAุ ูููููู ุฐูู ุจุงุณุชุฎุฏุงู ูุง ููู:

```py
my_xla_fn = tf.function(model.my_xla_fn, jit_compile=True)
```

## ุชุดุบูู ูููุฐุฌ ุชูููุฏ ูุต TensorFlow ุจุงุณุชุฎุฏุงู XLA ูู ๐ค Transformers

ูุชูููู ุงูุชูููุฏ ุงููุนุฌู ุจูุงุณุทุฉ XLA ุฏุงุฎู ููุชุจุฉ ๐ค Transformersุ ุชุญุชุงุฌ ุฅูู ุชุซุจูุช ุฅุตุฏุงุฑ ุญุฏูุซ ูู "transformers". ููููู ุชุซุจูุชู ุนู ุทุฑูู ุชุดุบูู ูุง ููู:

```bash
pip install transformers --upgrade
```

ุจุนุฏ ุฐููุ ููููู ุชุดุบูู ุงูููุฏ ุงูุชุงูู:

```py
import tensorflow as tf
from transformers import AutoTokenizer, TFAutoModelForCausalLM

# Will error if the minimal version of Transformers is not installed.
from transformers.utils import check_min_version

check_min_version("4.21.0")


tokenizer = AutoTokenizer.from_pretrained("openai-community/gpt2", padding_side="left", pad_token="</s>")
model = TFAutoModelForCausalLM.from_pretrained("openai-community/gpt2")
input_string = ["TensorFlow is"]

# One line to create an XLA generation function
xla_generate = tf.function(model.generate, jit_compile=True)

tokenized_input = tokenizer(input_string, return_tensors="tf")
generated_tokens = xla_generate(**tokenized_input, num_beams=2)

decoded_text = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)
print(f"Generated -- {decoded_text}")
# Generated -- TensorFlow is an open-source, open-source, distributed-source application # framework for the
```

ููุง ุชูุงุญุธุ ูุฅู ุชูููู XLA ุนูู "generate()" ูู ูุฌุฑุฏ ุณุทุฑ ูุงุญุฏ ูู ุงูููุฏ. ูุง ูุฒุงู ุจุงูู ุงูููุฏ ุฏูู ุชุบููุฑ. ููุน ุฐููุ ููุงู ุจุนุถ ุงูุฃุดูุงุก ุงูุชู ูุฌุจ ูุฑุงุนุงุชูุง ูู ููุชุทู ุงูููุฏ ุฃุนูุงู ูุงูุชู ุชุฎุต XLA ุชุญุฏูุฏูุง. ูุฌุจ ุฃู ุชููู ุนูู ุฏุฑุงูุฉ ุจุชูู ุงูุฃุดูุงุก ูุชุญููู ุงูุชุณุฑูุนุงุช ุงูุชู ูููู ุฃู ุชููุฑูุง XLA. ููุงูุด ูุฐู ุงูุฃููุฑ ูู ุงููุณู ุงูุชุงูู.

## ุงูุฃุดูุงุก ุงูุชู ูุฌุจ ูุฑุงุนุงุชูุง

ุนูุฏูุง ุชููู ุจุชูููุฐ ุฏุงูุฉ ูููููุฉ ูู XLA (ูุซู "xla_generate()" ุฃุนูุงู) ูููุฑุฉ ุงูุฃูููุ ูุณูู ุชุญุงูู ุฏุงุฎูููุง ุงุณุชูุชุงุฌ ุฑุณู ุงูุญุณุงุจุ ููู ูุง ูุณุชุบุฑู ููุชูุง ุทูููุงู. ุชูุนุฑู ูุฐู ุงูุนูููุฉ ุจุงุณู ["tracing"](https://www.tensorflow.org/guide/intro_to_graphs#when_is_a_function_tracing).

ูุฏ ุชูุงุญุธ ุฃู ููุช ุงูุชูููุฏ ููุณ ุณุฑูุนูุง. ูู ุชุญุชุงุฌ ุงูุงุณุชุฏุนุงุกุงุช ุงููุชุชุงููุฉ ูู "xla_generate()" (ุฃู ุฃู ุฏุงูุฉ ุฃุฎุฑู ูููููุฉ ูู XLA) ุฅูู ุงุณุชูุชุงุฌ ุฑุณู ุงูุญุณุงุจุ ุจุดุฑุท ุฃู ุชุชุจุน ุงูุฅุฏุฎุงูุงุช ุฅูู ุงูุฏุงูุฉ ููุณ ุงูุดูู ุงูุฐู ุชู ุจูุงุก ุฑุณู ุงูุญุณุงุจ ุจู ูู ุงูุจุฏุงูุฉ. ูู ุญูู ุฃู ูุฐุง ููุณ ูุดููุฉ ุจุงููุณุจุฉ ููุทุฑุงุฆู ุฐุงุช ุฃุดูุงู ุงูุฅุฏุฎุงู ุงูุซุงุจุชุฉ (ูุซู ุงูุตูุฑ)ุ ูุฌุจ ุงูุงูุชุจุงู ุฅุฐุง ููุช ุชุนูู ูุน ุทุฑุงุฆู ุฐุงุช ุฃุดูุงู ุฅุฏุฎุงู ูุชุบูุฑุฉ (ูุซู ุงููุต).

ูุถูุงู ุนูู "xla_generate()" ุฏุงุฆููุง ุจุฃุดูุงู ุฅุฏุฎุงู ูุชุทุงุจูุฉุ ููููู ุชุญุฏูุฏ ูุณูุทุงุช "padding" ุนูุฏ ุงุณุชุฏุนุงุก "tokenizer".

```py
import tensorflow as tf
from transformers import AutoTokenizer, TFAutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained("openai-community/gpt2", padding_side="left", pad_token="</s>")
model = TFAutoModelForCausalLM.from_pretrained("openai-community/gpt2")
input_string = ["TensorFlow is"]

xla_generate = tf.function(model.generate, jit_compile=True)

# Here, we call the tokenizer with padding options.
tokenized_input = tokenizer(input_string, pad_to_multiple_of=8, padding=True, return_tensors="tf")

generated_tokens = xla_generate(**tokenized_input, num_beams=2)
decoded_text = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)
print(f"Generated -- {decoded_text}")
```

ุจูุฐู ุงูุทุฑููุฉุ ููููู ุงูุชุฃูุฏ ูู ุฃู ุงูุฅุฏุฎุงูุงุช ุฅูู "xla_generate()" ุณุชุชููู ุฏุงุฆููุง ุฅุฏุฎุงูุงุช ุฐุงุช ุงูุดูู ุงูุฐู ุชู ุชุชุจุนูุง ุจูุ ููุง ูุคุฏู ุฅูู ุชุณุฑูุน ููุช ุงูุชูููุฏ. ููููู ุงูุชุญูู ูู ุฐูู ุจุงุณุชุฎุฏุงู ุงูููุฏ ุงูุชุงูู:

```py
import time
import tensorflow as tf
from transformers import AutoTokenizer, TFAutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained("openai-community/gpt2", padding_side="left", pad_token="</s>")
model = TFAutoModelForCausalLM.from_pretrained("openai-community/gpt2")

xla_generate = tf.function(model.generate, jit_compile=True)

for input_string in ["TensorFlow is", "TensorFlow is a", "TFLite is a"]:
tokenized_input = tokenizer(input_string, pad_to_multiple_of=8, padding=True, return_tensors="tf")
start = time.time_ns()
generated_tokens = xla_generate(**tokenized_input, num_beams=2)
end = time.time_ns()
print(f"Execution time -- {(end - start) / 1e6:.1f} ms\n")
```

ุนูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU) ูู ููุน Tesla T4ุ ููููู ุชููุน ุงููุฎุฑุฌุงุช ูุซู ูุง ููู:

```bash
Execution time -- 30819.6 ms

Execution time -- 79.0 ms

Execution time -- 78.9 ms
```

ุชููู ุงูุงุณุชุฏุนุงุก ุงูุฃูู ูู "xla_generate()" ูุณุชุบุฑู ููุชูุง ุทูููุงู ุจุณุจุจ ุงูุชุชุจุนุ ูููู ุงูุงุณุชุฏุนุงุกุงุช ุงููุชุชุงููุฉ ุฃุณุฑุน ุจูุซูุฑ. ุถุน ูู ุงุนุชุจุงุฑู ุฃู ุฃู ุชุบููุฑ ูู ุฎูุงุฑุงุช ุงูุชูููุฏ ูู ุฃู ููุทุฉ ุณูุคุฏู ุฅูู ุฅุนุงุฏุฉ ุงูุชุชุจุนุ ููุง ูุคุฏู ุฅูู ุจุทุก ููุช ุงูุชูููุฏ.

ูู ูุบุท ุฌููุน ุฎูุงุฑุงุช ุชูููุฏ ุงููุตูุต ุงูุชู ุชููุฑูุง ููุชุจุฉ ๐ค Transformers ูู ูุฐู ุงููุซููุฉ. ูุดุฌุนู ุนูู ูุฑุงุกุฉ ุงููุซุงุฆู ููุญุตูู ุนูู ุญุงูุงุช ุงุณุชุฎุฏุงู ูุชูุฏูุฉ.

## ููุงุฑุฏ ุฅุถุงููุฉ

ูุชุฑูู ููุง ุจุจุนุถ ุงูููุงุฑุฏ ุงูุฅุถุงููุฉ ุฅุฐุง ููุช ุชุฑุบุจ ูู ุงูุชุนูู ุฃูุซุฑ ูู XLA ูู ๐ค Transformers ูุจุดูู ุนุงู.

* [ูููุฑ ุฏูุชุฑ ุงูููุงุญุธุงุช ูุฐุง ูู Colab](https://colab.research.google.com/github/huggingface/blog/blob/main/notebooks/91_tf_xla_generate.ipynb) ุนุฑุถูุง ุชูุถูุญููุง ุชูุงุนูููุง ุฅุฐุง ููุช ุชุฑุบุจ ูู ุงูุนุจุซ ุจููุงุฐุฌ ุงูุชูููุฏ ุงููุชูุงููุฉ ูุน XLA (ูุซู [T5](https://huggingface.co/docs/transformers/model_doc/t5)) ูููุงุฐุฌ ุงูุชุฑููุฒ ูู ุงูุชุฑููุฒ (ูุซู [GPT2](https://huggingface.co/docs/transformers/model_doc/gpt2)).
* [ุชูุฏู ูุฐู ุงูุชุฏูููุฉ ูู ุงููุฏููุฉ](https://huggingface.co/blog/tf-xla-generate) ูุธุฑุฉ ุนุงูุฉ ุนูู ูุนุงููุฑ ุงูููุงุฑูุฉ ููููุงุฐุฌ ุงููุชูุงููุฉ ูุน XLA ุจุงูุฅุถุงูุฉ ุฅูู ููุฏูุฉ ุณููุฉ ุงูุงุณุชุฎุฏุงู ูู XLA ูู TensorFlow.
* [ุชูุงูุด ูุฐู ุงูุชุฏูููุฉ ูู ุงููุฏููุฉ](https://blog.tensorflow.org/2022/11/how-hugging-face-improved-text-generation-performance-with-xla.html) ููุณูุฉ ุงูุชุตููู ุงูุฎุงุตุฉ ุจูุง ูุฑุงุก ุฅุถุงูุฉ ุฏุนู XLA ุฅูู ููุงุฐุฌ TensorFlow ูู ๐ค Transformers.
* ุชุฏูููุงุช ููุตู ุจูุง ููุฒูุฏ ูู ุงูุชุนูู ุญูู XLA ูุฑุณูููุงุช TensorFlow ุจุดูู ุนุงู:
* [XLA: ูุชุฑุฌู ูุญุณู ูุชุนูู ุงูุขูุฉ](https://www.tensorflow.org/xla)
* [ููุฏูุฉ ุฅูู ุงูุฑุณูููุงุช ูtf.function](https://www.tensorflow.org/guide/intro_to_graphs)
* [ุฃุฏุงุก ุฃูุถู ูุน tf.function](https://www.tensorflow.org/guide/function)