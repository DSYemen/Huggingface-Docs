# ุชุญุณูู ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ูู ุฃุฌู ุงูุณุฑุนุฉ ูุงูุฐุงูุฑุฉ

ุชุชูุฏู ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ (LLMs) ูุซู GPT3/4ุ [Falcon](https://huggingface.co/tiiuae/falcon-40b)ุ ู [Llama](https://huggingface.co/meta-llama/Llama-2-70b-hf) ุจุณุฑุนุฉ ูู ูุฏุฑุชูุง ุนูู ุฃุฏุงุก ุงูููุงู ุงูุชู ุชุฑูุฒ ุนูู ุงูุฅูุณุงูุ ููุง ูุคูุฏ ููุณูุง ูุฃุฏูุงุช ุฃุณุงุณูุฉ ูู ุงูุตูุงุนุงุช ุงููุงุฆูุฉ ุนูู ุงููุนุฑูุฉ ุงูุญุฏูุซุฉ.

ููุน ุฐููุ ูุง ูุฒุงู ูุดุฑ ูุฐู ุงูููุงุฐุฌ ูู ุงูููุงู ุงููุงูุนูุฉ ููุซู ุชุญุฏููุง:

- ูุชุธูุฑ ููููุง ูุฅูุชุงุฌูุง ูููุต ูุดุจู ุงูุฅูุณุงูุ ุชุชุทูุจ ููุงุฐุฌ LLMs ุญุงูููุง ุฃู ุชุชููู ูู ูููุงุฑุงุช ุงููุนููุงุช (ุฑุงุฌุน [ูุงุจูุงู ูุขุฎุฑูู](https://arxiv.org/abs/2001.08361)ุ [ูู ูุขุฎุฑูู](https://arxiv.org/abs/2206.07682)). ููุฐุง ุจุฏูุฑู ูุฒูุฏ ูู ูุชุทูุจุงุช ุงูุฐุงูุฑุฉ ููุงุณุชูุชุงุฌ.

- ูู ุงูุนุฏูุฏ ูู ุงูููุงู ุงููุงูุนูุฉุ ุชุญุชุงุฌ ููุงุฐุฌ LLMs ุฅูู ูุนูููุงุช ุณูุงููุฉ ุดุงููุฉ. ูุชุทูุจ ุฐูู ูุฏุฑุฉ ุงููููุฐุฌ ุนูู ุฅุฏุงุฑุฉ ุชุณูุณูุงุช ุงูุฅุฏุฎุงู ุงูุทูููุฉ ุฌุฏูุง ุฃุซูุงุก ุงูุงุณุชุฏูุงู.

ุชููู ุตุนูุจุฉ ูุฐู ุงูุชุญุฏูุงุช ูู ุชุนุฒูุฒ ูุฏุฑุงุช LLMs ุงูุญุณุงุจูุฉ ูุงูุฐุงูุฑูุฉุ ุฎุงุตุฉ ุนูุฏ ุงูุชุนุงูู ูุน ุชุณูุณูุงุช ุงูุฅุฏุฎุงู ุงูููุณุนุฉ.

ูู ูุฐุง ุงูุฏูููุ ุณูุณุชุนุฑุถ ุงูุชูููุงุช ุงููุนุงูุฉ ููุดุฑ LLM ุจููุงุกุฉ:

1. **ุฏูุฉ ุฃูู:** ุฃุธูุฑุช ุงูุฃุจุญุงุซ ุฃู ุงูุนูู ุจุฏูุฉ ุฑูููุฉ ูุฎูุถุฉุ ููู [8 ุจุช ู4 ุจุช](./main_classes/quantization.md)ุ ูููู ุฃู ูุญูู ูุฒุงูุง ุญุณุงุจูุฉ ุฏูู ุงูุฎูุงุถ ูุจูุฑ ูู ุฃุฏุงุก ุงููููุฐุฌ.

2. **ุงูุงูุชุจุงู ุงูุณุฑูุน:** ุงูุงูุชุจุงู ุงูุณุฑูุน ูู ุชูููุน ูุฎูุงุฑุฒููุฉ ุงูุงูุชุจุงู ุงูุชู ูุง ุชููุฑ ููุท ููุฌูุง ุฃูุซุฑ ููุงุกุฉ ูู ุงุณุชุฎุฏุงู ุงูุฐุงูุฑุฉุ ูููููุง ุชุญูู ุฃูุถูุง ููุงุกุฉ ุฃุนูู ุจุณุจุจ ุงูุงุณุชุฎุฏุงู ุงูุฃูุซู ูุฐุงูุฑุฉ GPU.

3. **ุงูุงุจุชูุงุฑุงุช ุงููุนูุงุฑูุฉ:** ุจุงููุธุฑ ุฅูู ุฃู ููุงุฐุฌ LLMs ูุชู ูุดุฑูุง ุฏุงุฆููุง ุจููุณ ุงูุทุฑููุฉ ุฃุซูุงุก ุงูุงุณุชุฏูุงูุ ุฃู ุชูููุฏ ูุต ุชููุงุฆู ูุน ุณูุงู ุฅุฏุฎุงู ุทูููุ ููุฏ ุชู ุงูุชุฑุงุญ ุจููุงุช ูููุฐุฌ ูุชุฎุตุตุฉ ุชุณูุญ ุจุงูุงุณุชุฏูุงู ุงูุฃูุซุฑ ููุงุกุฉ. ุฃูู ุชูุฏู ูู ุจููุงุช ุงูููุงุฐุฌ ููุง ูู [ุนุฐุฑ](https://arxiv.org/abs/2108.12409)ุ [ุงูุชุฑููุฒุงุช ุงูุฏูุงุฑุฉ](https://arxiv.org/abs/2104.09864)ุ [ุงูุงูุชูุงู ูุชุนุฏุฏ ุงูุงุณุชุนูุงูุงุช (MQA)](https://arxiv.org/abs/1911.02150) ู [ูุฌููุนุฉ ุงูุงูุชูุงู ุจุงูุงุณุชุนูุงู (GQA)](https://arxiv.org/abs/2305.13245).

ุนูู ูุฏุงุฑ ูุฐุง ุงูุฏูููุ ุณููุฏู ุชุญููููุง ููุชูููุฏ ุงูุชููุงุฆู ูู ููุธูุฑ tensor. ูุชุนูู ูู ูุฒุงูุง ูุนููุจ ุงุนุชูุงุฏ ุงูุฏูุฉ ุงูููุฎูุถุฉุ ูููุฏู ุงุณุชูุดุงููุง ุดุงูููุง ูุฎูุงุฑุฒููุงุช ุงูุงูุชูุงู ุงูุฃุญุฏุซุ ูููุงูุด ุจููุงุช LLM ุงููุญุณูุฉ. ุฃุซูุงุก ุงูููุงู ุจุฐููุ ูููู ุจุชุดุบูู ุฃูุซูุฉ ุนูููุฉ ุชูุถุญ ูู ุชุญุณููุงุช ุงูููุฒุงุช.
## 1. ุงูุฎูุงุถ ุงูุฏูุฉ

ูููู ููู ูุชุทูุจุงุช ุงูุฐุงูุฑุฉ ุงูุฎุงุตุฉ ุจู LLMs ุจุดูู ุฃูุถู ูู ุฎูุงู ุงููุธุฑ ุฅูู LLM ููุฌููุนุฉ ูู ุงููุตูููุงุช ูุงููุชุฌูุงุช ุงููุฒููุฉุ ูุฅุฏุฎุงูุงุช ุงููุต ูุชุณูุณู ูู ุงููุชุฌูุงุช. ูููุง ูููุ ุณูุชู ุงุณุชุฎุฏุงู ุชุนุฑูู "ุงูุฃูุฒุงู" ููุฅุดุงุฑุฉ ุฅูู ุฌููุน ูุตูููุงุช ุงูุฃูุฒุงู ูุงููุชุฌูุงุช ูู ุงููููุฐุฌ.

ูู ููุช ูุชุงุจุฉ ูุฐุง ุงูุฏูููุ ุชุชููู LLMs ูู ูููุงุฑู ูุนููุฉ ุนูู ุงูุฃูู. ูุชููู ูู ูุนููุฉ ูู ุฑูู ุนุดุฑูุ ุนูู ุณุจูู ุงููุซุงู "4.5689" ูุงูุฐู ูุชู ุชุฎุฒููู ุนุงุฏุฉู ุจุชูุณูู float32 ุฃู bfloat16 ุฃู float16. ูุณูุญ ููุง ูุฐุง ุจุญุณุงุจ ูุชุทูุจุงุช ุงูุฐุงูุฑุฉ ูุชุญููู LLM ูู ุงูุฐุงูุฑุฉ ุจุณูููุฉ:

> *ูุชุทูุจ ุชุญููู ุฃูุฒุงู ูููุฐุฌ ูุญุชูู ุนูู X ูููุงุฑ ูุนููุฉ ุญูุงูู 4 * X ุฌูุฌุงุจุงูุช ูู VRAM ุจุฏูุฉ float32*

ููุน ุฐููุ ูุงุฏุฑูุง ูุง ูุชู ุชุฏุฑูุจ ุงูููุงุฐุฌ ุญุงูููุง ุจุฏูุฉ float32 ุงููุงููุฉุ ูููู ุนุงุฏุฉ ูุง ุชููู ุจุฏูุฉ bfloat16 ุฃูุ ุจุดูู ุฃูู ุชูุฑุงุฑูุงุ ุจุฏูุฉ float16. ูุฐููุ ุชุตุจุญ ุงููุงุนุฏุฉ ุงูุนุงูุฉ ูุง ููู:

> *ูุชุทูุจ ุชุญููู ุฃูุฒุงู ูููุฐุฌ ูุญุชูู ุนูู X ูููุงุฑ ูุนููุฉ ุญูุงูู 2 * X ุฌูุฌุงุจุงูุช ูู VRAM ุจุฏูุฉ bfloat16/float16*

ุจุงููุณุจุฉ ูุฅุฏุฎุงูุงุช ุงููุต ุงูุฃูุตุฑ (ุฃูู ูู 1024 ุฑูุฒูุง)ุ ูุฅู ูุชุทูุจุงุช ุงูุฐุงูุฑุฉ ููุงุณุชูุชุงุฌ ุชูููู ุนูููุง ุฅูู ุญุฏ ูุจูุฑ ูุชุทูุจุงุช ุงูุฐุงูุฑุฉ ูุชุญููู ุงูุฃูุฒุงู. ูุฐููุ ุฏุนูุง ููุชุฑุถ ุงูุขู ุฃู ูุชุทูุจุงุช ุงูุฐุงูุฑุฉ ููุงุณุชูุชุงุฌ ุชุณุงูู ูุชุทูุจุงุช ุงูุฐุงูุฑุฉ ูุชุญููู ุงููููุฐุฌ ูู VRAM GPU.

ูุฅุนุทุงุก ุจุนุถ ุงูุฃูุซูุฉ ุนูู ููุฏุงุฑ VRAM ุงูุฐู ูุณุชุบุฑูู ุชุญููู ูููุฐุฌ ูู bfloat16 ุชูุฑูุจูุง:

- **GPT3** ูุชุทูุจ 2 * 175 ุฌูุฌุงุจุงูุช = **350 ุฌูุฌุงุจุงูุช** VRAM
- **Bloom** ูุชุทูุจ 2 * 176 ุฌูุฌุงุจุงูุช = **352 ุฌูุฌุงุจุงูุช** VRAM
- **Llama-2-70b** ูุชุทูุจ 2 * 70 ุฌูุฌุงุจุงูุช = **140 ุฌูุฌุงุจุงูุช** VRAM
- **Falcon-40b** ูุชุทูุจ 2 * 40 ุฌูุฌุงุจุงูุช = **80 ุฌูุฌุงุจุงูุช** VRAM
- **MPT-30b** ูุชุทูุจ 2 * 30 ุฌูุฌุงุจุงูุช = **60 ุฌูุฌุงุจุงูุช** VRAM
- **bigcode/starcoder** ูุชุทูุจ 2 * 15.5 = **31 ุฌูุฌุงุจุงูุช** VRAM

ุงุนุชุจุงุฑูุง ูู ูุชุงุจุฉ ูุฐู ุงููุซููุฉุ ุชุนุฏ ุดุฑูุญุฉ GPU A100 & H100 ุงูุฃูุจุฑ ูู ุงูุณููุ ุญูุซ ุชูุฏู 80 ุฌูุฌุงุจุงูุช ูู VRAM. ุชุชุทูุจ ูุนุธู ุงูููุงุฐุฌ ุงููุฏุฑุฌุฉ ุณุงุจููุง ุฃูุซุฑ ูู 80 ุฌูุฌุงุจุงูุช ูุชุญููููุงุ ูุจุงูุชุงูู ููู ุชุชุทูุจ ุจุงูุถุฑูุฑุฉ ููุงุฒุงุฉ tensor ู/ุฃู ููุงุฒุงุฉ ุฎุท ุงูุฃูุงุจูุจ.

๐ค ูุง ูุฏุนู Transformers ููุงุฒุงุฉ tensor ุฎุงุฑุฌ ุงูุตูุฏูู ูุฃูู ูุชุทูุจ ูุชุงุจุฉ ุจููุฉ ุงููููุฐุฌ ุจุทุฑููุฉ ูุญุฏุฏุฉ. ุฅุฐุง ููุช ููุชููุง ุจูุชุงุจุฉ ููุงุฐุฌ ุจุทุฑููุฉ ููุงุฆูุฉ ูููุงุฒุงุฉ tensorุ ููุง ุชุชุฑุฏุฏ ูู ุฅููุงุก ูุธุฑุฉ ุนูู [ููุชุจุฉ ุงูุงุณุชุฏูุงู ุจุชูููุฏ ุงููุต](https://github.com/huggingface/text-generation-inference/tree/main/server/text_generation_server/models/custom_modeling).

ูุชู ุฏุนู ููุงุฒุงุฉ ุฎุท ุงูุฃูุงุจูุจ ุงูุจุณูุทุฉ ุฎุงุฑุฌ ุงูุตูุฏูู. ููููุงู ุจุฐููุ ูู ุจุชุญููู ุงููููุฐุฌ ุจุงุณุชุฎุฏุงู "device="auto"" ูุงูุฐู ุณูููู ุชููุงุฆููุง ุจูุถุน ุงูุทุจูุงุช ุงููุฎุชููุฉ ุนูู ูุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณููุงุช ุงููุชููุฑุฉ ููุง ูู ููุถุญ [ููุง](https://huggingface.co/docs/accelerate/v0.22.0/en/concept_guides/big_model_inference).

ููุน ุฐููุ ูุงุญุธ ุฃูู ูู ุญูู ุฃู ููุงุฒุงุฉ ุฎุท ุงูุฃูุงุจูุจ ุงูุจุณูุทุฉ ูุนุงูุฉ ููุบุงูุฉุ ุฅูุง ุฃููุง ูุง ุชุนุงูุฌ ูุดููุงุช ุนุฏู ูุดุงุท GPU. ุจุงููุณุจุฉ ููุฐุง ุงูุฃูุฑุ ุชููู ููุงุฒุงุฉ ุฎุท ุงูุฃูุงุจูุจ ุงูุฃูุซุฑ ุชูุฏููุง ูุทููุจุฉ ููุง ูู ููุถุญ [ููุง](https://huggingface.co/docs/transformers/en/perf_train_gpu_many#naive-model-parallelism-vertical-and-pipeline-parallelism).

ุฅุฐุง ูุงู ูุฏูู ุญู ุงููุตูู ุฅูู ุนูุฏุฉ 8 x 80GB A100ุ ูููููู ุชุญููู BLOOM ุนูู ุงููุญู ุงูุชุงูู:

```python
!pip install transformers accelerate bitsandbytes optimum
```

```python
from transformers import AutoModelForCausalLM

model = AutoModelForCausalLM.from_pretrained("bigscience/bloom", device_map="auto", pad_token_id=0)
```

ูู ุฎูุงู ุงุณุชุฎุฏุงู "device_map="auto""ุ ุณูุชู ุชูุฒูุน ุทุจูุงุช ุงูุงูุชูุงู ุจุงูุชุณุงูู ุนูู ุฌููุน ูุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณููุงุช ุงููุชููุฑุฉ.

ูู ูุฐุง ุงูุฏูููุ ุณูุณุชุฎุฏู [bigcode/octocoder](https://huggingface.co/bigcode/octocoder) ูุฃูู ูููู ุชุดุบููู ุนูู ุดุฑูุญุฉ ุฌูุงุฒ GPU A100 ูุงุญุฏุฉ ุจุณุนุฉ 40 ุฌูุฌุงุจุงูุช. ูุงุญุธ ุฃู ุฌููุน ุชุญุณููุงุช ุงูุฐุงูุฑุฉ ูุงูุณุฑุนุฉ ุงูุชู ุณูุทุจููุง ูู ุงูุขู ูุตุงุนุฏูุง ุชูุทุจู ุจุงูุชุณุงูู ุนูู ุงูููุงุฐุฌ ุงูุชู ุชุชุทูุจ ููุงุฒุงุฉ ุงูููุงุฐุฌ ุฃู ููุงุฒุงุฉ tensor.

ูุธุฑูุง ูุฃู ุงููููุฐุฌ ูุญูู ุจุฏูุฉ bfloat16ุ ููู ุงููุชููุน ุฃู ุชููู ูุชุทูุจุงุช ุงูุฐุงูุฑุฉ ูุชุดุบูู ุงูุงุณุชุฏูุงู ุจุงุณุชุฎุฏุงู "bigcode/octocoder" ุญูุงูู 31 ุฌูุฌุงุจุงูุช ูู VRAM ููููุง ููุงุนุฏุชูุง ุงูุนุงูุฉ ุฃุนูุงู. ุฏุนูุง ูุฌุฑุจ ุฐูู.

ุฃููุงูุ ูููู ุจุชุญููู ุงููููุฐุฌ ูุงููุญูู ุงููุบูู ุซู ูููู ุจุชูุฑูุฑููุง ุฅูู ูุงุฆู [pipeline](https://huggingface.co/docs/transformers/main_classes/pipelines) ูู Transformers.

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
import torch

model = AutoModelForCausalLM.from_pretrained("bigcode/octocoder", torch_dtype=torch.bfloat16, device_map="auto", pad_token_id=0)
tokenizer = AutoTokenizer.from_pretrained("bigcode/octocoder")

pipe = pipeline("text-generation", model=model, tokenizer=tokenizer)
```

```python
prompt = "Question: Please write a function in Python that transforms bytes to Giga bytes.\n\nAnswer:"

result = pipe(prompt, max_new_tokens=60)[0]["generated_text"][len(prompt):]
result
```

**ุงูุฅุฎุฑุงุฌ**:

```
Here is a Python function that transforms bytes to Giga bytes:

```python
def bytes_to_giga_bytes(bytes):
    return bytes / 1024 / 1024 / 1024
```

This function takes a single
```

ุฑุงุฆุนุ ูููููุง ุงูุขู ุงุณุชุฎุฏุงู ุงููุชูุฌุฉ ูุจุงุดุฑุฉ ูุชุญููู ุงูุจุงูุช ุฅูู ุฌูุฌุงุจุงูุช.

```python
def bytes_to_giga_bytes(bytes):
    return bytes / 1024 / 1024 / 1024
```

ุฏุนููุง ูุณุชุฏุนู [`torch.cuda.max_memory_allocated`](https://pytorch.org/docs/stable/generated/torch.cuda.max_memory_allocated.html) ูููุงุณ ุฐุฑูุฉ ุชุฎุตูุต ุฐุงูุฑุฉ GPU.

```python
bytes_to_giga_bytes(torch.cuda.max_memory_allocated())
```

**ุงูุฅุฎุฑุงุฌ**:

```bash
29.0260648727417
```

ูุฑูุจ ุจูุง ูููู ูู ุญุณุงุจูุง ุงูุชูุฑูุจู! ูููููุง ุฃู ูุฑู ุฃู ุงูุฑูู ุบูุฑ ุตุญูุญ ุชูุงููุง ูุฃู ุงูุงูุชูุงู ูู ุงูุจุงูุช ุฅูู ุงูููููุจุงูุช ูุชุทูุจ ุถุฑุจ 1024 ุจุฏูุงู ูู 1000. ูุฐููุ ูููู ุฃูุถูุง ููู ุตูุบุฉ ุงูุญุณุงุจ ุงูุชูุฑูุจู ุนูู ุฃููุง ุญุณุงุจ "ุจุญุฏ ุฃูุตู X ุฌูุฌุงุจุงูุช".

ูุงุญุธ ุฃูู ุฅุฐุง ุญุงูููุง ุชุดุบูู ุงููููุฐุฌ ุจุฏูุฉ float32 ุงููุงููุฉุ ูุณุชููู ููุงู ุญุงุฌุฉ ุฅูู 64 ุฌูุฌุงุจุงูุช ูู VRAM.

> ูุชู ุชุฏุฑูุจ ุฌููุน ุงูููุงุฐุฌ ุชูุฑูุจูุง ูู bfloat16 ูุฐู ุงูุฃูุงูุ ููุง ููุฌุฏ ุณุจุจ ูุชุดุบูู ุงููููุฐุฌ ุจุฏูุฉ float32 ุงููุงููุฉ ุฅุฐุง [ูุงูุช ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช ุงูุฎุงุตุฉ ุจู ุชุฏุนู bfloat16](https://discuss.pytorch.org/t/bfloat16-native-support/117155/5). ูู ุชููุฑ float32 ูุชุงุฆุฌ ุงุณุชุฏูุงู ุฃูุถู ูู ุงูุฏูุฉ ุงูุชู ุชู ุงุณุชุฎุฏุงููุง ูุชุฏุฑูุจ ุงููููุฐุฌ.

ุฅุฐุง ูู ุชูู ูุชุฃูุฏูุง ูู ุชูุณูู ุชุฎุฒูู ุฃูุฒุงู ุงููููุฐุฌ ุนูู Hubุ ูููููู ุฏุงุฆููุง ุงูุงุทูุงุน ุนูู ุชูููู ููุทุฉ ุงูุชูุชูุด ูู "torch_dtype"ุ ุนูู ุณุจูู ุงููุซุงู [ููุง](https://huggingface.co/meta-llama/Llama-2-7b-hf/blob/6fdf2e60f86ff2481f2241aaee459f85b5b0bbb9/config.json#L21). ููุตู ุจุชุนููู ุงููููุฐุฌ ุฅูู ููุณ ููุน ุงูุฏูุฉ ุงููุญุฏุฏ ูู ุงูุชูููู ุนูุฏ ุงูุชุญููู ุจุงุณุชุฎุฏุงู "from_pretrained(..., torch_dtype=...)" ุจุงุณุชุซูุงุก ุนูุฏูุง ูููู ุงูููุน ุงูุฃุตูู ูู float32ุ ููู ูุฐู ุงูุญุงูุฉ ูููู ุงุณุชุฎุฏุงู "float16" ุฃู "bfloat16" ููุงุณุชุฏูุงู.

ุฏุนููุง ูุญุฏุฏ ูุธููุฉ "flush (...)" ูุชุญุฑูุฑ ุฌููุน ุงูุฐุงูุฑุฉ ุงููุฎุตุตุฉ ุจุญูุซ ูููููุง ููุงุณ ุฐุฑูุฉ ุฐุงูุฑุฉ GPU ุงููุฎุตุตุฉ ุจุฏูุฉ.

```python
del pipe
del model

import gc
import torch

def flush():
    gc.collect()
    torch.cuda.empty_cache()
    torch.cuda.reset_peak_memory_stats()
```

ุฏุนููุง ูุณุชุฏุนูู ุงูุขู ููุชุฌุฑุจุฉ ุงูุชุงููุฉ.

```python
flush()
```

ูู ุงูุฅุตุฏุงุฑ ุงูุฃุฎูุฑ ูู ููุชุจุฉ accelerateุ ููููู ุฃูุถูุง ุงุณุชุฎุฏุงู ุทุฑููุฉ ูุณุงุนุฏุฉ ุชุณูู "release_memory()"

```python
from accelerate.utils import release_memory
# ...

release_memory(model)
```

ุงูุขูุ ูุงุฐุง ูู ูู ููู ูุฏู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช ุงูุฎุงุตุฉ ุจู 32 ุฌูุฌุงุจุงูุช ูู VRAMุ ููุฏ ุชุจูู ุฃู ุฃูุฒุงู ุงูููุงุฐุฌ ูููู ุชุญููููุง ุฅูู 8 ุจุชุงุช ุฃู 4 ุจุชุงุช ุฏูู ุฎุณุงุฑุฉ ูุจูุฑุฉ ูู ุงูุฃุฏุงุก (ุฑุงุฌุน [Dettmers et al.](https://arxiv.org/abs/2208.07339)).

ูููู ุชุญููู ุงููููุฐุฌ ุฅูู 3 ุฃู 2 ุจุช ูุน ุฎุณุงุฑุฉ ููุจููุฉ ูู ุงูุฃุฏุงุก ููุง ูู ููุถุญ ูู ูุฑูุฉ GPTQ ุงูุฃุฎูุฑุฉ [ููุง](https://arxiv.org/abs/2210.17323) ๐คฏ.

ุจุฏูู ุงูุฏุฎูู ูู ุงููุซูุฑ ูู ุงูุชูุงุตููุ ุชูุฏู ูุฎุทุทุงุช ุงูุชูููู ุฅูู ุชูููู ุฏูุฉ ุงูุฃูุฒุงู ูุน ูุญุงููุฉ ุงูุญูุงุธ ุนูู ุฏูุฉ ูุชุงุฆุฌ ุงูุงุณุชุฏูุงู ูู ุงููููุฐุฌ (*ุงููุนุฑูู ุฃูุถูุง ุจุงุณู* ุฃูุฑุจ ูุง ูููู ุฅูู bfloat16).

ูุงุญุธ ุฃู ุงูุชูููู ูุนูู ุจุดูู ุฌูุฏ ุฎุงุตุฉ ูุชูููุฏ ุงููุต ูุฃู ูู ูุง ููุชู ุจู ูู ุงุฎุชูุงุฑ *ูุฌููุนุฉ ุงูุฑููุฒ ุงูุฃูุซุฑ ุงุญุชูุงููุง ุงูุชุงููุฉ* ููุง ููุชู ุญููุง ุจุงูููู ุงูุฏูููุฉ ูุชูุฒูุน ุงูุฑูุฒ ุงูุชุงูู *ููุบุงุฑูุชู*.

ูู ูุง ููู ูู ุฃู ุชูุฒูุน ุงูุฑูุฒ ุงูุชุงูู *ููุบุงุฑูุชู* ูุธู ููุง ูู ุชูุฑูุจูุง ุจุญูุซ ุชุนุทู ุนูููุฉ "argmax" ุฃู "topk" ููุณ ุงููุชุงุฆุฌ.

ููุงู ุชูููุงุช ุชูููู ูุฎุชููุฉุ ูุงูุชู ูู ููุงูุดูุง ุจุงูุชูุตูู ููุงุ ูููู ุจุดูู ุนุงูุ ุชุนูู ุฌููุน ุชูููุงุช ุงูุชูููู ุนูู ุงููุญู ุงูุชุงูู:

1. ูู ุจุชุญููู ุฌููุน ุงูุฃูุฒุงู ุฅูู ุงูุฏูุฉ ุงููุณุชูุฏูุฉ
2. ูู ุจุชุญููู ุงูุฃูุฒุงู ุงููุญููุฉุ ููุฑุฑ ุชุณูุณู ุงูุฅุฏุฎุงู ูู ุงููุชุฌูุงุช ุจุฏูุฉ bfloat16
3. ูู ุจุฅูุบุงุก ุชุญููู ุงูุฃูุฒุงู ุฏููุงูููููุง ุฅูู bfloat16 ูุฅุฌุฑุงุก ุงูุญุณุงุจ ูุน ูุชุฌูุงุช ุงูุฅุฏุฎุงู ุงูุฎุงุตุฉ ุจูุง ุจุฏูุฉ bfloat16

ุจุงุฎุชุตุงุฑุ ูุฐุง ูุนูู ุฃู ุนูููุงุช ุถุฑุจ *ูุตูููุฉ ุงูุฅุฏุฎุงู-ุงููุฒู*ุ ูุน \\( X \\) ููููุง *ุงูุฅุฏุฎุงูุงุช*ุ \\( W \\) ููููุง ูุตูููุฉ ุงูุฃูุฒุงู ู \\( Y \\) ููููุง ุงูุฅุฎุฑุงุฌ:

$$ Y = X * W $$

ูุชู ุชุบููุฑูุง ุฅูู:

$$ Y = X * \text{dequantize}(W) $$

ุจุงููุณุจุฉ ููู ุถุฑุจ ูููุตูููุฉ. ูุชู ุชูููุฐ ุฅูุบุงุก ุงูุชุญููู ูุฅุนุงุฏุฉ ุงูุชุญููู ุจุงูุชุชุงุจุน ูุฌููุน ูุตูููุงุช ุงูุฃูุฒุงู ุฃุซูุงุก ุชุดุบูู ุงูุฅุฏุฎุงูุงุช ุฎูุงู ูุฎุทุท ุงูุดุจูุฉ.

ูุฐููุ ุบุงูุจูุง ูุง ูุง ูุชู ุชูููู ููุช ุงูุงุณุชุฏูุงู ุนูุฏ ุงุณุชุฎุฏุงู ุงูุฃูุฒุงู ุงููุญููุฉุ ููููู ูุฒูุฏ ุจุฏูุงู ูู ุฐูู.

ููู ูุธุฑูุฉุ ุฏุนููุง ูุฌุฑุจ ุฐูู! ูุชุญููู ุฃูุฒุงู ุงููููุฐุฌ ุจุงุณุชุฎุฏุงู Transformersุ ุชุญุชุงุฌ ุฅูู ุงูุชุฃูุฏ ูู ุชุซุจูุช ููุชุจุฉ [`bitsandbytes`](https://github.com/TimDettmers/bitsandbytes).

```bash
!pip install bitsandbytes
```

ุจุนุฏ ุฐููุ ูููููุง ุชุญููู ุงูููุงุฐุฌ ูู ุชูููู 8 ุจุชุงุช ุจุจุณุงุทุฉ ุนู ุทุฑูู ุฅุถุงูุฉ ุนูู "load_in_8bit=True" ุฅูู "from_pretrained".

```python
model = AutoModelForCausalLM.from_pretrained("bigcode/octocoder", load_in_8bit=True, pad_token_id=0)
```

ุงูุขูุ ุฏุนููุง ูุฌุฑู ูุซุงููุง ูุฑุฉ ุฃุฎุฑู ููููุณ ุงุณุชุฎุฏุงู ุงูุฐุงูุฑุฉ.

```python
pipe = pipeline("text-generation", model=model, tokenizer=tokenizer)

result = pipe(prompt, max_new_tokens=60)[0]["generated_text"][len(prompt):]
result
```

**ุงูุฅุฎุฑุงุฌ**:

```
Here is a Python function that transforms bytes to Giga bytes:

```python
def bytes_to_giga_bytes(bytes):
    return bytes / 1024 / 1024 / 1024
```

This function takes a single
```

ุฑุงุฆุนุ ูุญุตู ุนูู ููุณ ุงููุชูุฌุฉ ููุง ูู ุงูุณุงุจูุ ูุฐุง ูุง ููุฌุฏ ููุฏุงู ูู ุงูุฏูุฉ! ุฏุนูุง ูุฑู ููุฏุงุฑ ุงูุฐุงูุฑุฉ ุงูุชู ุชู ุงุณุชุฎุฏุงููุง ูุฐู ุงููุฑุฉ.

```python
bytes_to_giga_bytes(torch.cuda.max_memory_allocated())
```

**ุงูุฅุฎุฑุงุฌ**:

```
15.219234466552734
```

ุฃูู ุจูุซูุฑ! ููุฏ ุงูุฎูุถูุง ุฅูู ูุฌุฑุฏ ุฃูุซุฑ ูู 15 ุฌูุฌุงุจุงูุชุ ูุจุงูุชุงูู ูููููุง ุชุดุบูู ูุฐุง ุงููููุฐุฌ ุนูู ูุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณููุงุช ุงูุงุณุชููุงููุฉ ูุซู 4090.

ุฅููุง ูุฑู ููุณุจูุง ุฌูุฏูุง ูู ููุงุกุฉ ุงูุฐุงูุฑุฉ ููุง ููุฌุฏ ุชุฏููุฑ ูุฐูุฑ ูู ุฅุฎุฑุงุฌ ุงููููุฐุฌ. ููุน ุฐููุ ูููููุง ุฃูุถูุง ููุงุญุธุฉ ุชุจุงุทุค ุทููู ุฃุซูุงุก ุงูุงุณุชุฏูุงู.

ูููู ุจุญุฐู ุงูููุงุฐุฌ ูุฅูุฑุงุบ ุงูุฐุงูุฑุฉ ูุฑุฉ ุฃุฎุฑู.

```python
del model
del pipe
```

```python
flush()
```

ุฏุนููุง ูุฑู ูุง ูุณุชูููู ุฐุฑูุฉ ุฐุงูุฑุฉ GPU ุนูุฏ ุงูุชุญููู ุฅูู 4 ุจุชุงุช. ูููู ุชุญููู ุงููููุฐุฌ ุฅูู 4 ุจุชุงุช ุจุงุณุชุฎุฏุงู ููุณ ูุงุฌูุฉ ุจุฑูุฌุฉ ุงูุชุทุจููุงุช ููุง ูู ููุถุญ ุณุงุจููุง - ูุฐู ุงููุฑุฉ ุนู ุทุฑูู ุชูุฑูุฑ "load_in_4bit=True" ุจุฏูุงู ูู "load_in_8bit=True".

```python
model = AutoModelForCausalLM.from_pretrained("bigcode/octocoder", load_in_4bit=True, low_cpu_mem_usage=True, pad_token_id=0)

pipe = pipeline("text-generation", model=model, tokenizer=tokenizer)

result = pipe(prompt, max_new_tokens=60)[0]["generated_text"][len(prompt):]
result
```

**ุงูุฅุฎุฑุงุฌ**:

```
Here is a Python function that transforms bytes to Giga bytes:

```python
ndef bytes_to_gigabytes(bytes):
    return bytes / 1024 / 1024 / 1024
```

This function takes a single argument
```

ูุญู ูุฑู ููุณ ุฅุฎุฑุงุฌ ุงููุต ุชูุฑูุจูุง ููุง ูู ุงูุญุงู ูุจู - ููุท "python" ููููุฏ ูุจู ููุชุทู ุงูููุฏ. ุฏุนููุง ูุฑู ููุฏุงุฑ ุงูุฐุงูุฑุฉ ุงููุทููุจุฉ.

```python
bytes_to_giga_bytes(torch.cuda.max_memory_allocated())
```

**ุงูุฅุฎุฑุงุฌ**:

```
9.543574333190918
```

ูุฌุฑุฏ 9.5 ุฌูุฌุงุจุงูุช! ูุฐุง ููุณ ูุซูุฑูุง ุจุงููุณุจุฉ ููููุฐุฌ ูุญุชูู ุนูู ุฃูุซุฑ ูู 15 ูููุงุฑ ูุนููุฉ.
## 2. ููุงุด ุฃุชูุดู

ุชุชุดุงุฑู ุฃูุถู ููุงุฐุฌ ุงููุบุฉ ุงููุงุฆูุฉ ุนูู ุงูุฐูุงุก ุงูุงุตุทูุงุนู ุญุงูููุง ูู ููุณ ุงูุจููุฉ ุงูุฃุณุงุณูุฉ ุงูุชู ุชุชููู ูู ุทุจูุงุช ุงูุชุบุฐูุฉ ุงูุฃูุงููุฉุ ูุทุจูุงุช ุงูุชูุดูุทุ ูุทุจูุงุช ุงูุชูุญูุฏ ุงูููุงุณู ููุทุจูุงุชุ ูุงูุฃูู ูู ุฐููุ ุทุจูุงุช ุงูุฃุชูุชุฉ ุงูุฐุงุชูุฉ.

ุชูุนุฏ ุทุจูุงุช ุงูุฃุชูุชุฉ ุงูุฐุงุชูุฉ ุฃุณุงุณูุฉ ูู ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ุญูุซ ุชููููู ุงููููุฐุฌ ูู ููู ุงูุนูุงูุงุช ุงูุณูุงููุฉ ุจูู ุฑููุฒ ุงูุฅุฏุฎุงู.

ููุน ุฐููุ ูุฅู ุฐุฑูุฉ ุงุณุชููุงู ุฐุงูุฑุฉ ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU) ูุทุจูุงุช ุงูุฃุชูุชุฉ ุงูุฐุงุชูุฉ ุชููู ุจุดูู ุชุฑุจูุนู ูู ูู ูู ุชุนููุฏ ุงูุญุณุงุจ ูุงูุฐุงูุฑุฉ ูุน ุนุฏุฏ ุฑููุฒ ุงูุฅุฏุฎุงู (ููุทูู ุนููู ุฃูุถูุง ุทูู ุงูุชุณูุณู) ูุงูุฐู ูุฑูุฒ ุฅููู ูููุง ููู ุจู (N).

ููู ุญูู ุฃู ูุฐุง ููุณ ููุญูุธูุง ุญููุง ุจุงููุณุจุฉ ูุชุณูุณูุงุช ุงูุฅุฏุฎุงู ุงูุฃูุตุฑ (ุญุชู 1000 ุฑูุฒ ุฅุฏุฎุงู)ุ ูุฅูู ูุตุจุญ ูุดููุฉ ุฎุทูุฑุฉ ุจุงููุณุจุฉ ูุชุณูุณูุงุช ุงูุฅุฏุฎุงู ุงูุฃุทูู (ุญูุงูู 16000 ุฑูุฒ ุฅุฏุฎุงู).

ุฏุนููุง ูููู ูุธุฑุฉ ูุงุญุตุฉ. ุงูุตูุบุฉ ูุญุณุงุจ ุงูุฅุฎุฑุงุฌ (O) ูุทุจูุฉ ุงูุฃุชูุชุฉ ุงูุฐุงุชูุฉ ูุฅุฏุฎุงู (X) ุจุทูู (N) ูู:

$$ \textbf{O} = \text{Attn}(\mathbf{X}) = \mathbf{V} \times \text{Softmax}(\mathbf{QK}^T) \text{ with } \mathbf{Q} = \mathbf{W}_q \mathbf{X}, \mathbf{V} = \mathbf{W}_v \mathbf{X}, \mathbf{K} = \mathbf{W}_k \mathbf{X} $$

$$  \mathbf{X} = (\mathbf{x}_1, ... \mathbf{x}_{N}) $$ ูู ุชุณูุณู ุงูุฅุฏุฎุงู ุฅูู ุทุจูุฉ ุงูุฃุชูุชุฉ. ูุณุชุชููู ูู ูู ุงูุฅุณูุงุทุงุช (Q) ู(K) ูู (N) ูู ุงููุชุฌูุงุช ููุง ูุคุฏู ุฅูู ุฃู ูููู ุญุฌู (QK^T) ูู (N^2).

ุนุงุฏุฉ ูุง ุชุญุชูู ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ุนูู ุงูุนุฏูุฏ ูู ุฑุคูุณ ุงูุฃุชูุชุฉุ ูุจุงูุชุงูู ุชููู ุจุนุฏุฉ ุญุณุงุจุงุช ููุฃุชูุชุฉ ุงูุฐุงุชูุฉ ุจุงูุชูุงุฒู.

ูุจุงูุชุฑุงุถ ุฃู ูููุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ูุญุชูู ุนูู 40 ุฑุฃุณ ุฃุชูุชุฉ ููุนูู ุจุฏูุฉ bfloat16ุ ูููููุง ุญุณุงุจ ูุชุทูุจุงุช ุงูุฐุงูุฑุฉ ูุชุฎุฒูู ูุตูููุงุช (QK^T) ูุชููู 40 * 2 * N^2 ุจุงูุช. ุจุงููุณุจุฉ ูู (N=1000)ุ ูุง ููุฒู ุณูู ุญูุงูู 50 ููุฌุงุจุงูุช ูู ุฐุงูุฑุฉ ุงูููุฏูู ุงูุนุดูุงุฆูุฉ (VRAM)ุ ูููู ุจุงููุณุจุฉ ูู (N=16000)ุ ุณูุญุชุงุฌ ุฅูู 19 ุฌูุฌุงุจุงูุช ูู ุฐุงูุฑุฉ ุงูููุฏูู ุงูุนุดูุงุฆูุฉุ ูุจุงููุณุจุฉ ูู (N=100,000)ุ ุณูุญุชุงุฌ ุฅูู ูุง ููุฑุจ ูู 1 ุชูุฑุงุจุงูุช ูุชุฎุฒูู ูุตูููุงุช (QK^T) ููุท.

ุจุงุฎุชุตุงุฑุ ุชุตุจุญ ุฎูุงุฑุฒููุฉ ุงูุฃุชูุชุฉ ุงูุฐุงุชูุฉ ุงูุงูุชุฑุงุถูุฉ ุจุณุฑุนุฉ ุจุงูุธุฉ ุงูุชูููุฉ ูู ุญูุซ ุงูุฐุงูุฑุฉ ุจุงููุณุจุฉ ูุณูุงูุงุช ุงูุฅุฏุฎุงู ุงููุจูุฑุฉ.

ูุน ุชุญุณู ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ูู ููู ุงููุตูุต ูุชูููุฏูุงุ ูุชู ุชุทุจูููุง ุนูู ููุงู ูุชุฒุงูุฏุฉ ุงูุชุนููุฏ. ูุจูููุง ูุงูุช ุงูููุงุฐุฌ ุชุชุนุงูู ุณุงุจููุง ูุน ุชุฑุฌูุฉ ุฃู ุชูุฎูุต ุจุถุน ุฌููุ ูุฅููุง ุงูุขู ุชุฏูุฑ ุตูุญุงุช ูุงููุฉุ ููุง ูุชุทูุจ ุงููุฏุฑุฉ ุนูู ูุนุงูุฌุฉ ุฃุทูุงู ุฅุฏุฎุงู ุดุงููุฉ.

ููู ูููููุง ุงูุชุฎูุต ูู ูุชุทูุจุงุช ุงูุฐุงูุฑุฉ ุงูุจุงูุธุฉ ูุทูู ุงูุฅุฏุฎุงู ุงููุจูุฑุ ูุญู ุจุญุงุฌุฉ ุฅูู ุทุฑููุฉ ุฌุฏูุฏุฉ ูุญุณุงุจ ุขููุฉ ุงูุฃุชูุชุฉ ุงูุฐุงุชูุฉ ุงูุชู ุชุชุฎูุต ูู ูุตูููุฉ (QK^T). ูุงู [ุชุฑู ุฏุงู ูุขุฎุฑูู](https://arxiv.org/abs/2205.14135) ุจุชุทููุฑ ุฎูุงุฑุฒููุฉ ุฌุฏูุฏุฉ ุชูุงููุง ูุฃุทูููุง ุนูููุง ุงุณู **ููุงุด ุฃุชูุดู**.

ุจุงุฎุชุตุงุฑุ ุชููู ููุงุด ุฃุชูุดู ุจุชูุณูู ุญุณุงุจ (V * Softmax (QK^T)) ูุชุญุณุจ ุจุฏูุงู ูู ุฐูู ูุทุนูุง ุฃุตุบุฑ ูู ุงูุฅุฎุฑุงุฌ ุนู ุทุฑูู ุงูุชูุฑุงุฑ ุนุจุฑ ุนุฏุฉ ุฎุทูุงุช ูุญุณุงุจ Softmax:

$$ \textbf{O}_i \leftarrow s^a_{ij} * \textbf{O}_i + s^b_{ij} * \mathbf{V}_{j} \times \text{Softmax}(\mathbf{QK}^T_{i,j}) \text{ for multiple } i, j \text{ iterations} $$

ูุน (s^a_{ij}) ู(s^b_{ij}) ููููุง ุจุนุถ ุฅุญุตุงุฆูุงุช ุงูุชูุญูุฏ ุงูููุงุณู Softmax ุงูุชู ุชุญุชุงุฌ ุฅูู ุฅุนุงุฏุฉ ุญุณุงุจ ููู ูู (i) ู(j).

ูุฑุฌู ููุงุญุธุฉ ุฃู ููุงุด ุฃุชูุดู ุจุงููุงูู ุฃูุซุฑ ุชุนููุฏูุง ุฅูู ุญุฏ ูุง ูุชุจุณูุทู ููุง ุจุดูู ูุจูุฑ ุญูุซ ุฃู ุงูุฎูุถ ูู ุงููุซูุฑ ูู ุงูุชูุงุตูู ูุฎุฑุฌ ุนู ูุทุงู ูุฐุง ุงูุฏููู. ุงููุงุฑุฆ ูุฏุนู ูุฅููุงุก ูุธุฑุฉ ุนูู ูุฑูุฉ ููุงุด ุฃุชูุดู [Flash Attention paper](https://arxiv.org/abs/2205.14135) ููุญุตูู ุนูู ูุฒูุฏ ูู ุงูุชูุงุตูู.

ุงูููุฑุฉ ุงูุฑุฆูุณูุฉ ููุง ูู:

> ูู ุฎูุงู ุชุชุจุน ุฅุญุตุงุฆูุงุช ุชูุญูุฏ ููุงุณู Softmax ูุงุณุชุฎุฏุงู ุจุนุถ ุงูุฑูุงุถูุงุช ุงูุฐููุฉุ ุชููุญ ููุงุด ุฃุชูุดู ููุณ ุงูุฅุฎุฑุงุฌ **ุงูุฑููู** ููุงุฑูุฉ ุจุทุจูุฉ ุงูุฃุชูุชุฉ ุงูุฐุงุชูุฉ ุงูุงูุชุฑุงุถูุฉ ุจุชูููุฉ ุฐุงูุฑุฉ ุชุฒูุฏ ููุท ุจุดูู ุฎุทู ูุน (N).

ุจุงููุธุฑ ุฅูู ุงูุตูุบุฉุ ูุฏ ูููู ุงููุฑุก ุจุฏููููุง ุฃู ููุงุด ุฃุชูุดู ูุฌุจ ุฃู ุชููู ุฃุจุทุฃ ุจูุซูุฑ ููุงุฑูุฉ ุจุตูุบุฉ ุงูุฃุชูุชุฉ ุงูุฐุงุชูุฉ ุงูุงูุชุฑุงุถูุฉ ุญูุซ ููุฒู ุฅุฌุฑุงุก ุงููุฒูุฏ ูู ุงูุญุณุงุจุงุช. ูู ุงููุงูุนุ ุชุชุทูุจ ููุงุด ุฃุชูุดู ุงููุฒูุฏ ูู ุนูููุงุช ุงููุงุตูุฉ ุงูุนุงุฆูุฉ ููุงุฑูุฉ ุจุงูุฃุชูุชุฉ ุงูุนุงุฏูุฉ ุญูุซ ูุฌุจ ุฅุนุงุฏุฉ ุญุณุงุจ ุฅุญุตุงุฆูุงุช ุชูุญูุฏ ููุงุณู Softmax ุจุงุณุชูุฑุงุฑ (ุฑุงุฌุน [ุงููุฑูุฉ](https://arxiv.org/abs/2205.14135) ููุฒูุฏ ูู ุงูุชูุงุตูู ุฅุฐุง ููุช ููุชููุง).

> ููุน ุฐููุ ูุฅู ููุงุด ุฃุชูุดู ุฃุณุฑุน ุจูุซูุฑ ูู ุงูุงุณุชูุชุงุฌ ููุงุฑูุฉ ุจุงูุฃุชูุชุฉ ุงูุงูุชุฑุงุถูุฉ ูุงูุชู ุชุฃุชู ูู ูุฏุฑุชูุง ุนูู ุชูููู ุงููุชุทูุจุงุช ุนูู ุฐุงูุฑุฉ ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU) ุงูุฃุจุทุฃ ุฐุงุช ุงููุทุงู ุงูุชุฑุฏุฏู ุงูุนุงููุ ูุงูุชุฑููุฒ ุจุฏูุงู ูู ุฐูู ุนูู ุงูุฐุงูุฑุฉ ุงูููุฌูุฏุฉ ุนูู ุงูุดุฑูุญุฉ (SRAM) ุงูุฃุณุฑุน.

ูู ุงูุฃุณุงุณุ ุชุชุฃูุฏ ููุงุด ุฃุชูุดู ูู ุฅููุงููุฉ ุฅุฌุฑุงุก ุฌููุน ุนูููุงุช ุงููุชุงุจุฉ ูุงููุฑุงุกุฉ ุงููุณูุทุฉ ุจุงุณุชุฎุฏุงู ุฐุงูุฑุฉ SRAM ุงูุณุฑูุนุฉ ุงูููุฌูุฏุฉ ุนูู ุงูุดุฑูุญุฉ ุจุฏูุงู ูู ุงูุงุถุทุฑุงุฑ ุฅูู ุงููุตูู ุฅูู ุฐุงูุฑุฉ VRAM ุงูุฃุจุทุฃ ูุญุณุงุจ ูุชุฌู ุงูุฅุฎุฑุงุฌ (O).

ูู ุงูููุงุฑุณุฉ ุงูุนูููุฉุ ูุง ููุฌุฏ ุญุงูููุง ุฃู ุณุจุจ **ูุนุฏู** ุงุณุชุฎุฏุงู ููุงุด ุฃุชูุดู ุฅุฐุง ูุงูุช ูุชุงุญุฉ. ุชุนุทู ุงูุฎูุงุฑุฒููุฉ ููุณ ุงูุฅุฎุฑุงุฌ ุฑูุงุถููุงุ ููู ุฃุณุฑุน ูุฃูุซุฑ ููุงุกุฉ ูู ุงุณุชุฎุฏุงู ุงูุฐุงูุฑุฉ.

ุฏุนููุง ูููู ูุธุฑุฉ ุนูู ูุซุงู ุนููู.

ูุญุตู ูููุฐุฌ OctoCoder ุงูุขู ุนูู ููุฌู ุฅุฏุฎุงู ุฃุทูู ุจูุซูุฑ ูุชุถูู ูุง ูุณูู ููุฌู ุงููุธุงู. ุชูุณุชุฎุฏู ููุฌูุงุช ุงููุธุงู ูุชูุฌูู ูููุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ุฅูู ูุณุงุนุฏ ุฃูุถู ูุตูู ูููุงู ุงููุณุชุฎุฏููู.

ูููุง ูููุ ูุณุชุฎุฏู ููุฌู ุงููุธุงู ุงูุฐู ุณูุฌุนู OctoCoder ูุณุงุนุฏ ุชุฑููุฒ ุฃูุถู.

```python
system_prompt = """Below are a series of dialogues between various people and an AI technical assistant.
The assistant tries to be helpful, polite, honest, sophisticated, emotionally aware, and humble but knowledgeable.
The assistant is happy to help with code questions and will do their best to understand exactly what is needed.
It also tries to avoid giving false or misleading information, and it caveats when it isn't entirely sure about the right answer.
That said, the assistant is practical really does its best, and doesn't let caution get too much in the way of being useful.

The Starcoder models are a series of 15.5B parameter models trained on 80+ programming languages from The Stack (v1.2) (excluding opt-out requests).
The model uses Multi Query Attention, was trained using the Fill-in-the-Middle objective, and with 8,192 tokens context window for a trillion tokens of heavily deduplicated data.

-----

Question: Write a function that takes two lists and returns a list that has alternating elements from each input list.

Answer: Sure. Here is a function that does that.

def alternating(list1, list2):
results = []
for i in range(len(list1)):
results.append(list1[i])
results.append(list2[i])
return results

Question: Can you write some test cases for this function?

Answer: Sure, here are some tests.

assert alternating([10, 20, 30], [1, 2, 3]) == [10, 1, 20, 2, 30, 3]
assert alternating([True, False], [4, 5]) == [True, 4, False, 5]
assert alternating([], []) == []

Question: Modify the function so that it returns all input elements when the lists have uneven length. The elements from the longer list should be at the end.

Answer: Here is the modified function.

def alternating(list1, list2):
results = []
for i in range(min(len(list1), len(list2))):
results.append(list1[i])
results.append(list2[i])
if len(list1) > len(list2):
results.extend(list1[i+1:])
else:
results.extend(list2[i+1:])
return results

-----
"""
```

ูุฃุบุฑุงุถ ุงูุชูุถูุญุ ุณููุฑุฑ ููุฌู ุงููุธุงู ุนุดุฑ ูุฑุงุช ุจุญูุซ ูููู ุทูู ุงูุฅุฏุฎุงู ุทูููุงู ุจุฏุฑุฌุฉ ูุงููุฉ ูููุงุญุธุฉ ูููุฑุงุช ุฐุงูุฑุฉ ููุงุด ุฃุชูุดู.

ููุญู ููุฌู ุงููุต ุงูุฃุตูู "ุณุคุงู: ูุฑุฌู ูุชุงุจุฉ ุฏุงูุฉ ูู ุจุงูุซูู ูุชุญููู ุงูุจุงูุชุงุช ุฅูู ุฌูุฌุง ุจุงูุชุงุช.

ุงูุฅุฌุงุจุฉ: ููุง"

```python
long_prompt = 10 * system_prompt + prompt
```

ูููู ุจุชูุดูุท ูููุฐุฌูุง ูุฑุฉ ุฃุฎุฑู ุจุฏูุฉ bfloat16.

```python
model = AutoModelForCausalLM.from_pretrained("bigcode/octocoder", torch_dtype=torch.bfloat16, device_map="auto")
tokenizer = AutoTokenizer.from_pretrained("bigcode/octocoder")

pipe = pipeline("text-generation", model=model, tokenizer=tokenizer)
```

ุฏุนููุง ุงูุขู ูููู ุจุชุดุบูู ุงููููุฐุฌ ุชูุงููุง ููุง ูุนููุง ูู ูุจู *ุจุฏูู ููุงุด ุฃุชูุดู* ูููุงุณ ูุชุทูุจุงุช ุฐุงูุฑุฉ ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU) ุงููุตูู ูููุช ุงูุงุณุชูุชุงุฌ.

```python
import time

start_time = time.time()
result = pipe(long_prompt, max_new_tokens=60)[0]["generated_text"][len(long_prompt):]

print(f"Generated in {time.time() - start_time} seconds.")
result
```

**ุงูุฅุฎุฑุงุฌ**:

```
ุชู ุงูุฅูุดุงุก ูู 10.96854019165039 ุซุงููุฉ.
ุจุงูุชุฃููุฏ. ุฅููู ุฏุงูุฉ ุชููู ุจุฐูู.

def bytes_to_giga(bytes):
return bytes / 1024 / 1024 / 1024

ุงูุฅุฌุงุจุฉ: ุจุงูุชุฃููุฏ. ุฅููู ุฏุงูุฉ ุชููู ุจุฐูู.

def
```

ูุญุตู ุนูู ููุณ ุงูุฅุฎุฑุงุฌ ููุง ูุงู ูู ูุจูุ ูููู ูุฐู ุงููุฑุฉุ ูููู ุงููููุฐุฌ ุจุชูุฑุงุฑ ุงูุฅุฌุงุจุฉ ุนุฏุฉ ูุฑุงุช ุญุชู ูุชู ูุทุนู ุนูุฏ 60 ุฑูุฒูุง. ููุณ ูู ุงููุณุชุบุฑุจ ุฃููุง ูุฑุฑูุง ููุฌู ุงููุธุงู ุนุดุฑ ูุฑุงุช ูุฃุบุฑุงุถ ุงูุชูุถูุญ ูุจุงูุชุงูู ูููุง ุจุชูุจูู ุงููููุฐุฌ ูุชูุฑุงุฑ ููุณู.

**ููุงุญุธุฉ** ุฃูู ูุง ููุจุบู ุชูุฑุงุฑ ููุฌู ุงููุธุงู ุนุดุฑ ูุฑุงุช ูู ุงูุชุทุจููุงุช ุงููุงูุนูุฉ - ูุงููุฑุฉ ุงููุงุญุฏุฉ ูุงููุฉ!

ุฏุนููุง ูููุณ ูุชุทูุจุงุช ุฐุงูุฑุฉ ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU) ุงููุตูู.

```python
bytes_to_giga_bytes(torch.cuda.max_memory_allocated())
```

**ุงูุฅุฎุฑุงุฌ**:

```bash
37.668193340301514
```

ููุง ูุฑูุ ูุฅู ูุชุทูุจุงุช ุฐุงูุฑุฉ ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU) ุงููุตูู ุฃุนูู ุจูุซูุฑ ููุง ูุงูุช ุนููู ูู ุงูุจุฏุงูุฉุ ููู ูุง ูุฑุฌุน ุฅูู ุญุฏ ูุจูุฑ ุฅูู ุทูู ุชุณูุณู ุงูุฅุฏุฎุงู ุงูุฃุทูู. ููุง ุฃู ุนูููุฉ ุงูุชูููุฏ ุชุณุชุบุฑู ุงูุขู ุฃูุซุฑ ูู ุฏูููุฉ ุจูููู.

ูุณุชุฏุนู ุงูุฏุงูุฉ `flush()` ูุชุญุฑูุฑ ุฐุงูุฑุฉ ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU) ููุชุฌุฑุจุฉ ุงูุชุงููุฉ.

```python
flush()
```

ููููุงุฑูุฉุ ุฏุนููุง ูููู ุจุชุดุบูู ููุณ ุงูุฏุงูุฉุ ูููู ูุน ุชูููู ููุงุด ุฃุชูุดู ุจุฏูุงู ูู ุฐูู.

ููููุงู ุจุฐููุ ูููู ุจุชุญููู ุงููููุฐุฌ ุฅูู [BetterTransformer](https://huggingface.co/docs/optimum/bettertransformer/overview) ูุจุฐูู ุชูููู PyTorch's [SDPA self-attention](https://pytorch.org/docs/master/generated/torch.nn.functional.scaled_dot_product_attention) ูุงูุชู ูููููุง ุจุฏูุฑูุง ุงุณุชุฎุฏุงู ููุงุด ุฃุชูุดู.

```python
model.to_bettertransformer()
```

ุงูุขู ูููู ุจุชุดุบูู ููุณ ููุทุน ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉ ุชูุงููุง ููุง ูุนููุง ูู ูุจู ูุณุชุณุชุฎุฏู Transformers ุชููุงุฆููุง ููุงุด ุฃุชูุดู.

```py
start_time = time.time()
with torch.backends.cuda.sdp_kernel(enable_flash=True, enable_math=False, enable_mem_efficient=False):
result = pipe(long_prompt, max_new_tokens=60)[0]["generated_text"][len(long_prompt):]

print(f"Generated in {time.time() - start_time} seconds.")
result
```

**ุงูุฅุฎุฑุงุฌ**:

```
ุชู ุงูุฅูุดุงุก ูู 3.0211617946624756 ุซุงููุฉ.
ุจุงูุชุฃููุฏ. ุฅููู ุฏุงูุฉ ุชููู ุจุฐูู.

def bytes_to_giga(bytes):
return bytes / 1024 / 1024 / 1024

ุงูุฅุฌุงุจุฉ: ุจุงูุชุฃููุฏ. ุฅููู ุฏุงูุฉ ุชููู ุจุฐูู.

def
```

ูุญุตู ุนูู ููุณ ุงููุชูุฌุฉ ุจุงูุถุจุท ููุง ูุงู ูู ูุจูุ ูููู ูููููุง ููุงุญุธุฉ ุชุณุฑูุน ูุจูุฑ ุจูุถู ููุงุด ุฃุชูุดู.

ุฏุนููุง ูููุณ ุงุณุชููุงู ุงูุฐุงูุฑุฉ ูุขุฎุฑ ูุฑุฉ.

```python
bytes_to_giga_bytes(torch.cuda.max_memory_allocated())
```

**ุงูุฅุฎุฑุงุฌ**:

```
32.617331981658936
```

ููุญู ุงูุขู ุชูุฑูุจูุง ุนุฏูุง ุฅูู ุฐุฑูุฉ ุฐุงูุฑุฉ ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU) ุงูุฃุตููุฉ ุงูุจุงูุบุฉ 29 ุฌูุฌุงุจุงูุช.

ูููููุง ุฃู ููุงุญุธ ุฃููุง ูุณุชุฎุฏู ููุท ุญูุงูู 100 ููุฌุงุจุงูุช ุฅุถุงููุฉ ูู ุฐุงูุฑุฉ ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU) ุนูุฏ ุชูุฑูุฑ ุชุณูุณู ุฅุฏุฎุงู ุทููู ุฌุฏูุง ูุน ููุงุด ุฃุชูุดู ููุงุฑูุฉ ุจุชูุฑูุฑ ุชุณูุณู ุฅุฏุฎุงู ูุตูุฑ ููุง ูุนููุง ูู ุงูุจุฏุงูุฉ.

```py
flush()
```

ููุฒูุฏ ูู ุงููุนูููุงุช ุญูู ููููุฉ ุงุณุชุฎุฏุงู ููุงุด ุฃุชูุดูุ ูุฑุฌู ุงูุงุทูุงุน ุนูู [ุตูุญุฉ ุงููุซุงุฆู ูุฐู](https://huggingface.co/docs/transformers/en/perf_infer_gpu_one#flashattention-2).
## 3. ุงูุงุจุชูุงุฑุงุช ุงููุนูุงุฑูุฉ

ุญุชู ุงูุขูุ ูููุง ุจุฏุฑุงุณุฉ ุชุญุณูู ููุงุกุฉ ุงูุญุณุงุจ ูุงูุฐุงูุฑุฉ ูู ุฎูุงู:

- ุชุญููู ุงูุฃูุฒุงู ุฅูู ุชูุณูู ุฏูุฉ ุฃูู
- ุงุณุชุจุฏุงู ุฎูุงุฑุฒููุฉ ุงูุงูุชูุงู ุงูุฐุงุชู ุจูุณุฎุฉ ุฃูุซุฑ ููุงุกุฉ ูู ุญูุซ ุงูุฐุงูุฑุฉ ูุงูุญุณุงุจ

ุฏุนููุง ุงูุขู ูููู ูุธุฑุฉ ุนูู ููููุฉ ุชุบููุฑ ุจููุฉ ูููุฐุฌ ุงููุบุฉ ุงููุจูุฑ (LLM) ุจุญูุซ ูููู ุฃูุซุฑ ูุนุงููุฉ ูููุงุกุฉ ูููููุงุช ุงูุชู ุชุชุทูุจ ูุตูุตูุง ุทูููุฉ ูุฅุฏุฎุงูุ ุนูู ุณุจูู ุงููุซุงู:

- ุงูุฅุฌุงุจุฉ ุนูู ุงูุฃุณุฆูุฉ ุงููุนุฒุฒุฉ ุจุงูุงุณุชุฑุฌุงุน
- ุชูุฎูุต
- ุงูุฏุฑุฏุดุฉ

ูุงุญุธ ุฃู "ุงูุฏุฑุฏุดุฉ" ูุง ุชุชุทูุจ ูู LLM ุงูุชุนุงูู ูุน ูุตูุต ุทูููุฉ ูุฅุฏุฎุงู ูุญุณุจุ ุจู ุชุชุทูุจ ุฃูุถูุง ุฃู ูููู LLM ูุงุฏุฑูุง ุนูู ุงูุชุนุงูู ุจููุงุกุฉ ูุน ุงูุญูุงุฑ ุงููุชุจุงุฏู ุจูู ุงููุณุชุฎุฏู ูุงููุณุงุนุฏ (ูุซู ChatGPT).

ุจูุฌุฑุฏ ุชุฏุฑูุจ LLMุ ูุตุจุญ ูู ุงูุตุนุจ ุชุบููุฑ ุจููุชู ุงูุฃุณุงุณูุฉุ ูุฐูู ูู ุงูููู ูุฑุงุนุงุฉ ููุงู LLM ูุณุจููุง ูุชุญุณูู ุจููุฉ ุงููููุฐุฌ ููููุง ูุฐูู.

ููุงู ููููุงู ูููุงู ูู ุจููุฉ ุงููููุฐุฌ ูุตุจุญุงู ุจุณุฑุนุฉ ุนูู ุฒุฌุงุฌุฉ ููุฐุงูุฑุฉ ู/ุฃู ุงูุฃุฏุงุก ุจุงููุณุจุฉ ูุชุณูุณูุงุช ุงูุฅุฏุฎุงู ุงููุจูุฑุฉ.

- ุงูุชุถูููุงุช ุงูููุถุนูุฉ
- ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ููููุชุงุญ-ุงููููุฉ

ุฏุนููุง ูููู ูุธุฑุฉ ุนูู ูู ูููู ุจูุฒูุฏ ูู ุงูุชูุงุตูู.

### 3.1 ุชุญุณูู ุงูุชุถูููุงุช ุงูููุถุนูุฉ ูู LLMs

ูุถุน ุงูุงูุชูุงู ุงูุฐุงุชู ูู ุฑูุฒ ูู ุนูุงูุฉ ูุน ุงูุฑููุฒ ุงูุฃุฎุฑู.

ุนูู ุณุจูู ุงููุซุงูุ ูููู ุฃู ุชุจุฏู ูุตูููุฉ \\ (Softmax (QK^T \\)) ูุชุณูุณู ุฅุฏุฎุงู ุงููุต *"Hello"ุ "I"ุ "love"ุ "you"* ุนูู ุงููุญู ุงูุชุงูู:

![](/blog/assets/163_optimize_llm/self_attn_tokens.png)

ูุชู ุฅุนุทุงุก ูู ุฑูุฒ ูููุฉ ูุชูุฉ ุงุญุชูุงููุฉ ูุญุถุฑ ุจูุง ุฌููุน ุฑููุฒ ุงููููุงุช ุงูุฃุฎุฑูุ ูุจุงูุชุงูู ูุชู ูุถุนู ูู ุนูุงูุฉ ูุน ุฌููุน ุฑููุฒ ุงููููุงุช ุงูุฃุฎุฑู. ุนูู ุณุจูู ุงููุซุงูุ ูุญุถุฑ ุงูุฑูุฒ "love" ุฅูู ุงูุฑูุฒ "Hello" ุจูุณุจุฉ 5%ุ ูุฅูู "I" ุจูุณุจุฉ 30%ุ ูุฅูู ููุณู ุจูุณุจุฉ 65%.

ุณููุงุฌู LLM ุงููุงุฆู ุนูู ุงูุงูุชูุงู ุงูุฐุงุชูุ ูููู ุจุฏูู ุชุถูููุงุช ููุถุนูุฉุ ุตุนูุจุงุช ูุจูุฑุฉ ูู ููู ููุงุถุน ุฅุฏุฎุงูุงุช ุงููุต ุจุงููุณุจุฉ ูุจุนุถูุง ุงูุจุนุถ.

ููุฑุฌุน ุฐูู ุฅูู ุฃู ุฏุฑุฌุฉ ุงูุงุญุชูุงู ุงูุชู ูุญุณุจูุง \\ (QK^T \\) ุชุฑุจุท ูู ุฑูุฒ ูููุฉ ุจูู ุฑูุฒ ูููุฉ ุฃุฎุฑู ูู ุญุณุงุจุงุช O (1) ุจุบุถ ุงููุธุฑ ุนู ูุณุงูุฉ ุงูููุถุน ุงููุณุจู ุจููููุง.

ูุฐููุ ุจุงููุณุจุฉ ูู LLM ุจุฏูู ุชุถูููุงุช ููุถุนูุฉุ ูุจุฏู ุฃู ูู ุฑูุฒ ูู ููุณ ุงููุณุงูุฉ ุฅูู ุฌููุน ุงูุฑููุฒ ุงูุฃุฎุฑูุ ุนูู ุณุจูู ุงููุซุงูุ ุณูููู ูู ุงูุตุนุจ ุงูุชูููุฒ ุจูู *"Hello I love you"* ู *"You love I hello"*.

ููู ูููู LLM ุชุฑุชูุจ ุงูุฌููุ ููุงู ุญุงุฌุฉ ุฅูู ุฅุดุงุฑุฉ ุฅุถุงููุฉุ ูุนุงุฏุฉ ูุง ูุชู ุชุทุจูููุง ูู ุดูู ุชุฑููุฒุงุช ููุถุนูุฉ (ุฃู ูุง ููุทูู ุนููู ุฃูุถูุง ุงูุชุถูููุงุช ุงูููุถุนูุฉ).

ุชุฑููุฒ ุงูุชุถูููุงุช ุงูููุถุนูุฉ ููุถุน ูู ุฑูุฒ ุฅูู ุนุฑุถ ุฑููู ูููู ูู LLM ุงูุงุณุชูุงุฏุฉ ููู ูููู ุชุฑุชูุจ ุงูุฌูู ุจุดูู ุฃูุถู.

ูุฏู ูุคููู ูุฑูุฉ "Attention Is All You Need" ุชุถูููุงุช ููุถุนูุฉ ุฌูุจูุฉ \\ (P = p_1ุ ...ุ p_N \\).

ุญูุซ ูุชู ุญุณุงุจ ูู ูุชุฌู \\ (p_i \\) ูุฏุงูุฉ ุฌูุจูุฉ ูููุถุนู \\ (i \\).

ุซู ูุชู ุจุจุณุงุทุฉ ุฅุถุงูุฉ ุงูุชุฑููุฒุงุช ุงูููุถุนูุฉ ุฅูู ูุชุฌูุงุช ุชุณูุณู ุงูุฅุฏุฎุงู \\ (\\ hat {X} = \\ hat {x} _1ุ ...ุ \\ hat {x} _N \\) = (x_1 + p_1ุ ...ุ x_N + p_N) ููุง ูุฏูุน ุงููููุฐุฌ ุฅูู ุชุนูู ุชุฑุชูุจ ุงูุฌูู ุจุดูู ุฃูุถู.

ุจุฏูุงู ูู ุงุณุชุฎุฏุงู ุงูุชุถูููุงุช ุงูููุถุนูุฉ ุงูุซุงุจุชุฉุ ุงุณุชุฎุฏู ุขุฎุฑูู (ูุซู [Devlin et al.](https://arxiv.org/abs/1810.04805)) ุชุฑููุฒุงุช ููุถุนูุฉ ููุนููููุฉ ูุชู ูู ุฎูุงููุง ุชุนูู ุงูุชุถูููุงุช ุงูููุถุนูุฉ \\ (P \\) ุฃุซูุงุก ุงูุชุฏุฑูุจ.

ูุงูุช ุงูุชุถูููุงุช ุงูููุถุนูุฉ ุงูุฌูุจูุฉ ูุงูููุนููููุฉ ูู ุงูุทุฑู ุงูุณุงุฆุฏุฉ ูุชุฑููุฒ ุชุฑุชูุจ ุงูุฌูู ูู LLMsุ ูููู ุชู ุงูุชุดุงู ุงูุนุฏูุฏ ูู ุงููุดููุงุช ุงููุชุนููุฉ ุจูุฐู ุงูุชุฑููุฒุงุช ุงูููุถุนูุฉ:

1. ุงูุชุถูููุงุช ุงูููุถุนูุฉ ุงูุฌูุจูุฉ ูุงูููุนููููุฉ ูู ุชุถูููุงุช ููุถุนูุฉ ูุทููุฉุ ุฃู ุฃููุง ุชุฑููุฒ ุชุถููููุง ูุฑูุฏูุง ููู ูุนุฑู ููุถุน: \\ (0ุ ...ุ N \\). ููุง ุฃุธูุฑ [Huang et al.](https://arxiv.org/abs/2009.13658) ู [Su et al.](https://arxiv.org/abs/2104.09864)ุ ุชุคุฏู ุงูุชุถูููุงุช ุงูููุถุนูุฉ ุงููุทููุฉ ุฅูู ุถุนู ุฃุฏุงุก LLM ุจุงููุณุจุฉ ูุฅุฏุฎุงูุงุช ุงููุต ุงูุทูููุฉ. ุจุงููุณุจุฉ ูุฅุฏุฎุงูุงุช ุงููุต ุงูุทูููุฉุ ูููู ูู ุงููููุฏ ุฃู ูุชุนูู ุงููููุฐุฌ ุงููุณุงูุฉ ุงูููุถุนูุฉ ุงููุณุจูุฉ ุงูุชู ุชูุชูููุง ุฑููุฒ ุงูุฅุฏุฎุงู ุจุงููุณุจุฉ ูุจุนุถูุง ุงูุจุนุถ ุจุฏูุงู ูู ููุถุนูุง ุงููุทูู.

2. ุนูุฏ ุงุณุชุฎุฏุงู ุงูุชุถูููุงุช ุงูููุถุนูุฉ ุงูููุนููููุฉุ ูุฌุจ ุชุฏุฑูุจ LLM ุนูู ุทูู ุฅุฏุฎุงู ุซุงุจุช \\ (N \\)ุ ููุง ูุฌุนู ูู ุงูุตุนุจ ุงูุงุณุชูุฑุงุก ุฅูู ุทูู ุฅุฏุฎุงู ุฃุทูู ููุง ุชู ุชุฏุฑูุจู ุนููู.

ูุคุฎุฑูุงุ ุฃุตุจุญุช ุงูุชุถูููุงุช ุงูููุถุนูุฉ ุงููุณุจูุฉ ุงูุชู ูููููุง ูุนุงูุฌุฉ ุงููุดููุงุช ุงููุฐููุฑุฉ ุฃุนูุงู ุฃูุซุฑ ุดุนุจูุฉุ ูุฃุจุฑุฒูุง:

- [ุชุถููู ุงูููุถุน ุงูุฏูุงุฑ (RoPE)](https://arxiv.org/abs/2104.09864)
- [ALiBi](https://arxiv.org/abs/2108.12409)

ูุฌุงุฏู ูู ูู *RoPE* ู *ALiBi* ุจุฃู ูู ุงูุฃูุถู ุฅุนุทุงุก ุฅุดุงุฑุฉ ุฅูู LLM ุญูู ุชุฑุชูุจ ุงูุฌูู ูุจุงุดุฑุฉ ูู ุฎูุงุฑุฒููุฉ ุงูุงูุชูุงู ุงูุฐุงุชู ุญูุซ ูุชู ูุถุน ุฑููุฒ ุงููููุงุช ูู ุนูุงูุฉ ูุน ุจุนุถูุง ุงูุจุนุถ. ูุจุดูู ุฃูุซุฑ ุชุญุฏูุฏูุงุ ูุฌุจ ุงูุฅุดุงุฑุฉ ุฅูู ุชุฑุชูุจ ุงูุฌูู ุนู ุทุฑูู ุชุนุฏูู ุญุณุงุจ \\ (QK^T \\).

ุจุฏูู ุงูุฏุฎูู ูู ุงููุซูุฑ ูู ุงูุชูุงุตููุ ูุดูุฑ *RoPE* ุฅูู ุฃูู ูููู ุชุฑููุฒ ุงููุนูููุงุช ุงูููุถุนูุฉ ูู ุฃุฒูุงุฌ ุงูุงุณุชุนูุงู-ุงูููุชุงุญุ ุนูู ุณุจูู ุงููุซุงู \\ (q_i \\) ู (x_j \\) ุนู ุทุฑูู ุชุฏููุฑ ูู ูุชุฌู ุจุฒุงููุฉ \\ (theta * i \\) ู \\ (theta * j \\) ุนูู ุงูุชูุงูู ูุน \\ (i, j \\) ุงูุชู ุชุตู ููุถุน ุงูุฌููุฉ ููู ูุชุฌู:

$$ \\ hat {q} _i^T \\ hat {x} _j = \\ {q} _i^T R_ {theta, i -j} \\ {x} _j. $$

ููุซู \\ (R_ {theta, i - j} \\) ูุตูููุฉ ุฏูุฑุงู. \\ (theta \\) *ุบูุฑ* ููุนูููู ุฃุซูุงุก ุงูุชุฏุฑูุจุ ููููู ุจุฏูุงู ูู ุฐูู ูุชู ุชุนูููู ุฅูู ูููุฉ ูุญุฏุฏุฉ ูุณุจููุง ุชุนุชูุฏ ุนูู ุทูู ุชุณูุณู ุงูุฅุฏุฎุงู ุงูุฃูุตู ุฃุซูุงุก ุงูุชุฏุฑูุจ.

> ูู ุฎูุงู ุงูููุงู ุจุฐููุ ูุง ุชุชุฃุซุฑ ุฏุฑุฌุฉ ุงูุงุญุชูุงู ุจูู \\ (q_i \\) ู (q_j \\) ุฅูุง ุฅุฐุง \\ (i ูุง = j \\) ูุชุนุชูุฏ ููุท ุนูู ุงููุณุงูุฉ ุงููุณุจูุฉ \\ (i - j \\) ุจุบุถ ุงููุธุฑ ุนู ููุงุถุน ูู ูุชุฌู ูุญุฏุฏุฉ \\ (i \\) ู (j \\).

ูุชู ุงุณุชุฎุฏุงู *RoPE* ูู ุงูุนุฏูุฏ ูู ุฃูู LLMs ุงููููุ ูุซู:

- [**Falcon**](https://huggingface.co/tiiuae/falcon-40b)
- [**Llama**](https://arxiv.org/abs/2302.13971)
- [**PaLM**](https://arxiv.org/abs/2204.02311)

ููุจุฏููุ ููุชุฑุญ *ALiBi* ูุฎุทุท ุชุฑููุฒ ููุถุนู ูุณุจู ุฃุจุณุท. ูุชู ุฅุถุงูุฉ ุงููุณุงูุฉ ุงููุณุจูุฉ ุงูุชู ุชูุชูููุง ุฑููุฒ ุงูุฅุฏุฎุงู ุฅูู ุจุนุถูุง ุงูุจุนุถ ูุนุฏุฏ ุตุญูุญ ุณูุจู ููุณูู ุญุณุจ ูููุฉ ูุญุฏุฏุฉ ูุณุจููุง `m` ุฅูู ูู ุฅุฏุฎุงู ุงุณุชุนูุงู-ููุชุงุญ ููุตูููุฉ \\ (QK^T \\) ูุจุงุดุฑุฉ ูุจู ุญุณุงุจ softmax.

![](/blog/assets/163_optimize_llm/alibi.png)

ููุง ูู ููุถุญ ูู ูุฑูุฉ [ALiBi](https://arxiv.org/abs/2108.12409)ุ ูุณูุญ ูุฐุง ุงูุชุฑููุฒ ุงูููุถุนู ุงููุณุจู ุงูุจุณูุท ูููููุฐุฌ ุจุงูุญูุงุธ ุนูู ุฃุฏุงุก ุนุงูู ุญุชู ูู ุชุณูุณูุงุช ุฅุฏุฎุงู ูุต ุทูููุฉ ุฌุฏูุง.

ูุชู ุงุณุชุฎุฏุงู *ALiBi* ูู ุงูุนุฏูุฏ ูู ุฃูู LLMs ุงููููุ ูุซู:

- [**MPT**](https://huggingface.co/mosaicml/mpt-30b)
- [**BLOOM**](https://huggingface.co/bigscience/bloom)

ูููู ููู ูู ุชุฑููุฒุงุช ุงูููุถุน *RoPE* ู *ALiBi* ุงูุงุณุชูุฑุงุก ุฅูู ุฃุทูุงู ุงูุฅุฏุฎุงู ุงูุชู ูู ูุชู ููุงุญุธุชูุง ุฃุซูุงุก ุงูุชุฏุฑูุจุ ูู ุญูู ุซุจุช ุฃู ุงูุงุณุชูุฑุงุก ูุนูู ุจุดูู ุฃูุถู ุฎุงุฑุฌ ุงูุตูุฏูู ูู *ALiBi* ููุงุฑูุฉ ุจู *RoPE*.

ุจุงููุณุจุฉ ูู ALiBiุ ูุง ุนููู ุณูู ุฒูุงุฏุฉ ููู ุงููุตูููุฉ ุงูููุถุนูุฉ ุงููุซูุซูุฉ ุงูุณูููุฉ ููุทุงุจูุฉ ุทูู ุชุณูุณู ุงูุฅุฏุฎุงู.

ุจุงููุณุจุฉ ูู *RoPE*ุ ูุคุฏู ุงูุญูุงุธ ุนูู ููุณ \\ (theta \\) ุงูุฐู ุชู ุงุณุชุฎุฏุงูู ุฃุซูุงุก ุงูุชุฏุฑูุจ ุฅูู ูุชุงุฆุฌ ุถุนููุฉ ุนูุฏ ุชูุฑูุฑ ุฅุฏุฎุงูุงุช ูุต ุฃุทูู ุจูุซูุฑ ูู ุชูู ุงูุชู ุดููุฏุช ุฃุซูุงุก ุงูุชุฏุฑูุจุ ุฑุงุฌุน [Press et al.](https://arxiv.org/abs/2108.12409). ููุน ุฐููุ ูุฌุฏ ุงููุฌุชูุน ุจุนุถ ุงูุญูู ุงููุนุงูุฉ ุงูุชู ุชููู ุจุชุนุฏูู \\ (theta \\)ุ ููุง ูุณูุญ ุจุงูุชุถูููุงุช ุงูููุถุนูุฉ *RoPE* ุจุงูุนูู ุจุดูู ุฌูุฏ ูุชุณูุณูุงุช ุฅุฏุฎุงู ุงููุต ุงููุณุชูุฑุฆุฉ (ุงูุธุฑ [ููุง](https://github.com/huggingface/transformers/pull/24653)).

> ูู ูู RoPE ู ALiBi ููุง ุชุถูููุงุช ููุถุนูุฉ ูุณุจูุฉ *ุบูุฑ* ููุนููููุฉ ุฃุซูุงุก ุงูุชุฏุฑูุจุ ูููููุง ุจุฏูุงู ูู ุฐูู ุชุณุชูุฏ ุฅูู ุงูุญุฏุณ ุงูุชุงูู:

- ูุฌุจ ุฅุนุทุงุก ุงูุฅุดุงุฑุงุช ุงูููุถุนูุฉ ุญูู ุฅุฏุฎุงูุงุช ุงููุต ูุจุงุดุฑุฉ ุฅูู ูุตูููุฉ \\ (QK^T \\) ูุทุจูุฉ ุงูุงูุชูุงู ุงูุฐุงุชู
- ูุฌุจ ุชุญููุฒ LLM ุนูู ุชุนูู ุชุฑููุฒุงุช ููุถุนูุฉ ุฐุงุช ูุณุงูุฉ *ูุณุจูุฉ* ุซุงุจุชุฉ
- ูููุง ุงุจุชุนุฏุช ุฑููุฒ ุฅุฏุฎุงู ุงููุต ุนู ุจุนุถูุง ุงูุจุนุถุ ุงูุฎูุถ ุงุญุชูุงู ุงูุงุณุชุนูุงู-ุงููููุฉ. ูู ูู RoPE ู ALiBi ููููุงู ูู ุงุญุชูุงู ุงูุงุณุชุนูุงู-ุงูููุชุงุญ ููุฑููุฒ ุงูุจุนูุฏุฉ ุนู ุจุนุถูุง ุงูุจุนุถ. RoPE ุนู ุทุฑูู ุชูููู ุญุงุตู ุงูุถุฑุจ ูู ุงููุชุฌู ุนู ุทุฑูู ุฒูุงุฏุฉ ุงูุฒุงููุฉ ุจูู ูุชุฌูุงุช ุงูุงุณุชุนูุงู-ุงูููุชุงุญ. ALiBi ุนู ุทุฑูู ุฅุถุงูุฉ ุฃุนุฏุงุฏ ุตุญูุญุฉ ุณูุจูุฉ ูุจูุฑุฉ ุฅูู ุญุงุตู ุถุฑุจ ุงููุชุฌู

ูู ุงูุฎุชุงูุ ูู ุงูุฃูุถู ุชุฏุฑูุจ LLMs ุงูุชู ูููุตุฏ ุจูุง ุงููุดุฑ ูู ููุงู ุชุชุทูุจ ุงูุชุนุงูู ูุน ุฅุฏุฎุงูุงุช ูุต ูุจูุฑุฉ ุจุงุณุชุฎุฏุงู ุงูุชุถูููุงุช ุงูููุถุนูุฉ ุงููุณุจูุฉุ ูุซู RoPE ู ALiBi. ูุงุญุธ ุฃูุถูุง ุฃูู ุญุชู ุฅุฐุง ุชู ุชุฏุฑูุจ LLM ุจุงุณุชุฎุฏุงู RoPE ู ALiBi ุนูู ุทูู ุซุงุจุช ูุจูุบุ ุนูู ุณุจูู ุงููุซุงูุ \\ (N_1 = 2048 \\)ุ ููููู ุงุณุชุฎุฏุงูู ุนููููุง ุจุฅุฏุฎุงูุงุช ูุต ุฃูุจุฑ ุจูุซูุฑ ูู \\ (N_1 \\)ุ ูุซู \\ (N_2 = 8192> N_1 \\) ุนู ุทุฑูู ุงุณุชูุฑุงุก ุงูุชุถูููุงุช ุงูููุถุนูุฉ.
### 3.2 ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ููููุชุงุญ-ุงููููุฉ

ูุนูู ุชูููุฏ ุงููุต ุฐุงุชู ุงูุฑุฌูุน ูุน ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ูู ุฎูุงู ุฅุฏุฎุงู ุชุณูุณู ุงูุฅุฏุฎุงู ุจุดูู ุชูุฑุงุฑูุ ูุนููุฉ ุงูุฑูุฒ ุงูุชุงููุ ูุฅูุญุงู ุงูุฑูุฒ ุงูุชุงูู ุจุชุณูุณู ุงูุฅุฏุฎุงูุ ูุงูุงุณุชูุฑุงุฑ ูู ุฐูู ุญุชู ููุชุฌ ูููุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ุฑูุฒูุง ูุดูุฑ ุฅูู ุงูุชูุงู ุงูุชูููุฏ.

ูุฑุฌู ุงูุงุทูุงุน ุนูู [ุฏููู ุฅูุดุงุก ุงููุต ุงูุฎุงุต ุจู Transformer](https://huggingface.co/docs/transformers/llm_tutorial#generate-text) ููุญุตูู ุนูู ุดุฑุญ ูุฑุฆู ุฃูุซุฑ ูููููุฉ ุนูู ุงูุชูููุฏ ุฐุงุชู ุงูุฑุฌูุน.

ุฏุนูุง ูููุฐ ููุชุทููุง ูุตูุฑูุง ูู ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉ ูุฅุธูุงุฑ ููููุฉ ุนูู ุงูุชูููุฏ ุฐุงุชู ุงูุฑุฌูุน ูู ุงูููุงุฑุณุฉ ุงูุนูููุฉ. ุจุจุณุงุทุฉุ ุณูุฃุฎุฐ ุงูุฑูุฒ ุงูุชุงูู ุงูุฃูุซุฑ ุงุญุชูุงููุง ุนุจุฑ `torch.argmax`.

```python
input_ids = tokenizer(prompt, return_tensors="pt")["input_ids"].to("cuda")

for _ in range(5):
    next_logits = model(input_ids)["logits"][:, -1:]
    next_token_id = torch.argmax(next_logits,dim=-1)

    input_ids = torch.cat([input_ids, next_token_id], dim=-1)
    print("shape of input_ids", input_ids.shape)

generated_text = tokenizer.batch_decode(input_ids[:, -5:])
generated_text
```

**ุงูุฅุฎุฑุงุฌ**:

```
shape of input_ids torch.Size([1, 21])
shape of input_ids torch.Size([1, 22])
shape of input_ids torch.Size([1, 23])
shape of input_ids torch.Size([1, 24])
shape of input_ids torch.Size([1, 25])
[' Here is a Python function']
```

ููุง ูุฑูุ ูู ูู ูุฑุฉ ูุฒูุฏ ุฑููุฒ ุฅุฏุฎุงู ุงููุต ุจุงูุฑูุฒ ุงูุฐู ุชู ุงุฎุชูุงุฑู ููุชู.

ุจุงุณุชุซูุงุกุงุช ููููุฉ ุฌุฏูุงุ ูุชู ุชุฏุฑูุจ ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ุจุงุณุชุฎุฏุงู [ูุฏู ููุฐุฌุฉ ุงููุบุฉ ุงูุณุจุจูุฉ](https://huggingface.co/docs/transformers/tasks/language_modeling#causal-language-modeling) ูุจุงูุชุงูู ูุชู ุญุฌุจ ุงููุซูุซ ุงูุนููู ููุตูููุฉ ุฏุฑุฌุงุช ุงูุงูุชูุงู - ููุฐุง ูู ุงูุณุจุจ ูู ุฃู ุฏุฑุฌุงุช ุงูุงูุชูุงู ุชูุชุฑู ูุงุฑุบุฉ ูู ุงููุฎุทุทูู ุฃุนูุงู (ุฃู ูููู ููุง ุงุญุชูุงู 0). ููุญุตูู ุนูู ููุฎุต ุณุฑูุน ุญูู ููุฐุฌุฉ ุงููุบุฉ ุงูุณุจุจูุฉุ ููููู ุงูุฑุฌูุน ุฅูู ูุฏููุฉ [*Illustrated Self Attention*](https://jalammar.github.io/illustrated-gpt2/#part-2-illustrated-self-attention).

ููุชูุฌุฉ ูุฐููุ ูุง ุชุนุชูุฏ ุงูุฑููุฒ *ุฃุจุฏูุง* ุนูู ุงูุฑููุฒ ุงูุณุงุจูุฉุ ูุจุดูู ุฃูุซุฑ ุชุญุฏูุฏูุงุ ูุง ูุชู ุฃุจุฏูุง ูุถุน ุงููุชุฌู \\( \mathbf{q}_i \\) ูู ุนูุงูุฉ ูุน ุฃู ูุชุฌูุงุช ููููุงุชูุญ ูุงูููู \\( \mathbf{k}_j, \mathbf{v}_j \\) ุฅุฐุง \\( j > i \\). ุจุฏูุงู ูู ุฐููุ ูุญุถุฑ \\( \mathbf{q}_i \\) ููุท ุฅูู ูุชุฌูุงุช ุงููููุฉ ุงูุฑุฆูุณูุฉ ุงูุณุงุจูุฉ \\( \mathbf{k}_{m < i}, \mathbf{v}_{m < i} \text{ , for } m \in \{0, \ldots i - 1\} \\). ูุชูููู ุงูุญุณุงุจุงุช ุบูุฑ ุงูุถุฑูุฑูุฉุ ูููู ุจุนุฏ ุฐูู ุชุฎุฒูู ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ููู ุทุจูุฉ ูู ูุชุฌูุงุช ุงููููุฉ ุงูุฑุฆูุณูุฉ ูุฌููุน ุงูุฎุทูุงุช ุงูุฒูููุฉ ุงูุณุงุจูุฉ.

ูููุง ูููุ ุณูุฎุจุฑ ูููุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ุจุงุณุชุฎุฏุงู ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ููููุชุงุญ-ุงููููุฉ ุนู ุทุฑูู ุงุณุชุฑุฏุงุฏูุง ูุฅุฑุณุงููุง ููู ุชูุฑูุฑ ููุฃูุงู.

ูู Transformersุ ูููููุง ุงุณุชุฑุฏุงุฏ ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ููููุชุงุญ-ุงููููุฉ ุนู ุทุฑูู ุชูุฑูุฑ ุนูู `use_cache` ุฅูู ููุงููุฉ `forward` ููููููุง ุจุนุฏ ุฐูู ุชูุฑูุฑู ูุน ุงูุฑูุฒ ุงูุญุงูู.

```python
past_key_values = None # past_key_values is the key-value cache
generated_tokens = []
next_token_id = tokenizer(prompt, return_tensors="pt")["input_ids"].to("cuda")

for _ in range(5):
    next_logits, past_key_values = model(next_token_id, past_key_values=past_key_values, use_cache=True).to_tuple()
    next_logits = next_logits[:, -1:]
    next_token_id = torch.argmax(next_logits, dim=-1)

    print("shape of input_ids", next_token_id.shape)
    print("length of key-value cache", len(past_key_values[0][0]))  # past_key_values are of shape [num_layers, 0 for k, 1 for v, batch_size, length, hidden_dim]
    generated_tokens.append(next_token_id.item())

generated_text = tokenizer.batch_decode(generated_tokens)
generated_text
```

**ุงูุฅุฎุฑุงุฌ**:

```
shape of input_ids torch.Size([1, 1])
length of key-value cache 20
shape of input_ids torch.Size([1, 1])
length of key-value cache 21
shape of input_ids torch.Size([1, 1])
length of key-value cache 22
shape of input_ids torch.Size([1, 1])
length of key-value cache 23
shape of input_ids torch.Size([1, 1])
length of key-value cache 24
[' Here', ' is', ' a', ' Python', ' function']
```

ููุง ูููููุง ุฃู ูุฑูุ ุนูุฏ ุงุณุชุฎุฏุงู ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ููููุชุงุญ-ุงููููุฉุ ูุง ูุชู ุฒูุงุฏุฉ ุฑููุฒ ุฅุฏุฎุงู ุงููุต ูู ุงูุทููุ ูููููุง ุชุธู ูุชุฌู ุฅุฏุฎุงู ูุงุญุฏูุง. ูู ูุงุญูุฉ ุฃุฎุฑูุ ูุชู ุฒูุงุฏุฉ ุทูู ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ููููุชุงุญ-ุงููููุฉ ุจูุงุญุฏ ูู ูู ุฎุทูุฉ ูู ุงูุชุดููุฑ.

> ูุนูู ุงุณุชุฎุฏุงู ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ููููุชุงุญ-ุงููููุฉ ุฃู \\( \mathbf{QK}^T \\) ูุชู ุชููููู ุจุดูู ุฃุณุงุณู ุฅูู \\( \mathbf{q}_c\mathbf{K}^T \\) ูุน \\( \mathbf{q}_c \\) ููู ุฅุณูุงุท ุงูุงุณุชุนูุงู ููุฅุฏุฎุงู ุงูุญุงูู ุงูุฐู ูุชู ุชูุฑูุฑู *ุฏุงุฆููุง* ููุชุฌู ูุงุญุฏ ููุท.

ูููุฑ ุงุณุชุฎุฏุงู ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ููููุชุงุญ-ุงููููุฉ ููุฒุชูู:

- ุฒูุงุฏุฉ ูุจูุฑุฉ ูู ุงูููุงุกุฉ ุงูุญุณุงุจูุฉ ุญูุซ ูุชู ุฅุฌุฑุงุก ุญุณุงุจุงุช ุฃูู ููุงุฑูุฉ ุจุญุณุงุจ ูุตูููุฉ \\( \mathbf{QK}^T \\) ุงููุงููุฉ. ูุคุฏู ุฐูู ุฅูู ุฒูุงุฏุฉ ุณุฑุนุฉ ุงูุงุณุชุฏูุงู.
- ูุง ุชุฒุฏุงุฏ ุงูุฐุงูุฑุฉ ุงููุตูู ุงููุทููุจุฉ ุจุดูู ุฑุจุงุนู ูุน ุนุฏุฏ ุงูุฑููุฒ ุงููููุฏุฉุ ูููููุง ุชุฒุฏุงุฏ ุจุดูู ุฎุทู ููุท.

> ูุฌุจ *ุฏุงุฆููุง* ุงุณุชุฎุฏุงู ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ููููุชุงุญ-ุงููููุฉ ุญูุซ ูุคุฏู ุฐูู ุฅูู ูุชุงุฆุฌ ูุชุทุงุจูุฉ ูุณุฑุนุฉ ูุจูุฑุฉ ููุชุณูุณูุงุช ุงููุฏุฎูุฉ ุงูุฃุทูู. ูุชู ุชูููู ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ููููุชุงุญ-ุงููููุฉ ุจุดูู ุงูุชุฑุงุถู ูู Transformers ุนูุฏ ุงุณุชุฎุฏุงู ุฎุท ุฃูุงุจูุจ ุงููุต ุฃู ุทุฑููุฉ [`generate`](https://huggingface.co/docs/transformers/main_classes/text_generation).

<Tip warning={true}>
ูุงุญุธ ุฃูู ุนูู ุงูุฑุบู ูู ูุตูุญุชูุง ุจุงุณุชุฎุฏุงู ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ููููุชุงุญ-ุงููููุฉุ ููุฏ ูููู ุฅุฎุฑุงุฌ ูููุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ูุฎุชูููุง ููููุงู ุนูุฏ ุงุณุชุฎุฏุงููุง. ูุฐู ูู ุฎุงุตูุฉ ููู ุงูุถุฑุจ ุงููุตูููุฉ ููุณูุง - ููููู ูุฑุงุกุฉ ุงููุฒูุฏ ุนููุง [ููุง](https://github.com/huggingface/transformers/issues/25420#issuecomment-1775317535).
</Tip>

#### 3.2.1 ูุญุงุฏุซุฉ ูุชุนุฏุฏุฉ ุงูุฌููุงุช

ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ููููุชุงุญ-ุงููููุฉ ูููุฏุฉ ุจุดูู ุฎุงุต ููุชุทุจููุงุช ูุซู ุงูุฏุฑุฏุดุฉ ุญูุซ ุชููู ููุงู ุญุงุฌุฉ ุฅูู ุนุฏุฉ ุชูุฑูุฑุงุช ูู ูู ุงูุชุดููุฑ ุฐุงุชู ุงูุฑุฌูุน. ุฏุนูุง ูููู ูุธุฑุฉ ุนูู ูุซุงู.

```
ุงููุณุชุฎุฏู: ูู ุนุฏุฏ ุงูุฃุดุฎุงุต ุงูุฐูู ูุนูุดูู ูู ูุฑูุณุงุ
ุงููุณุงุนุฏ: ูุนูุด ุญูุงูู 75 ููููู ุดุฎุต ูู ูุฑูุณุง
ุงููุณุชุฎุฏู: ููู ุนุฏุฏ ุงูุฃุดุฎุงุต ูู ุฃููุงููุงุ
ุงููุณุงุนุฏ: ููุฌุฏ ูู ุฃููุงููุง ุญูุงูู 81 ููููู ูุณูุฉ
```

ูู ูุฐู ุงูุฏุฑุฏุดุฉุ ูููู ูููุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ุจูู ุงูุชุดููุฑ ุฐุงุชู ุงูุฑุฌูุน ูุฑุชูู:

1. ูู ุงููุฑุฉ ุงูุฃูููุ ุชููู ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ููููุชุงุญ-ุงููููุฉ ูุงุฑุบุฉ ูุชููู ูุทุงูุจุฉ ุงูุฅุฏุฎุงู ูู `"ุงููุณุชุฎุฏู: ูู ุนุฏุฏ ุงูุฃุดุฎุงุต ุงูุฐูู ูุนูุดูู ูู ูุฑูุณุงุ"` ููููู ุงููููุฐุฌ ุจุชูููุฏ ุงููุต ุฐุงุชู ุงูุฑุฌูุน `"ูุนูุด ุญูุงูู 75 ููููู ุดุฎุต ูู ูุฑูุณุง"` ุฃุซูุงุก ุฒูุงุฏุฉ ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ููููุชุงุญ-ุงููููุฉ ูู ูู ุฎุทูุฉ ูู ุชุดููุฑ.

2. ูู ุงููุฑุฉ ุงูุซุงููุฉุ ุชููู ูุทุงูุจุฉ ุงูุฅุฏุฎุงู ูู `"ุงููุณุชุฎุฏู: ูู ุนุฏุฏ ุงูุฃุดุฎุงุต ุงูุฐูู ูุนูุดูู ูู ูุฑูุณุงุ \n ุงููุณุงุนุฏ: ูุนูุด ุญูุงูู 75 ููููู ุดุฎุต ูู ูุฑูุณุง \n ุงููุณุชุฎุฏู: ููู ุนุฏุฏ ุงูุฃุดุฎุงุต ูู ุฃููุงููุงุ"`. ุจูุถู ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุชุ ูุชู ุจุงููุนู ุญุณุงุจ ุฌููุน ูุชุฌูุงุช ุงููููุฉ ุงูุฑุฆูุณูุฉ ููุฌููุชูู ุงูุฃููููู. ูุฐููุ ุชุชููู ูุทุงูุจุฉ ุงูุฅุฏุฎุงู ููุท ูู `"ุงููุณุชุฎุฏู: ููู ุนุฏุฏ ุงูุฃุดุฎุงุต ูู ุฃููุงููุงุ"`. ุฃุซูุงุก ูุนุงูุฌุฉ ูุทุงูุจุฉ ุงูุฅุฏุฎุงู ุงููุฎุชุตุฑุฉุ ูุชู ุถู ูุชุฌูุงุช ุงููููุฉ ุงูุฑุฆูุณูุฉ ุงููุญุณูุจุฉ ุฅูู ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ููููุชุงุญ-ุงููููุฉ ููู ุงูุชุดููุฑ ุงูุฃูู. ุซู ูุชู ุชูููุฏ ุฅุฌุงุจุฉ ุงููุณุงุนุฏ ุงูุซุงููุฉ ุฐุงุชููุง `"ููุฌุฏ ูู ุฃููุงููุง ุญูุงูู 81 ููููู ูุณูุฉ"` ูุน ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ููููุชุงุญ-ุงููููุฉ ุงูุชู ุชุชููู ูู ูุชุฌูุงุช ุงููููุฉ ุงูุฑุฆูุณูุฉ ุงููุดูุฑุฉ ูู `"ุงููุณุชุฎุฏู: ูู ุนุฏุฏ ุงูุฃุดุฎุงุต ุงูุฐูู ูุนูุดูู ูู ูุฑูุณุงุ \n ุงููุณุงุนุฏ: ูุนูุด ุญูุงูู 75 ููููู ุดุฎุต ูู ูุฑูุณุง \n ุงููุณุชุฎุฏู: ููู ุนุฏุฏ ุงูุฃุดุฎุงุต ูู ุฃููุงููุงุ"`.

ูุฌุจ ููุงุญุธุฉ ุฃูุฑูู ููุง:

1. ุงูุญูุงุธ ุนูู ูู ุงูุณูุงู ุฃูุฑ ุจุงูุบ ุงูุฃูููุฉ ูููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ุงูุชู ูุชู ูุดุฑูุง ูู ุงูุฏุฑุฏุดุฉ ุญุชู ูููู ูููุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ูู ุงูุณูุงู ุงูุณุงุจู ูููุญุงุฏุซุฉ. ุนูู ุณุจูู ุงููุซุงูุ ุจุงููุณุจุฉ ูููุซุงู ุฃุนูุงูุ ูุญุชุงุฌ ูููุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ุฅูู ููู ุฃู ุงููุณุชุฎุฏู ูุดูุฑ ุฅูู ุงูุณูุงู ุนูุฏ ุงูุณุคุงู `"ููู ุนุฏุฏ ุงูุฃุดุฎุงุต ูู ุฃููุงููุงุ"`.

2. ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ููููุชุงุญ-ุงููููุฉ ูููุฏุฉ ุฌุฏูุง ููุฏุฑุฏุดุฉ ุญูุซ ุชุชูุญ ููุง ุงูุงุณุชูุฑุงุฑ ูู ุฒูุงุฏุฉ ุชุงุฑูุฎ ุงูุฏุฑุฏุดุฉ ุงููุดูุฑ ุจุฏูุงู ูู ุงูุงุถุทุฑุงุฑ ุฅูู ุฅุนุงุฏุฉ ุชุดููุฑ ุชุงุฑูุฎ ุงูุฏุฑุฏุดุฉ ูู ุงูุจุฏุงูุฉ (ููุง ูู ุงูุญุงูุ ุนูู ุณุจูู ุงููุซุงูุ ุนูุฏ ุงุณุชุฎุฏุงู ุจููุฉ ุงูุชุฑููุฒ-ูู ุงูุชุฑููุฒ).

ูู `transformers`ุ ุณุชุนูุฏ ููุงููุฉ `generate` ูููุฉ `past_key_values` ุนูุฏูุง ูุชู ุชูุฑูุฑ `return_dict_in_generate=True`ุ ุจุงูุฅุถุงูุฉ ุฅูู `use_cache=True` ุงูุงูุชุฑุงุถูุฉ. ูุงุญุธ ุฃูู ุบูุฑ ูุชุงุญ ุจุนุฏ ูู ุฎูุงู ูุงุฌูุฉ `pipeline`.

```python
# ุงูุชูููุฏ ูุงููุนุชุงุฏ
prompt = system_prompt + "ุณุคุงู: ูุฑุฌู ูุชุงุจุฉ ุฏุงูุฉ ูู ุจุงูุซูู ูุชุญููู ุงูุจุงูุชุงุช ุฅูู ุบูุบุงุจุงูุช.\n\nุงูุฅุฌุงุจุฉ: ููุง"
model_inputs = tokenizer(prompt, return_tensors='pt')
generation_output = model.generate(**model_inputs, max_new_tokens=60, return_dict_in_generate=True)
decoded_output = tokenizer.batch_decode(generation_output.sequences)[0]

# ุชูุฑูุฑ `past_key_values` ุงูุชู ุชูุช ุฅุนุงุฏุชูุง ูุชุณุฑูุน ุฌููุฉ ุงููุญุงุฏุซุฉ ุงูุชุงููุฉ
prompt = decoded_output + "\nุณุคุงู: ููู ูููููู ุชุนุฏูู ุงูุฏุงูุฉ ุฃุนูุงู ูุฅุฑุฌุงุน ููุบุงุจุงูุช ุจุฏูุงู ูู ุฐููุ\n\nุงูุฅุฌุงุจุฉ: ููุง"
model_inputs = tokenizer(prompt, return_tensors='pt')
generation_output = model.generate(
**model_inputs,
past_key_values=generation_output.past_key_values,
max_new_tokens=60,
return_dict_in_generate=True
)
tokenizer.batch_decode(generation_output.sequences)[0][len(prompt):]
```

**ุงูุฅุฎุฑุงุฌ**:

```
ูู ูุณุฎุฉ ูุนุฏูุฉ ูู ุงูุฏุงูุฉ ุงูุชู ุชููู ุจุฅุฑุฌุงุน ููุบุงุจุงูุช ุจุฏูุงู ูู ุฐูู.

def bytes_to_megabytes(bytes):
    return bytes / 1024 / 1024

ุงูุฅุฌุงุจุฉ: ุชููู ุงูุฏุงูุฉ ุจุฃุฎุฐ ุนุฏุฏ ูู ุงูุจุงูุชุงุช ูุฅุฏุฎุงู ูุฅุฑุฌุงุน ุนุฏุฏ ุงูุจุงูุชุงุช ุจุงูููุบุงุจุงูุช
```

ุฑุงุฆุนุ ูุง ูุชู ุฅููุงู ููุช ุฅุถุงูู ูุฅุนุงุฏุฉ ุญุณุงุจ ููุณ ุงูููุชุงุญ ูุงูููู ูุทุจูุฉ ุงูุงูุชูุงู! ููุงู ูุน ุฐูู ูุดููุฉ ูุงุญุฏุฉ. ูู ุญูู ูุชู ุชูููู ุฐุงูุฑุฉ ุงููุตูู ุงูุนุดูุงุฆู ุงููุทููุจุฉ ุจุดูู ูุจูุฑ ููุตูููุฉ \\( \mathbf{QK}^T \\)ุ ูููู ุฃู ุชุตุจุญ ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ููููุชุงุญ-ุงููููุฉ ููููุฉ ููุบุงูุฉ ูู ุญูุซ ุงูุฐุงูุฑุฉ ุจุงููุณุจุฉ ูุชุณูุณูุงุช ุงูุฅุฏุฎุงู ุงูุทูููุฉ ุฃู ุงูุฏุฑุฏุดุฉ ูุชุนุฏุฏุฉ ุงูุฃุฏูุงุฑ. ุชุฐูุฑ ุฃู ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ููููุชุงุญ-ุงููููุฉ ุชุญุชุงุฌ ุฅูู ุชุฎุฒูู ูุชุฌูุงุช ุงููููุฉ ุงูุฑุฆูุณูุฉ ูุฌููุน ูุชุฌูุงุช ุงูุฅุฏุฎุงู ุงูุณุงุจูุฉ \\( \mathbf{x}_i \text{, for } i \in \{1, \ldots, c - 1\} \\) ูุฌููุน ุทุจูุงุช ุงูุงูุชูุงู ุงูุฐุงุชู ููุฌููุน ุฑุคูุณ ุงูุงูุชูุงู.

ุฏุนูุง ูุญุณุจ ุนุฏุฏ ุงูููู ุงูุนุงุฆูุฉ ุงูุชู ูุฌุจ ุชุฎุฒูููุง ูู ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ููููุชุงุญ-ุงููููุฉ ููููุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ `bigcode/octocoder` ุงูุฐู ุงุณุชุฎุฏููุงู ูู ูุจู.

ูุจูุบ ุนุฏุฏ ุงูููู ุงูุนุงุฆูุฉ ุถุนู ุทูู ุงูุชุณูุณู ูุถุฑูุจูุง ูู ุนุฏุฏ ุฑุคูุณ ุงูุงูุชูุงู ูุถุฑูุจูุง ูู ุจุนุฏ ุฑุฃุณ ุงูุงูุชูุงู ููุถุฑูุจูุง ูู ุนุฏุฏ ุงูุทุจูุงุช.

ูุญุณุงุจ ุฐูู ููููุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ูุฏููุง ุจุทูู ุชุณูุณู ุฅุฏุฎุงู ุงูุชุฑุงุถู ูุจูุบ 16000:

```python
config = model.config
2 * 16_000 * config.n_layer * config.n_head * config.n_embd // config.n_head
```

**ุงูุฅุฎุฑุงุฌ**:

```
7864320000
```

ุญูุงูู 8 ูููุงุฑุงุช ูููุฉ ุนุงุฆูุฉ! ูุชุทูุจ ุชุฎุฒูู 8 ูููุงุฑุงุช ูููุฉ ุนุงุฆูุฉ ูู ุฏูุฉ `float16` ุญูุงูู 15 ุฌูุฌุงุจุงูุช ูู ุฐุงูุฑุฉ ุงููุตูู ุงูุนุดูุงุฆูุ ููู ูุง ููุฑุจ ูู ูุตู ูุฒู ุงููููุฐุฌ ููุณู!

ุงูุชุฑุญ ุงูุจุงุญุซูู ุทุฑููุชูู ุชุณูุญุงู ุจุชูููู ุชูููุฉ ุงูุฐุงูุฑุฉ ูุชุฎุฒูู ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ููููุชุงุญ-ุงููููุฉุ ูุชู ุงุณุชูุดุงูููุง ูู ุงูุฃูุณุงู ุงููุฑุนูุฉ ุงูุชุงููุฉ.

#### 3.2.2 ุงูุงูุชูุงู ูุชุนุฏุฏ ุงูุงุณุชุนูุงูุงุช (MQA)

ุชู ุงูุชุฑุงุญ [ุงูุงูุชูุงู ูุชุนุฏุฏ ุงูุงุณุชุนูุงูุงุช](https://arxiv.org/abs/1911.02150) ูู ูุฑูุฉ *Fast Transformer Decoding: One Write-Head is All You Need* ุจูุงุณุทุฉ Noam Shazeer. ููุง ููุญู ุงูุนููุงูุ ุงูุชุดู ููุงู ุฃูู ุจุฏูุงู ูู ุงุณุชุฎุฏุงู `n_head` ุฃูุฒุงู ุฅุณูุงุท ุงููููุฉ ุงูุฑุฆูุณูุฉุ ูููู ุงุณุชุฎุฏุงู ุฒูุฌ ูุงุญุฏ ูู ุฃูุฒุงู ุงูุฅุณูุงุท ูููููุฉ ุงูุฑุฆูุณูุฉ ูุดุชุฑูุฉ ุนุจุฑ ุฌููุน ุฑุคูุณ ุงูุงูุชูุงู ุฏูู ุฃู ูุชุฏููุฑ ุฃุฏุงุก ุงููููุฐุฌ ุจุดูู ูุจูุฑ.

> ูู ุฎูุงู ุงุณุชุฎุฏุงู ุฒูุฌ ูุงุญุฏ ูู ุฃูุฒุงู ุงูุฅุณูุงุท ูููููุฉ ุงูุฑุฆูุณูุฉุ ูุฌุจ ุฃู ุชููู ูุชุฌูุงุช ุงููููุฉ ุงูุฑุฆูุณูุฉ \\( \mathbf{k}_i, \mathbf{v}_i \\) ูุชุทุงุจูุฉ ุนุจุฑ ุฌููุน ุฑุคูุณ ุงูุงูุชูุงูุ ููู ูุง ูุนูู ุจุฏูุฑู ุฃููุง ูุญุชุงุฌ ููุท ุฅูู ุชุฎุฒูู ุฒูุฌ ูุงุญุฏ ูู ุงูุฅุณูุงุทุงุช ูููููุฉ ุงูุฑุฆูุณูุฉ ูู ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ุจุฏูุงู ูู `n_head`.

ูุธุฑูุง ูุฃู ูุนุธู ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ุชุณุชุฎุฏู ูุง ุจูู 20 ู100 ุฑุฃุณ ุงูุชูุงูุ ูุฅู MQA ูููู ุจุดูู ูุจูุฑ ูู ุงุณุชููุงู ุงูุฐุงูุฑุฉ ูุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช ููููุชุงุญ-ุงููููุฉ. ุจุงููุณุจุฉ ููููุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ุงููุณุชุฎุฏู ูู ูุฐุง ุงูุฏูุชุฑุ ูููููุง ุชูููู ุงุณุชููุงู ุงูุฐุงูุฑุฉ ุงููุทููุจุฉ ูู 15 ุฌูุฌุงุจุงูุช ุฅูู ุฃูู ูู 400 ููุฌุงุจุงูุช ุนูุฏ ุทูู ุชุณูุณู ุงูุฅุฏุฎุงู 16000.

ุจุงูุฅุถุงูุฉ ุฅูู ุชูููุฑ ุงูุฐุงูุฑุฉุ ูุคุฏู MQA ุฃูุถูุง ุฅูู ุชุญุณูู ุงูููุงุกุฉ ุงูุญุณุงุจูุฉ ููุง ูู ููุถุญ ุฃุฏูุงู.

ูู ูู ุงูุชุดููุฑ ุฐุงุชู ุงูุฑุฌูุนุ ูุฌุจ ุฅุนุงุฏุฉ ุชุญููู ูุชุฌูุงุช ุงููููุฉ ุงูุฑุฆูุณูุฉ ุงููุจูุฑุฉุ ูุฏูุฌูุง ูุน ูุชุฌู ุงููููุฉ ุงูุฑุฆูุณูุฉ ุงูุญุงูู ูุฅุฏุฎุงููุง ุจุนุฏ ุฐูู ูู ุญุณุงุจ \\( \mathbf{q}_c\mathbf{K}^T \\) ูู ูู ุฎุทูุฉ. ุจุงููุณุจุฉ ููู ุงูุชุดููุฑ ุฐุงุชู ุงูุฑุฌูุนุ ูููู ุฃู ุชุตุจุญ ุนุฑุถ ุงููุทุงู ุงูุชุฑุฏุฏู ููุฐุงูุฑุฉ ุงููุทููุจุฉ ูุฅุนุงุฏุฉ ุงูุชุญููู ุงููุณุชูุฑ ุงุฎุชูุงููุง ุฒููููุง ุฎุทูุฑูุง. ูู ุฎูุงู ุชูููู ุญุฌู ูุชุฌูุงุช ุงููููุฉ ุงูุฑุฆูุณูุฉุ ููุฒู ุงููุตูู ุฅูู ุฐุงูุฑุฉ ุฃููุ ููุง ูููู ูู ุงุฎุชูุงู
## ุฎุงุชูุฉ

ูุฃุชู ูุฌุชูุน ุงูุจุญุซ ุจุงุณุชูุฑุงุฑ ุจุทุฑู ุฌุฏูุฏุฉ ูุฐููุฉ ูุชุณุฑูุน ููุช ุงูุงุณุชูุชุงุฌ ูููุงุฐุฌ ุงููุบุฉ ุงูุถุฎูุฉ ูุงููุชุฒุงูุฏุฉ. ุนูู ุณุจูู ุงููุซุงูุ ุฃุญุฏ ุงุชุฌุงูุงุช ุงูุจุญุซ ุงููุงุนุฏุฉ ูู ูุฐุง ุงููุฌุงู ูู "ูู ุงูุชุดููุฑ ุงูุชุฎูููู"ุ ุญูุซ ุชููู ููุงุฐุฌ ุงููุบุฉ ุงูุฃุตุบุฑ ูุงูุฃุณุฑุน ุจุชูููุฏ "ุงูุฑููุฒ ุงูุณููุฉ"ุ ุจูููุง ุชููู ููุงุฐุฌ ุงููุบุฉ ุงูุถุฎูุฉ ููุณูุง ุจุชูููุฏ "ุงูุฑููุฒ ุงูุตุนุจุฉ" ููุท. ูุงูุฎุฑูุฌ ุฅูู ูุฒูุฏ ูู ุงูุชูุงุตูู ูุฎุฑุฌ ุนู ูุทุงู ูุฐุง ุงูุฏูุชุฑุ ูููู ูููู ูุฑุงุกุชู ูู ูุฐู [ุงูุชุฏูููุฉ ุงูุฑุงุฆุนุฉ](https://huggingface.co/blog/assisted-generation).

ูุนูุฏ ุงูุณุจุจ ูู ูุฏุฑุฉ ููุงุฐุฌ ุงููุบุฉ ุงูุถุฎูุฉ ูุซู GPT3/4 ูLlama-2-70b ูClaude ูPaLM ุนูู ุงูุนูู ุจุณุฑุนุฉ ูุจูุฑุฉ ูู ูุงุฌูุงุช ุงูุฏุฑุฏุดุฉ ูุซู [Hugging Face Chat](https://huggingface.co/chat/) ุฃู ChatGPT ุฅูู ุญุฏ ูุจูุฑ ุฅูู ุงูุชุญุณููุงุช ุงููุฐููุฑุฉ ุฃุนูุงู ูู ุงูุฏูุฉ ูุงูุฎูุงุฑุฒููุงุช ูุงูุจููุฉ.

ูู ุงููุณุชูุจูุ ุณุชุฒุฏุงุฏ ูุณุฑุนุงุช ูุซู ูุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณููุงุช (GPUs) ููุญุฏุงุช ูุนุงูุฌุฉ tensor (TPUs) ูุบูุฑูุง ูู ุญูุซ ุงูุณุฑุนุฉ ูุณุชุณูุญ ุจูุฒูุฏ ูู ุงูุฐุงูุฑุฉุ ูููู ูุฌุจ ุนูู ุงููุฑุก ูุน ุฐูู ุฃู ูุชุฃูุฏ ุฏุงุฆููุง ูู ุงุณุชุฎุฏุงู ุฃูุถู ุงูุฎูุงุฑุฒููุงุช ูุงูุชุตูููุงุช ุงููุชุงุญุฉ ูุชุญููู ุฃูุตู ุงุณุชูุงุฏุฉ ูู ุฃููุงูู.