# ุงูุตูุฑุฉ ุฅูู ุงูุตูุฑุฉ
[[open-in-colab]]

ุงูุตูุฑุฉ ุฅูู ุงูุตูุฑุฉ ูุดุงุจูุฉ ูู [ุงููุต ุฅูู ุงูุตูุฑุฉ](conditional_image_generation)ุ ูููู ุจุงูุฅุถุงูุฉ ุฅูู ููุฌูุ ููููู ุฃูุถูุง ุชูุฑูุฑ ุตูุฑุฉ ุฃูููุฉ ูููุทุฉ ุจุฏุงูุฉ ูุนูููุฉ ุงูุงูุชุดุงุฑ. ูุชู ุชุฑููุฒ ุงูุตูุฑุฉ ุงูุฃูููุฉ ุฅูู ูุณุงุญุฉ ุฎููุฉ ููุชู ุฅุถุงูุฉ ุงูุถูุถุงุก ุฅูููุง. ุซู ุชุฃุฎุฐ ุงููููุฐุฌ ุงูุฎูู ููุงูุชุดุงุฑ ููุฌู ูุงูุตูุฑุฉ ุงูุฎููุฉ ุงูุตุงุฎุจุฉุ ููุชููุน ุงูุถูุถุงุก ุงููุถุงูุฉุ ููุฒูู ุงูุถูุถุงุก ุงููุชููุนุฉ ูู ุงูุตูุฑุฉ ุงูุฃูููุฉ ุงูุฎููุฉ ููุญุตูู ุนูู ุงูุตูุฑุฉ ุงูุฎููุฉ ุงูุฌุฏูุฏุฉ. ุฃุฎูุฑูุงุ ูููู ูู ุงูุชุฑููุฒ ุจุชุฑุฌูุฉ ุงูุตูุฑุฉ ุงูุฎููุฉ ุงูุฌุฏูุฏุฉ ูุฑุฉ ุฃุฎุฑู ุฅูู ุตูุฑุฉ.

ูุน ๐ค Diffusersุ ูุฐุง ุณูู ูุซู 1-2-3:

1. ูู ุจุชุญููู ููุทุฉ ุชูุชูุด ูู ูุฆุฉ [`AutoPipelineForImage2Image`]ุ ูููู ูุฐุง ุงูุฃูุจูุจ ุชููุงุฆููุง ุจุชุนููู ุชุญููู ูุฆุฉ ุงูุฃูุงุจูุจ ุงูุตุญูุญุฉ ุจูุงุกู ุนูู ููุทุฉ ุงูุชูุชูุด:

```py
ุงุณุชูุฑุงุฏ ุงูุดุนูุฉ
ูู ุงููุงุดุฑูู ุงุณุชูุฑุงุฏ AutoPipelineForImage2Image
ูู ุงููุงุดุฑูู. ุงุณุชูุฑุงุฏ utils ุชุญููู ุงูุตูุฑุฉุ ูุฌุนู ุตูุฑุฉ ุงูุดุจูุฉ

ุฎุท ุงูุฃูุงุจูุจ = AutoPipelineForImage2Image.from_pretrained (
"kandinsky-community/kandinsky-2-2-decoder"ุ torch_dtype=torch.float16ุ use_safetensors=True
)
ุฎุท ุงูุฃูุงุจูุจ. ุชูููู_ูููุฐุฌ_ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ_offload ()
# ุงุญุฐู ุงูุณุทุฑ ุงูุชุงูู ุฅุฐุง ูู ูุชู ุชุซุจูุช xFormers ุฃู ูุฏูู PyTorch 2.0 ุฃู ุฃุนูู ูุซุจุช
ุฎุท ุงูุฃูุงุจูุจ. ุชูููู_xformers_memory_efficient_attention ()
```

<Tip>
ุณุชูุงุญุธ ุทูุงู ุงูุฏูููุ ูุณุชุฎุฏู [`~DiffusionPipeline.enable_model_cpu_offload`] ู [`~DiffusionPipeline.enable_xformers_memory_efficient_attention`]ุ ูุชูููุฑ ุงูุฐุงูุฑุฉ ูุฒูุงุฏุฉ ุณุฑุนุฉ ุงูุงุณุชุฏูุงู. ุฅุฐุง ููุช ุชุณุชุฎุฏู PyTorch 2.0ุ ููุณุช ุจุญุงุฌุฉ ุฅูู ุงุณุชุฏุนุงุก [`~DiffusionPipeline.enable_xformers_memory_efficient_attention`] ุนูู ุฎุท ุฃูุงุจูุจู ูุฃูู ุณูููู ุจุงููุนู ุจุงุณุชุฎุฏุงู ุงูุชูุงู PyTorch 2.0 ุงูุฃุตูู [scaled-dot product](../optimization/torch2.0#scaled-dot-product-attention).
</Tip>

2. ูู ุจุชุญููู ุตูุฑุฉ ูุชูุฑูุฑูุง ุฅูู ุฎุท ุงูุฃูุงุจูุจ:

```py
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/cat.png")
```

3. ูู ุจุชูุฑูุฑ ููุฌู ูุตูุฑุฉ ุฅูู ุฎุท ุงูุฃูุงุจูุจ ูุฅูุดุงุก ุตูุฑุฉ:

```py
prompt = "cat wizard, gandalf, lord of the rings, detailed, fantasy, cute, adorable, Pixar, Disney, 8k"
image = pipeline(prompt, image=init_image).images[0]
make_image_grid([init_image, image], rows=1, cols=2)
```

<div class="flex gap-4">
<div>
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/cat.png"/>
<figcaption class="mt-2 text-center text-sm text-gray-500>ุงูุตูุฑุฉ ุงูุฃูููุฉ</figcaption>
</div>
<div>
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img.png"/>
<figcaption class="mt-2 text-center text-sm text-gray-500>ุงูุตูุฑุฉ ุงููููุฏุฉ</figcaption>
</div>
</div>

## ุงูููุงุฐุฌ ุงูุดุนุจูุฉ

ุฃูุซุฑ ููุงุฐุฌ ุงูุตูุฑ ุฅูู ุงูุตูุฑ ุดููุนูุง ูู [Stable Diffusion v1.5](https://huggingface.co/runwayml/stable-diffusion-v1-5)ุ [Stable Diffusion XL (SDXL)](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0)ุ ู [Kandinsky 2.2](https://huggingface.co/kandinsky-community/kandinsky-2-2-decoder). ุชุฎุชูู ูุชุงุฆุฌ ููุงุฐุฌ Stable Diffusion ู Kandinsky ุจุณุจุจ ุงูุงุฎุชูุงูุงุช ูู ุจููุชูุง ูุนูููุฉ ุชุฏุฑูุจูุงุ ููููู ุนููููุง ุชููุน ุฃู ุชูุชุฌ SDXL ุตูุฑูุง ุฐุงุช ุฌูุฏุฉ ุฃุนูู ูู Stable Diffusion v1.5. ุฏุนูุง ูููู ูุธุฑุฉ ุณุฑูุนุฉ ุนูู ููููุฉ ุงุณุชุฎุฏุงู ูู ูู ูุฐู ุงูููุงุฐุฌ ูููุงุฑูุฉ ูุชุงุฆุฌูุง.

### ุงูุงูุชุดุงุฑ ุงููุณุชูุฑ v1.5

Stable Diffusion v1.5 ุนุจุงุฑุฉ ุนู ูููุฐุฌ ุงูุชุดุงุฑ ุฎูู ูุชู ุชููุฆุชู ูู ููุทุฉ ุชูุชูุด ูุจูุฑุฉุ ููุชู ุถุจุท ุฏูุชู ุจุดูู ุฃูุจุฑ ูู 595 ุฃูู ุฎุทูุฉ ุนูู ุตูุฑ 512x512. ูุงุณุชุฎุฏุงู ูุฐุง ุงูุฃูุจูุจ ููุตูุฑุฉ ุฅูู ุงูุตูุฑุฉุ ุณุชุญุชุงุฌ ุฅูู ุฅุนุฏุงุฏ ุตูุฑุฉ ุฃูููุฉ ูุชูุฑูุฑูุง ุฅูู ุฎุท ุงูุฃูุงุจูุจ. ุซู ููููู ุชูุฑูุฑ ููุฌู ูุงูุตูุฑุฉ ุฅูู ุฎุท ุงูุฃูุงุจูุจ ูุฅูุดุงุก ุตูุฑุฉ ุฌุฏูุฏุฉ:

```py
ุงุณุชูุฑุงุฏ ุงูุดุนูุฉ
ูู ุงููุงุดุฑูู ุงุณุชูุฑุงุฏ AutoPipelineForImage2Image
ูู ุงููุงุดุฑูู. ุงุณุชูุฑุงุฏ utils ุฌุนู ุตูุฑุฉ ุงูุดุจูุฉุ ุชุญููู ุงูุตูุฑุฉ

ุฎุท ุงูุฃูุงุจูุจ = AutoPipelineForImage2Image.from_pretrained (
"runwayml/stable-diffusion-v1-5"ุ torch_dtype=torch.float16ุ variant="fp16"ุ use_safetensors=True
)
ุฎุท ุงูุฃูุงุจูุจ. ุชูููู_ูููุฐุฌ_ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ_offload ()
# ุงุญุฐู ุงูุณุทุฑ ุงูุชุงูู ุฅุฐุง ูู ูุชู ุชุซุจูุช xFormers ุฃู ูุฏูู PyTorch 2.0 ุฃู ุฃุนูู ูุซุจุช
ุฎุท ุงูุฃูุงุจูุจ. ุชูููู_xformers_memory_efficient_attention ()

# ุฅุนุฏุงุฏ ุงูุตูุฑุฉ
url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png"
init_image = load_image(url)

prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"

# ุชูุฑูุฑ ููุฌู ูุตูุฑุฉ ุฅูู ุฎุท ุงูุฃูุงุจูุจ
image = pipeline(promptุ image=init_image).images[0]
make_image_grid([init_image, image]ุ ุงูุตููู=1ุ cols=2)
```

<div class="flex gap-4">
<div>
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png"/>
<figcaption class="mt-2 text-center text-sm text-gray-500>ุงูุตูุฑุฉ ุงูุฃูููุฉ</figcaption>
</div>
<div>
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-sdv1.5.png"/>
<figcaption class="mt-2 text-center text-sm text-gray-500>ุงูุตูุฑุฉ ุงููููุฏุฉ</figcaption>
</div>
</div>

### ุงูุงูุชุดุงุฑ ุงููุณุชูุฑ XL (SDXL)

SDXL ูู ุฅุตุฏุงุฑ ุฃูุซุฑ ููุฉ ูู ูููุฐุฌ Stable Diffusion. ูุณุชุฎุฏู ูููุฐุฌูุง ุฃุณุงุณููุง ุฃูุจุฑุ ููููุฐุฌูุง ูุญุณููุง ุฅุถุงูููุง ูุฒูุงุฏุฉ ุฌูุฏุฉ ุฅุฎุฑุงุฌ ุงููููุฐุฌ ุงูุฃุณุงุณู. ุงูุฑุฃ ุฏููู [SDXL](sdxl) ููุญุตูู ุนูู ุฏููู ุฃูุซุฑ ุชูุตููุงู ุญูู ููููุฉ ุงุณุชุฎุฏุงู ูุฐุง ุงููููุฐุฌุ ูุงูุชูููุงุช ุงูุฃุฎุฑู ุงูุชู ูุณุชุฎุฏููุง ูุฅูุชุงุฌ ุตูุฑ ุนุงููุฉ ุงูุฌูุฏุฉ.

```py
ุงุณุชูุฑุงุฏ ุงูุดุนูุฉ
ูู ุงููุงุดุฑูู ุงุณุชูุฑุงุฏ AutoPipelineForImage2Image
ูู ุงููุงุดุฑูู. ุงุณุชูุฑุงุฏ utils ุฌุนู ุตูุฑุฉ ุงูุดุจูุฉุ ุชุญููู ุงูุตูุฑุฉ

ุฎุท ุงูุฃูุงุจูุจ = AutoPipelineForImage2Image.from_pretrained (
"stabilityai/stable-diffusion-xl-refiner-1.0"ุ torch_dtype=torch.float16ุ variant="fp16"ุ use_safetensors=True
)
ุฎุท ุงูุฃูุงุจูุจ. ุชูููู_ูููุฐุฌ_ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ_offload ()
# ุงุญุฐู ุงูุณุทุฑ ุงูุชุงูู ุฅุฐุง ูู ูุชู ุชุซุจูุช xFormers ุฃู ูุฏูู PyTorch 2.0 ุฃู ุฃุนูู ูุซุจุช
ุฎุท ุงูุฃูุงุจูุจ. ุชูููู_xformers_memory_efficient_attention ()

# ุฅุนุฏุงุฏ ุงูุตูุฑุฉ
url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-sdxl-init.png"
init_image = load_image(url)

prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"

# ุชูุฑูุฑ ููุฌู ูุตูุฑุฉ ุฅูู ุฎุท ุงูุฃูุงุจูุจ
image = pipeline(promptุ image=init_imageุ strength=0.5).images[0]
make_image_grid([init_image, image]ุ ุงูุตููู=1ุ cols=2)
```

<div class="flex gap-4">
<div>
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-sdxl-init.png"/>
<figcaption class="mt-2 text-center text-sm text-gray-500>ุงูุตูุฑุฉ ุงูุฃูููุฉ</figcaption>
</div>
<div>
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-sdxl.png"/>
<figcaption class="mt-2 text-center text-sm text-gray-500>ุงูุตูุฑุฉ ุงููููุฏุฉ</figcaption>
</div>
</div>

### ูุงูุฏููุณูู 2.2

ูุฎุชูู ูููุฐุฌ ูุงูุฏููุณูู ุนู ููุงุฐุฌ Stable Diffusion ูุฃูู ูุณุชุฎุฏู ูููุฐุฌูุง ูุณุจููุง ููุตูุฑ ูุฅูุดุงุก ุชุถูููุงุช ุงูุตูุฑ. ุชุณุงุนุฏ ุงูุชุถูููุงุช ูู ุฅูุดุงุก ูุญุงุฐุงุฉ ุฃูุถู ุจูู ุงููุต ูุงูุตูุฑุ ููุง ูุณูุญ ููููุฐุฌ ุงูุงูุชุดุงุฑ ุงูุฎูู ุจุชูููุฏ ุตูุฑ ุฃูุถู.

ุฃุจุณุท ุทุฑููุฉ ูุงุณุชุฎุฏุงู Kandinsky 2.2 ูู:

```py
ุงุณุชูุฑุงุฏ ุงูุดุนูุฉ
ูู ุงููุงุดุฑูู ุงุณุชูุฑุงุฏ AutoPipelineForImage2Image
ูู ุงููุงุดุฑูู. ุงุณุชูุฑุงุฏ utils ุฌุนู ุตูุฑุฉ ุงูุดุจูุฉุ ุชุญููู ุงูุตูุฑุฉ

ุฎุท ุงูุฃูุงุจูุจ = AutoPipelineForImage2Image.from_pretrained (
"kandinsky-community/kandinsky-2-2-decoder"ุ torch_dtype=torch.float16ุ use_safetensors=True
)
ุฎุท ุงูุฃูุงุจูุจ. ุชูููู_ูููุฐุฌ_ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ_offload ()
# ุงุญุฐู ุงูุณุทุฑ ุงูุชุงูู ุฅุฐุง ูู ูุชู ุชุซุจูุช xFormers ุฃู ูุฏูู PyTorch 2.0 ุฃู ุฃุนูู ูุซุจุช
ุฎุท ุงูุฃูุงุจูุจ. ุชูููู_xformers_memory_efficient_attention ()

# ุฅุนุฏุงุฏ ุงูุตูุฑุฉ
url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png"
init_image = load_image(url)

prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"

# ุชูุฑูุฑ ููุฌู ูุตูุฑุฉ ุฅูู ุฎุท ุงูุฃูุงุจูุจ
image = pipeline(promptุ image=init_image).images[0]
make_image_grid([init_image, image]ุ ุงูุตููู=1ุ cols=2)
```

<div class="flex gap-4">
<div>
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png"/>
<figcaption class="mt-2 text-center text-sm text-gray-500>ุงูุตูุฑุฉ ุงูุฃูููุฉ</figcaption>
</div>
<div>
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-kandinsky.png"/>
<figcaption class="mt-2 text-center text-sm text-gray-500>ุงูุตูุฑุฉ ุงููููุฏุฉ</figcaption>
</div>
</div>

## ุชูููู ูุนููุงุช ุฎุท ุงูุฃูุงุจูุจ

ููุงู ุงูุนุฏูุฏ ูู ุงููุนููุงุช ุงููููุฉ ุงูุชู ููููู ุชูููููุง ูู ุฎุท ุงูุฃูุงุจูุจ ูุงูุชู ุณุชุคุซุฑ ุนูู ุนูููุฉ ุฅูุดุงุก ุงูุตูุฑ ูุฌูุฏุฉ ุงูุตูุฑุฉ. ุฏุนูุง ูููู ูุธุฑุฉ ูุงุญุตุฉ ุนูู ูุง ุชูุนูู ูุฐู ุงููุนููุงุช ูููู ูุคุซุฑ ุชุบููุฑูุง ุนูู ุงูุฅุฎุฑุงุฌ.
### ุงูููุฉ

`strength` ูู ุฃุญุฏ ุฃูู ุงููุนููุงุช ุงูุชู ูุฌุจ ูุฑุงุนุงุชูุงุ ูุณูููู ููุง ุชุฃุซูุฑ ูุจูุฑ ุนูู ุงูุตูุฑุฉ ุงูุชู ูุชู ุฅูุดุงุคูุง. ููู ุชุญุฏุฏ ูุฏู ุชุดุงุจู ุงูุตูุฑุฉ ุงููุงุชุฌุฉ ูุน ุงูุตูุฑุฉ ุงูุฃูููุฉ. ูุจุนุจุงุฑุฉ ุฃุฎุฑู:

- ๐ ุชุนุทู ูููุฉ ุฃุนูู ูู `strength` ุงููููุฐุฌ ูุฒูุฏูุง ูู "ุงูุฅุจุฏุงุน" ูุฅูุดุงุก ุตูุฑุฉ ูุฎุชููุฉ ุนู ุงูุตูุฑุฉ ุงูุฃูููุฉุ ูุชุนูู ูููุฉ `strength` ุชุณุงูู 1.0 ุชุฌุงูู ุงูุตูุฑุฉ ุงูุฃูููุฉ ุฅูู ุญุฏ ูุจูุฑ

- ๐ ุชุนูู ูููุฉ ุฃูู ูู `strength` ุฃู ุงูุตูุฑุฉ ุงููุงุชุฌุฉ ุฃูุซุฑ ุชุดุงุจูุง ูุน ุงูุตูุฑุฉ ุงูุฃูููุฉ

ูุฑุชุจุท ูุนูู `strength` ู`num_inference_steps` ูุฃู `strength` ุชุญุฏุฏ ุนุฏุฏ ุฎุทูุงุช ุงูุถุฌูุฌ ุงููุฑุงุฏ ุฅุถุงูุชูุง. ุนูู ุณุจูู ุงููุซุงูุ ุฅุฐุง ูุงู `num_inference_steps` ูู 50 ู`strength` ูู 0.8ุ ููุฐุง ูุนูู ุฅุถุงูุฉ 40 (50 * 0.8) ุฎุทูุฉ ุถุฌูุฌ ุฅูู ุงูุตูุฑุฉ ุงูุฃูููุฉ ุซู ุฅุฒุงูุฉ ุงูุถุฌูุฌ ูู 40 ุฎุทูุฉ ููุญุตูู ุนูู ุงูุตูุฑุฉ ุงููููุฏุฉ ุญุฏูุซูุง.

```py
import torch
from diffusers import AutoPipelineForImage2Image
from diffusers.utils import make_image_grid, load_image

pipeline = AutoPipelineForImage2Image.from_pretrained(
"runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# prepare image
url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png"
init_image = load_image(url)

prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"

# pass prompt and image to pipeline
image = pipeline(prompt, image=init_image, strength=0.8).images[0]
make_image_grid([init_image, image], rows=1, cols=2)
```

<div class="flex flex-row gap-4">
<div class="flex-1">
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-strength-0.4.png"/>
<figcaption class="mt-2 text-center text-sm text-gray-500">strength = 0.4</figcaption>
</div>
<div class="flex-1">
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-strength-0.6.png"/>
<figcaption class="mt-โ text-center text-sm text-gray-500">strength = 0.6</figcaption>
</div>
<div class="flex-1">
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-strength-1.0.png"/>
<figcaption class="mt-2 text-center text-sm text-gray-500">strength = 1.0</figcaption>
</div>
</div>

### ูููุงุณ ุงูุชูุฌูู

ููุณุชุฎุฏู ูุนูู `guidance_scale` ููุชุญูู ูู ูุฏู ุชูุงูู ุงูุตูุฑุฉ ุงููููุฏุฉ ูุทูุจ ุงููุต. ุชุนูู ูููุฉ ุฃุนูู ูู `guidance_scale` ุฃู ุงูุตูุฑุฉ ุงููููุฏุฉ ุฃูุซุฑ ุชูุงููุง ูุน ุงูุทูุจุ ูู ุญูู ุฃู ูููุฉ ุฃูู ูู `guidance_scale` ุชุนูู ุฃู ุงูุตูุฑุฉ ุงููููุฏุฉ ูุฏููุง ูุณุงุญุฉ ุฃูุจุฑ ููุงูุญุฑุงู ุนู ุงูุทูุจ.

ููููู ุงูุฌูุน ุจูู `guidance_scale` ู`strength` ููุฒูุฏ ูู ุงูุชุญูู ุงูุฏููู ูู ูุฏู ุชุนุจูุฑ ุงููููุฐุฌ. ุนูู ุณุจูู ุงููุซุงูุ ูู ุจุฏูุฌ `strength + guidance_scale` ุนุงูููุง ููุฅุจุฏุงุน ุงูุฃูุตู ุฃู ุงุณุชุฎุฏู ูุฒูุฌูุง ูู `strength` ุงูููุฎูุถ ู`guidance_scale` ุงูููุฎูุถ ูุฅูุดุงุก ุตูุฑุฉ ุชุดุจู ุงูุตูุฑุฉ ุงูุฃูููุฉ ูููููุง ููุณุช ูุฑุชุจุทุฉ ุจุดูู ุตุงุฑู ุจุงูุทูุจ.

```py
import torch
from diffusers import AutoPipelineForImage2Image
from diffusers.utils import make_image_grid, load_image

pipeline = AutoPipelineForImage2Image.from_pretrained(
"runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# prepare image
url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png"
init_image = load_image(url)

prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"

# pass prompt and image to pipeline
image = pipeline(prompt, image=init_image, guidance_scale=8.0).images[0]
make_image_grid([init_image, image], rows=1, cols=2)
```

<div class="flex flex-row gap-4">
<div class="flex-1">
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-guidance-0.1.png"/>
<figcaption class="mt-2 text-center text-sm text-gray-500">guidance_scale = 0.1</figcaption>
</div>
<div class="flex-1">
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-guidance-3.0.png"/>
<figcaption class="mt-2 text-center text-sm text-gray-500">guidance_scale = 5.0</figcaption>
</div>
<div class="flex-1">
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-guidance-7.5.png"/>
<figcaption class="mt-2 text-center text-sm text-gray-500">guidance_scale = 10.0</figcaption>
</div>
</div>

### ุทูุจ ุณูุจู

ูุคุฏู ุงูุทูุจ ุงูุณูุจู ุฅูู ุชููุฆุฉ ุงููููุฐุฌ ูุนุฏู ุชุถููู ุฃุดูุงุก ูู ุตูุฑุฉุ ููููู ุงุณุชุฎุฏุงูู ูุชุญุณูู ุฌูุฏุฉ ุงูุตูุฑุฉ ุฃู ุชุนุฏูููุง. ุนูู ุณุจูู ุงููุซุงูุ ููููู ุชุญุณูู ุฌูุฏุฉ ุงูุตูุฑุฉ ุนู ุทุฑูู ุชุถููู ูุทุงูุจุงุช ุณูุจูุฉ ูุซู "ุชูุงุตูู ุณูุฆุฉ" ุฃู "ุถุจุงุจู" ูุชุดุฌูุน ุงููููุฐุฌ ุนูู ุฅูุดุงุก ุตูุฑุฉ ุฐุงุช ุฌูุฏุฉ ุฃุนูู. ุฃู ููููู ุชุนุฏูู ุตูุฑุฉ ุนู ุทุฑูู ุชุญุฏูุฏ ุงูุฃุดูุงุก ุงูุชู ุณูุชู ุงุณุชุจุนุงุฏูุง ูู ุงูุตูุฑุฉ.

```py
import torch
from diffusers import AutoPipelineForImage2Image
from diffusers.utils import make_image_grid, load_image

pipeline = AutoPipelineForImage2Image.from_pretrained(
"stabilityai/stable-diffusion-xl-refiner-1.0", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# prepare image
url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png"
init_image = load_image(url)

prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"
negative_prompt = "ugly, deformed, disfigured, poor details, bad anatomy"

# pass prompt and image to pipeline
image = pipeline(prompt, negative_prompt=negative_prompt, image=init_image).images[0]
make_image_grid([init_image, image], rows=1, cols=2)
```

<div class="flex flex-row gap-4">
<div class="flex-1">
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-negative-1.png"/>
<figcaption class="mt-2 text-center text-sm text-gray-500">negative_prompt = "ugly, deformed, disfigured, poor details, bad anatomy"</figcaption>
</div>
<div class="flex-1">
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-negative-2.png"/>
<figcaption class="mt-2 text-center text-sm text-gray-500">negative_prompt = "jungle"</figcaption>
</div>
</div>

## ุฎุทูุท ุฃูุงุจูุจ ุงูุตูุฑุฉ ุฅูู ุงูุตูุฑุฉ ุงููุชุณูุณูุฉ

ููุงู ุจุนุถ ุงูุทุฑู ุงููุซูุฑุฉ ููุงูุชูุงู ุงูุฃุฎุฑู ุงูุชู ููููู ูู ุฎูุงููุง ุงุณุชุฎุฏุงู ุฎุท ุฃูุงุจูุจ ุงูุตูุฑุฉ ุฅูู ุงูุตูุฑุฉ ุจุฎูุงู ูุฌุฑุฏ ุฅูุดุงุก ุตูุฑุฉ (ุนูู ุงูุฑุบู ูู ุฃู ูุฐุง ุฑุงุฆุน ุฃูุถูุง). ููููู ุงููุถู ูุฏููุง ูุฑุจุทู ุจุฎุทูุท ุฃูุงุจูุจ ุฃุฎุฑู.

### ุงููุต ุฅูู ุงูุตูุฑุฉ ุฅูู ุงูุตูุฑุฉ

ูุณูุญ ุฑุจุท ุฎุท ุฃูุงุจูุจ ุงููุต ุฅูู ุงูุตูุฑุฉ ูุงูุตูุฑุฉ ุฅูู ุงูุตูุฑุฉ ุจุฅูุดุงุก ุตูุฑุฉ ูู ุงููุต ูุงุณุชุฎุฏุงู ุงูุตูุฑุฉ ุงููููุฏุฉ ูุตูุฑุฉ ุฃูููุฉ ูุฎุท ุฃูุงุจูุจ ุงูุตูุฑุฉ ุฅูู ุงูุตูุฑุฉ. ูุฐุง ูููุฏ ุฅุฐุง ููุช ุชุฑูุฏ ุฅูุดุงุก ุตูุฑุฉ ูู ุงูุตูุฑ. ุนูู ุณุจูู ุงููุซุงูุ ุฏุนูุง ูููู ุจุชุณูุณู ูููุฐุฌ Stable Diffusion ููููุฐุฌ Kandinsky.

ุงุจุฏุฃ ุจุฅูุดุงุก ุตูุฑุฉ ุจุงุณุชุฎุฏุงู ุฎุท ุฃูุงุจูุจ ุงููุต ุฅูู ุงูุตูุฑุฉ:

```py
from diffusers import AutoPipelineForText2Image, AutoPipelineForImage2Image
import torch
from diffusers.utils import make_image_grid

pipeline = AutoPipelineForText2Image.from_pretrained(
"runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

text2image = pipeline("Astronaut in a jungle, cold color palette, muted colors, detailed, 8k").images[0]
text2image
```

ุงูุขู ููููู ุชูุฑูุฑ ูุฐู ุงูุตูุฑุฉ ุงููููุฏุฉ ุฅูู ุฎุท ุฃูุงุจูุจ ุงูุตูุฑุฉ ุฅูู ุงูุตูุฑุฉ:

```py
pipeline = AutoPipelineForImage2Image.from_pretrained(
"kandinsky-community/kandinsky-2-2-decoder", torch_dtype=torch.float16, use_safetensors=True
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

image2image = pipeline("Astronaut in a jungle, cold color palette, muted colors, detailed, 8k", image=text2image).images[0]
make_image_grid([text2image, image2image], rows=1, cols=2)
```
### ุฑุจุท ุนุฏุฉ ุฃูุงุจูุจ ููุตูุฑ ูุน ุจุนุถูุง ุงูุจุนุถ
ููููู ุฃูุถูุง ุฑุจุท ุนุฏุฉ ุฃูุงุจูุจ ููุตูุฑ ูุน ุจุนุถูุง ุงูุจุนุถ ูุฅูุดุงุก ุตูุฑ ุฃูุซุฑ ุฅุซุงุฑุฉ ููุงูุชูุงู. ูููู ุฃู ูููู ูุฐุง ูููุฏูุง ูุฃุฏุงุก ููู ุงูุฃุณููุจ ุจุดูู ุชูุฑุงุฑู ุนูู ุตูุฑุฉุ ุฃู ุฅูุดุงุก ุตูุฑ GIF ูุตูุฑุฉุ ุฃู ุงุณุชุนุงุฏุฉ ุงูุฃููุงู ูุตูุฑุฉุ ุฃู ุงุณุชุนุงุฏุฉ ุงูููุงุทู ุงูููููุฏุฉ ูู ุตูุฑุฉ.

ุงุจุฏุฃ ุจุชูููุฏ ุตูุฑุฉ:

```py
import torch
from diffusers import AutoPipelineForImage2Image
from diffusers.utils import make_image_grid, load_image

pipeline = AutoPipelineForImage2Image.from_pretrained(
"runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# prepare image
url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png"
init_image = load_image(url)

prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"

# pass prompt and image to pipeline
image = pipeline(prompt, image=init_image, output_type="latent").images[0]
```

<Tip>
ูู ุงูููู ุชุญุฏูุฏ `output_type="latent"` ูู ุงูุฃูุจูุจ ููุญูุงุธ ุนูู ุฌููุน ุงููุฎุฑุฌุงุช ูู ุงููุณุงุญุฉ ุงููุฎููุฉ ูุชุฌูุจ ุฎุทูุฉ ุงูุชุฑููุฒ ูุงููู ุบูุฑ ุงูุถุฑูุฑูุฉ. ูุนูู ูุฐุง ููุท ุฅุฐุง ูุงูุช ุงูุฃูุงุจูุจ ุงููุฑุชุจุทุฉ ุชุณุชุฎุฏู ููุณ VAE.
</Tip>

ูุฑุฑ ุงูุฅุฎุฑุงุฌ ุงููุฎูู ูู ูุฐุง ุงูุฃูุจูุจ ุฅูู ุงูุฃูุจูุจ ุงูุชุงูู ูุชูููุฏ ุตูุฑุฉ ุนูู [ููุท ูุชุงุจ ูุฒูู](https://huggingface.co/ogkalu/Comic-Diffusion):

```py
pipeline = AutoPipelineForImage2Image.from_pretrained(
"ogkalu/Comic-Diffusion"ุ torch_dtype=torch.float16
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# ูุฌุจ ุชุถููู ุงูุฑูุฒ "charliebo artstyle" ูู ุงููุทุงูุจุฉ ูุงุณุชุฎุฏุงู ููุทุฉ ุงูุชูุชูุด ูุฐู
image = pipeline("Astronaut in a jungle, charliebo artstyle"ุ image=image, output_type="latent").images[0]
```

ูุฑุฑ ูุฑุฉ ุฃุฎุฑู ูุชูููุฏ ุงูุตูุฑุฉ ุงูููุงุฆูุฉ ุนูู [ููุท ูู ุงูุจูุณู](https://huggingface.co/kohbanye/pixel-art-style):

```py
pipeline = AutoPipelineForImage2Image.from_pretrained(
"kohbanye/pixel-art-style"ุ torch_dtype=torch.float16
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# ูุฌุจ ุชุถููู ุงูุฑูุฒ "pixelartstyle" ูู ุงููุทุงูุจุฉ ูุงุณุชุฎุฏุงู ููุทุฉ ุงูุชูุชูุด ูุฐู
image = pipeline("Astronaut in a jungle, pixelartstyle"ุ image=image).images[0]
make_image_grid([init_image, image], rows=1, cols=2)
```

### ุฃูุจูุจ ุงูุตูุฑ ุฅูู ุฃูุจูุจ ุชูุจูุฑ ุฅูู ุตูุฑุฉ ูุงุฆูุฉ ุงูุฏูุฉ
ููุงู ุทุฑููุฉ ุฃุฎุฑู ูุฑุจุท ุฃูุจูุจ ุงูุตูุฑ ุงูุฎุงุต ุจู ููู ุงุณุชุฎุฏุงู ุฃูุจูุจ ุชูุจูุฑ ูุตูุฑุฉ ูุงุฆูุฉ ุงูุฏูุฉ ูุฒูุงุฏุฉ ูุณุชูู ุงูุชูุงุตูู ูู ุงูุตูุฑุฉ ุญููุง.

ุงุจุฏุฃ ุจุฃูุจูุจ ุตูุฑุฉ ุฅูู ุตูุฑุฉ:

```py
import torch
from diffusers import AutoPipelineForImage2Image
from diffusers.utils import make_image_grid, load_image

pipeline = AutoPipelineForImage2Image.from_pretrained(
"runwayml/stable-diffusion-v1-5"ุ torch_dtype=torch.float16ุ variant="fp16"ุ use_safetensors=True
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# prepare image
url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png"
init_image = load_image(url)

prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"

# pass prompt and image to pipeline
image_1 = pipeline(prompt, image=init_image, output_type="latent").images[0]
```

<Tip>
ูู ุงูููู ุชุญุฏูุฏ `output_type="latent"` ูู ุงูุฃูุจูุจ ููุญูุงุธ ุนูู ุฌููุน ุงููุฎุฑุฌุงุช ูู ุงููุณุงุญุฉ ุงููุฎููุฉ ูุชุฌูุจ ุฎุทูุฉ ุงูุชุฑููุฒ ูุงููู ุบูุฑ ุงูุถุฑูุฑูุฉ. ูุนูู ูุฐุง ููุท ุฅุฐุง ูุงูุช ุงูุฃูุงุจูุจ ุงููุฑุชุจุทุฉ ุชุณุชุฎุฏู ููุณ VAE.
</Tip>

ูู ุจุชูุตููู ุจุฃูุจูุจ ุชูุจูุฑ ูุฒูุงุฏุฉ ุฏูุฉ ุงูุตูุฑุฉ:

```py
from diffusers import StableDiffusionLatentUpscalePipeline

upscaler = StableDiffusionLatentUpscalePipeline.from_pretrained(
"stabilityai/sd-x2-latent-upscaler"ุ torch_dtype=torch.float16ุ variant="fp16"ุ use_safetensors=True
)
upscaler.enable_model_cpu_offload()
upscaler.enable_xformers_memory_efficient_attention()

image_2 = upscaler(promptุ image=image_1ุ output_type="latent").images[0]
```

ุฃุฎูุฑูุงุ ูู ุจุชูุตููู ุจุฃูุจูุจ ูุงุฆู ุงูุฏูุฉ ูุฒูุงุฏุฉ ุชุญุณูู ุงูุฏูุฉ:

```py
from diffusers import StableDiffusionUpscalePipeline

super_res = StableDiffusionUpscalePipeline.from_pretrained(
"stabilityai/stable-diffusion-x4-upscaler"ุ torch_dtype=torch.float16ุ variant="fp16"ุ use_safetensors=True
)
super_res.enable_model_cpu_offload()
super_res.enable_xformers_memory_efficient_attention()

image_3 = super_res(promptุ image=image_2).images[0]
make_image_grid([init_image, image_3.resize((512, 512))], rows=1, cols=2)
```

## ุงูุชุญูู ูู ุฅูุดุงุก ุงูุตูุฑ
ูููู ุฃู ูููู ูุญุงููุฉ ุฅูุดุงุก ุตูุฑุฉ ุชุจุฏู ุจุงูุถุจุท ููุง ุชุฑูุฏ ุฃูุฑูุง ุตุนุจูุงุ ููุฐุง ูู ุงูุณุจุจ ูู ุฃู ุชูููุงุช ูููุงุฐุฌ ุงูุชุญูู ูู ุงูุชูููุฏ ูููุฏุฉ ุฌุฏูุง. ูู ุญูู ููููู ุงุณุชุฎุฏุงู `negative_prompt` ููุชุญูู ุฌุฒุฆููุง ูู ุฅูุดุงุก ุงูุตูุฑุ ููุงู ุทุฑู ุฃูุซุฑ ููุฉ ูุซู ูุฒู ุงููุทุงูุจุฉ ูุดุจูุงุช ุงูุชุญูู.

### ูุฒู ุงููุทุงูุจุฉ
ูุณูุญ ูุฒู ุงููุทุงูุจุฉ ุจุชุบููุฑ ุญุฌู ุชูุซูู ูู ููููู ูู ูุทุงูุจุฉ. ุนูู ุณุจูู ุงููุซุงูุ ูู ูุทุงูุจุฉ ูุซู "ุฑุงุฆุฏ ูุถุงุก ูู ุงูุบุงุจุฉุ ููุญุฉ ุฃููุงู ุจุงุฑุฏุฉุ ุฃููุงู ุฎุงูุชุฉุ ููุตูุฉุ 8k"ุ ููููู ุงุฎุชูุงุฑ ุฒูุงุฏุฉ ุฃู ุชูููู ุชุถููู "ุฑุงุฆุฏ ุงููุถุงุก" ู"ุงูุบุงุจุฉ". ุชููุฑ ููุชุจุฉ [Compel](https://github.com/damian0815/compel) ุจูุงุก ุฌููุฉ ุจุณูุทูุง ูุชุนุฏูู ุฃูุฒุงู ุงููุทุงูุจุฉ ูุฅูุดุงุก ุงูุชุถูููุงุช. ููููู ูุนุฑูุฉ ููููุฉ ุฅูุดุงุก ุงูุชุถูููุงุช ูู ุฏููู [ูุฒู ุงููุทุงูุจุฉ](weighted_prompts).

ูุฏู [`AutoPipelineForImage2Image`] ูุนููุฉ `prompt_embeds` (ู`negative_prompt_embeds` ุฅุฐุง ููุช ุชุณุชุฎุฏู ูุทุงูุจุฉ ุณูุจูุฉ) ุญูุซ ููููู ุชูุฑูุฑ ุงูุชุถูููุงุช ุงูุชู ุชุญู ูุญู ูุนููุฉ `prompt`.

```py
from diffusers import AutoPipelineForImage2Image
import torch

pipeline = AutoPipelineForImage2Image.from_pretrained(
"runwayml/stable-diffusion-v1-5"ุ torch_dtype=torch.float16ุ variant="fp16"ุ use_safetensors=True
)
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

image = pipeline(prompt_embeds=prompt_embedsุ # ุชู ุฅูุดุงุคู ูู Compel
negative_prompt_embeds=negative_prompt_embedsุ # ุชู ุฅูุดุงุคู ูู Compel
image=init_imageุ
).images[0]
```
### ControlNet

ุชููุฑ ControlNets ุทุฑููุฉ ุฃูุซุฑ ูุฑููุฉ ูุฏูุฉ ููุชุญูู ูู ุชูููุฏ ุงูุตูุฑ ูุฃูู ูููู ุฃู ุชุณุชุฎุฏู ุตูุฑุฉ ุดุฑุทูุฉ ุฅุถุงููุฉ. ูููู ุฃู ุชููู ุงูุตูุฑุฉ ุงูุดุฑุทูุฉ ุตูุฑุฉ Canny ุฃู ุฎุฑูุทุฉ ุนูู ุฃู ุชุฌุฒุฆุฉ ุตูุฑุฉุ ูุญุชู ุงูุฎุฑุจุดุงุช! ุฃููุง ูุงู ููุน ุงูุตูุฑุฉ ุงูุดุฑุทูุฉ ุงูุชู ุชุฎุชุงุฑูุงุ ูููู ControlNet ุจุชูููุฏ ุตูุฑุฉ ุชุญุงูุธ ุนูู ุงููุนูููุงุช ุงูููุฌูุฏุฉ ูููุง.

ุนูู ุณุจูู ุงููุซุงูุ ุฏุนููุง ูุดุชุฑุท ุตูุฑุฉ ุจุงุณุชุฎุฏุงู ุฎุฑูุทุฉ ุนูู ููุญูุงุธ ุนูู ุงููุนูููุงุช ุงูููุงููุฉ ูู ุงูุตูุฑุฉ.

```py
from diffusers.utils import load_image, make_image_grid

# prepare image
url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png"
init_image = load_image(url)
init_image = init_image.resize((958, 960)) # ุชุบููุฑ ุญุฌู ุงูุตูุฑุฉ ุฅูู ุฃุจุนุงุฏ ุตูุฑุฉ ุงูุนูู
depth_image = load_image("https://huggingface.co/lllyasviel/control_v11f1p_sd15_depth/resolve/main/images/control.png")
make_image_grid([init_image, depth_image], rows=1, cols=2)
```

ูู ุจุชุญููู ูููุฐุฌ ControlNet ุงููุดุฑูุท ุจุฎุฑุงุฆุท ุงูุนูู ู [`AutoPipelineForImage2Image`]:

```py
from diffusers import ControlNetModel, AutoPipelineForImage2Image
import torch

controlnet = ControlNetModel.from_pretrained("lllyasviel/control_v11f1p_sd15_depth", torch_dtype=torch.float16, variant="fp16", use_safetensors=True)
pipeline = AutoPipelineForImage2Image.from_pretrained(
"runwayml/stable-diffusion-v1-5", controlnet=controlnet, torch_dtype=torch.float16, variant="fp16", use_safetensors=True
)
pipeline.enable_model_cpu_offload()
# ุงุญุฐู ุงูุณุทุฑ ุงูุชุงูู ุฅุฐุง ูู ููู xFormers ูุซุจุชูุง ุฃู ุฅุฐุง ูุงู ูุฏูู PyTorch 2.0 ุฃู ุฃุนูู ูุซุจุชูุง
pipeline.enable_xformers_memory_efficient_attention()
```

ุงูุขู ูู ุจุชูููุฏ ุตูุฑุฉ ุฌุฏูุฏุฉ ูุดุฑูุทุฉ ุจุฎุฑูุทุฉ ุงูุนูู ูุงูุตูุฑุฉ ุงูุฃูููุฉ ูุงููุต ุงููุนูู:

```py
prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"
image_control_net = pipeline(prompt, image=init_image, control_image=depth_image).images[0]
make_image_grid([init_image, depth_image, image_control_net], rows=1, cols=3)
```

<div class="flex flex-row gap-4">
<div class="flex-1">
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png"/>
<figcaption class="mt-2 text-center text-sm text-gray-500">ุงูุตูุฑุฉ ุงูุฃูููุฉ</figcaption>
</div>
<div class="flex-1">
<img class="rounded-xl" src="https://huggingface.co/lllyasviel/control_v11f1p_sd15_depth/resolve/main/images/control.png"/>
<figcaption class="mt-2 text-center text-sm text-gray-500">ุตูุฑุฉ ุงูุนูู</figcaption>
</div>
<div class="flex-1">
<img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-controlnet.png"/>
<figcaption class="mt-2 text-center text-sm text-gray-500">ุตูุฑุฉ ControlNet</figcaption>
</div>
</div>

ุฏุนููุง ูุทุจู [ููุทูุง](https://huggingface.co/nitrosocke/elden-ring-diffusion) ุฌุฏูุฏูุง ุนูู ุงูุตูุฑุฉ ุงูุชู ุชู ุฅูุดุงุคูุง ูู ControlNet ุนู ุทุฑูู ุฑุจุทูุง ุจุฎุท ุฃูุงุจูุจ ูู ุงูุตูุฑุฉ ุฅูู ุงูุตูุฑุฉ:

```py
pipeline = AutoPipelineForImage2Image.from_pretrained(
"nitrosocke/elden-ring-diffusion", torch_dtype=torch.float16,
)
pipeline.enable_model_cpu_offload()
# ุงุญุฐู ุงูุณุทุฑ ุงูุชุงูู ุฅุฐุง ูู ููู xFormers ูุซุจุชูุง ุฃู ุฅุฐุง ูุงู ูุฏูู PyTorch 2.0 ุฃู ุฃุนูู ูุซุจุชูุง
pipeline.enable_xformers_memory_efficient_attention()

prompt = "elden ring style astronaut in a jungle" # ุชุถููู ุงูุฑูุฒ ุงููููุฒ "elden ring style" ูู ุงููุต ุงููุนูู
negative_prompt = "ugly, deformed, disfigured, poor details, bad anatomy"

image_elden_ring = pipeline(prompt, negative_prompt=negative_prompt, image=image_control_net, strength=0.45, guidance_scale=10.5).images[0]
make_image_grid([init_image, depth_image, image_control_net, image_elden_ring], rows=2, cols=2)
```

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-elden-ring.png">
</div>

## ุชุญุณูู

ุฅู ุชุดุบูู ููุงุฐุฌ ุงูุงูุชุดุงุฑ ุจุงูุธ ุงูุชูููุฉ ููุซูู ุงูุงุณุชุฎุฏุงู ููุญูุณุจุฉุ ูููู ุจุงุณุชุฎุฏุงู ุจุนุถ ุงูุญูู ุงูุชุญุณูููุฉุ ูู ุงููููู ุชูุงููุง ุชุดุบูููุง ุนูู ูุนุงูุฌุงุช ุงูุฑุณููุงุช GPU ูููุณุชููููู ูุงูุทุจูุฉ ุงููุฌุงููุฉ. ุนูู ุณุจูู ุงููุซุงูุ ููููู ุงุณุชุฎุฏุงู ุดูู ุฃูุซุฑ ููุงุกุฉ ูู ุญูุซ ุงูุฐุงูุฑุฉ ููุงูุชูุงู ูุซู [ุงูุชูุงู ุงูููุชุฌ ุงูููุทู ุงููููููุฒ](../optimization/torch2.0#scaled-dot-product-attention) ูู PyTorch 2.0 ุฃู [xFormers](../optimization/xformers) (ููููู ุงุณุชุฎุฏุงู ุฃุญุฏููุงุ ูููู ูุง ุชูุฌุฏ ุญุงุฌุฉ ูุงุณุชุฎุฏุงู ูููููุง). ููููู ุฃูุถูุง ููู ุงููููุฐุฌ ุฅูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช GPU ุฃุซูุงุก ุงูุชุธุงุฑ ููููุงุช ุฎุท ุงูุฃูุงุจูุจ ุงูุฃุฎุฑู ุนูู ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ CPU.

```diff
+ pipeline.enable_model_cpu_offload()
+ pipeline.enable_xformers_memory_efficient_attention()
```

ูุน [`torch.compile`](../optimization/torch2.0#torchcompile)ุ ููููู ุฒูุงุฏุฉ ุณุฑุนุฉ ุงูุงุณุชุฏูุงู ูุฏูู ุนู ุทุฑูู ูู UNet ุงูุฎุงุต ุจู ุจู:

```py
pipeline.unet = torch.compile(pipeline.unet, mode="reduce-overhead", fullgraph=True)
```

ููุนุฑูุฉ ุงููุฒูุฏุ ุงุทูุน ุนูู ุฃุฏูุฉ [ุชูููู ุงุณุชุฎุฏุงู ุงูุฐุงูุฑุฉ](../optimization/memory) ู [Torch 2.0](../optimization/torch2.0).