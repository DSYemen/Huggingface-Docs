# الأجهزة المخصصة للتدريب

يمكن للأجهزة التي تستخدمها لتشغيل تدريب النماذج والاستدلال أن يكون لها تأثير كبير على الأداء. للحصول على نظرة متعمقة حول وحدات معالجة الرسومات GPU، تأكد من الاطلاع على منشور المدونة الممتاز الخاص بـ Tim Dettmer [هنا](https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/).

دعونا نلقي نظرة على بعض النصائح العملية لإعدادات GPU.

## وحدة معالجة الرسومات GPU

عند تدريب نماذج أكبر، لديك ثلاثة خيارات أساسية:

- وحدات معالجة رسومات GPU أكبر
- المزيد من وحدات معالجة الرسومات GPUs
- المزيد من وحدة المعالجة المركزية CPU و NVMe (يتم تفريغها بواسطة [DeepSpeed-Infinity](main_classes/deepspeed#nvme-support))

دعونا نبدأ بالحالة التي لديك فيها وحدة معالجة رسومات GPU واحدة.

### الطاقة والتبريد

إذا اشتريت وحدة معالجة رسومات GPU عالية الجودة باهظة الثمن، فتأكد من تزويدها بالطاقة الصحيحة والتبريد الكافي.

**الطاقة**:

تحتوي بعض بطاقات وحدات معالجة الرسومات GPU عالية الجودة الموجهة للمستهلكين على مقبس أو مقبسين PCI-E 8-Pin، وفي بعض الأحيان 3. تأكد من توصيل أكبر عدد ممكن من كابلات PCI-E 8-Pin المستقلة في البطاقة كما هو الحال في المقبس. لا تستخدم الانقسامين الموجودين في نهاية الكابل نفسه (المعروف أيضًا باسم كابل pigtail). وهذا يعني أنه إذا كان لديك مقبسان على وحدة معالجة الرسومات GPU، فأنت تريد كابلين PCI-E 8-Pin للانتقال من وحدة الإمداد بالطاقة PSU إلى البطاقة وليس واحدًا يحتوي على موصلين PCI-E 8-Pin في النهاية! لن تحصل على الأداء الكامل من بطاقتك بخلاف ذلك.

يجب توصيل كل كابل طاقة PCI-E 8-Pin بمسار 12V على جانب وحدة الإمداد بالطاقة PSU ويمكنه توفير ما يصل إلى 150 واط من الطاقة.

قد تستخدم بعض البطاقات الأخرى موصلات PCI-E 12-Pin، ويمكن أن توفر هذه الموصلات ما يصل إلى 500-600 واط من الطاقة.

قد تستخدم البطاقات منخفضة الجودة موصلات 6-Pin، والتي توفر ما يصل إلى 75 واط من الطاقة.

بالإضافة إلى ذلك، تريد وحدة إمداد الطاقة PSU عالية الجودة التي لديها جهد مستقر. قد لا توفر بعض الوحدات منخفضة الجودة البطاقة بالجهد المستقر الذي تحتاجه للعمل في ذروتها.

وبالطبع، يجب أن تحتوي وحدة الإمداد بالطاقة PSU على عدد كافٍ من الواط غير المستخدم لتزويد البطاقة بالطاقة.

**التبريد**:

عندما ترتفع درجة حرارة وحدة معالجة الرسومات GPU، فسوف تبدأ في تقليل سرعتها ولن تقدم أداءً كاملاً، بل وقد تتوقف عن العمل إذا ارتفعت درجة حرارتها بشدة.

من الصعب تحديد درجة الحرارة المثلى التي يجب السعي لتحقيقها عندما تكون وحدة معالجة الرسومات GPU مثقلة بالعمل، ولكن ربما يكون أي شيء أقل من 80 درجة مئوية جيدًا، ولكن كلما انخفضت درجة الحرارة كان ذلك أفضل - ربما يكون النطاق من 70 إلى 75 درجة مئوية ممتازًا. ومن المرجح أن يبدأ خفض السرعة عند حوالي 84-90 درجة مئوية. ولكن بالإضافة إلى خفض الأداء، فإن ارتفاع درجة الحرارة لفترة طويلة من المحتمل أن يقلل من عمر وحدة معالجة الرسومات GPU.

بعد ذلك، دعونا نلقي نظرة على أحد أهم الجوانب عند وجود وحدات معالجة رسومات GPU متعددة: الاتصال.

### اتصال وحدات معالجة الرسومات GPU المتعددة

إذا كنت تستخدم وحدات معالجة رسومات GPU متعددة، فيمكن لطريقة اتصال البطاقات أن يكون لها تأثير كبير على إجمالي وقت التدريب. إذا كانت وحدات معالجة الرسومات GPUs موجودة على نفس العقدة المادية، فيمكنك تشغيل ما يلي:

```bash
nvidia-smi topo -m
```

وسيخبرك ذلك بكيفية اتصال وحدات معالجة الرسومات GPUs. على جهاز به وحدتا معالجة رسومات GPU متصلتان بـ NVLink، فمن المحتمل أن ترى شيئًا مثل:

```
GPU0    GPU1    CPU Affinity    NUMA Affinity
GPU0     X      NV2     0-23            N/A
GPU1    NV2      X      0-23            N/A
```

على جهاز مختلف بدون NVLink، قد نرى:

```
GPU0    GPU1    CPU Affinity    NUMA Affinity
GPU0     X      PHB     0-11            N/A
GPU1    PHB      X      0-11            N/A
```

يشمل التقرير هذا الشرح:

```
X    = Self
SYS  = Connection traversing PCIe as well as the SMP interconnect between NUMA nodes (e.g., QPI/UPI)
NODE = Connection traversing PCIe as well as the interconnect between PCIe Host Bridges within a NUMA node
PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)
PXB  = Connection traversing multiple PCIe bridges (without traversing the PCIe Host Bridge)
PIX  = Connection traversing at most a single PCIe bridge
NV#  = Connection traversing a bonded set of # NVLinks
```

لذا فإن التقرير الأول `NV2` يخبرنا بأن وحدات معالجة الرسومات GPUs متصلة بواسطة رابطين NVLink، والتقرير الثاني `PHB` لدينا إعداد PCIe+Bridge نموذجي للمستهلك.

تحقق من نوع الاتصال الذي لديك في إعدادك. سيجعل بعضها الاتصال بين البطاقات أسرع (مثل NVLink)، والبعض الآخر أبطأ (مثل PHB).

اعتمادًا على نوع حل قابلية التوسع المستخدم، قد يكون لسرعة الاتصال تأثير كبير أو صغير. إذا كان يلزم مزامنة وحدات معالجة الرسومات GPUs نادرًا، كما هو الحال في DDP، فإن تأثير الاتصال البطيء سيكون أقل أهمية. إذا كان يلزم أن ترسل وحدات معالجة الرسومات GPUs الرسائل إلى بعضها البعض بشكل متكرر، كما هو الحال في ZeRO-DP، فإن اتصال أسرع يصبح بالغ الأهمية لتحقيق تدريب أسرع.

#### NVlink

[NVLink](https://en.wikipedia.org/wiki/NVLink) هو رابط اتصالات متعدد المسارات قريب المدى متسلسل قائم على الأسلاك طورته شركة Nvidia.

يوفر كل جيل جديد عرض نطاق ترددي أسرع، على سبيل المثال، إليك اقتباس من [بنية معالج الرسومات GPU Ampere GA102 من Nvidia](https://www.nvidia.com/content/dam/en-zz/Solutions/geforce/ampere/pdf/NVIDIA-ampere-GA102-GPU-Architecture-Whitepaper-V1.pdf):

> NVLink® من الجيل الثالث
> تستخدم معالجات GA102 من NVIDIA واجهة NVLink من الجيل الثالث، والتي تتضمن روابط x4 أربعة،
> يوفر كل رابط 14.0625 جيجابايت/ثانية من عرض النطاق الترددي في كل اتجاه بين وحدتي معالجة رسومات GPU. توفر أربعة
> روابط 56.25 جيجابايت/ثانية من عرض النطاق الترددي في كل اتجاه، و112.5 جيجابايت/ثانية من إجمالي عرض النطاق الترددي
> بين وحدتي معالجة رسومات GPU. يمكن توصيل وحدتي معالجة الرسومات GPU من RTX 3090 معًا لتشغيل SLI باستخدام NVLink.
> (ملاحظة: لا يتم دعم تكوينات SLI ثلاثية الاتجاهات ورباعية الاتجاهات.)

لذا، كلما زادت قيمة `X` التي تحصل عليها في تقرير `NVX` في إخراج `nvidia-smi topo -m`، كان ذلك أفضل. سيعتمد الجيل على بنية وحدة معالجة الرسومات GPU الخاصة بك.

دعونا نقارن تنفيذ نموذج اللغة openai-community/gpt2 للتدريب على عينة صغيرة من wikitext.

النتائج هي:

| NVlink | الوقت |
| -----  | ---: |
| نعم      | 101s |
| لا      | 131s |

يمكنك أن ترى أن NVLink يكمل التدريب بنسبة 23% تقريبًا. في المعيار الثاني، نستخدم `NCCL_P2P_DISABLE=1` لإخبار وحدات معالجة الرسومات GPUs بعدم استخدام NVLink.

هنا كود المعيار الكامل والنواتج:

```bash
# DDP w/ NVLink

rm -r /tmp/test-clm; CUDA_VISIBLE_DEVICES=0,1 torchrun \
--nproc_per_node 2 examples/pytorch/language-modeling/run_clm.py --model_name_or_path openai-community/gpt2 \
--dataset_name wikitext --dataset_config_name wikitext-2-raw-v1 --do_train \
--output_dir /tmp/test-clm --per_device_train_batch_size 4 --max_steps 200

{'train_runtime': 101.9003, 'train_samples_per_second': 1.963, 'epoch': 0.69}

# DDP w/o NVLink

rm -r /tmp/test-clm; CUDA_VISIBLE_DEVICES=0,1 NCCL_P2P_DISABLE=1 torchrun \
--nproc_per_node 2 examples/pytorch/language-modeling/run_clm.py --model_name_or_path openai-community/gpt2 \
--dataset_name wikitext --dataset_config_name wikitext-2-raw-v1 --do_train
--output_dir /tmp/test-clm --per_device_train_batch_size 4 --max_steps 200

{'train_runtime': 131.4367, 'train_samples_per_second': 1.522, 'epoch': 0.69}
```

الأجهزة: 2x TITAN RTX 24 جيجابايت لكل منهما + NVlink مع رابطين NVLink (`NV2` في `nvidia-smi topo -m`)

البرمجيات: `pytorch-1.8-to-be` + `cuda-11.0` / `transformers==4.3.0.dev0`