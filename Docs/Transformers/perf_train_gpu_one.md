## ุฃุณุงููุจ ูุฃุฏูุงุช ููุชุฏุฑูุจ ุงููุนุงู ุนูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU) ุงููุฑุฏูุฉ

ููุธูุฑ ูุฐุง ุงูุฏููู ุงูุชูููุงุช ุงูุนูููุฉ ุงูุชู ููููู ุงุณุชุฎุฏุงููุง ูุฒูุงุฏุฉ ููุงุกุฉ ุชุฏุฑูุจ ูููุฐุฌู ูู ุฎูุงู ุชุญุณูู ุงุณุชุฎุฏุงู ุงูุฐุงูุฑุฉุ ุฃู ุชุณุฑูุน ุงูุชุฏุฑูุจุ ุฃู ูููููุง. ุฅุฐุง ููุช ุชุฑุบุจ ูู ููู ููููุฉ ุงุณุชุฎุฏุงู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช ุฃุซูุงุก ุงูุชุฏุฑูุจุ ููุฑุฌู ุงูุฑุฌูุน ุฃููุงู ุฅูู ุงูุฏููู ุงูููุงูููู [ุชุดุฑูุญ ุชุฏุฑูุจ ุงููููุฐุฌ](model_memory_anatomy). ูุฑูุฒ ูุฐุง ุงูุฏููู ุนูู ุงูุชูููุงุช ุงูุนูููุฉ.

ุนูุฏ ุชุฏุฑูุจ ุงูููุงุฐุฌ ุงููุจูุฑุฉุ ููุงู ุฌุงูุจุงู ูุฌุจ ูุฑุงุนุงุชููุง ูู ููุณ ุงูููุช:

- *ูุนุฏู ููู ุงูุจูุงูุงุช/ููุช ุงูุชุฏุฑูุจ*: ูุคุฏู ุชุญููู ุฃูุตู ูุนุฏู ููู (ุนููุงุช/ุซุงููุฉ) ุฅูู ุฎูุถ ุชูููุฉ ุงูุชุฏุฑูุจ. ููุชู ุชุญููู ุฐูู ุจุดูู ุนุงู ูู ุฎูุงู ุงูุงุณุชูุงุฏุฉ ูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช ูุฏุฑ ุงูุฅููุงูุ ูุจุงูุชุงูู ููุก ุฐุงูุฑุฉ ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช ุฅูู ุญุฏููุง ุงูุฃูุตู. ุฅุฐุง ุชุฌุงูุฒ ุญุฌู ุงูุฏููุนุฉ ุงููุทููุจ ุญุฏูุฏ ุฐุงูุฑุฉ ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุชุ ููููู ูุชูููุงุช ุชุญุณูู ุงูุฐุงูุฑุฉุ ูุซู ุชุฑุงูู ุงูุชุฏุฑุฌุงุชุ ุฃู ุชุณุงุนุฏ ูู ุฐูู.

- *ุฃุฏุงุก ุงููููุฐุฌ*: ููุน ุฐููุ ุฅุฐุง ูุงู ุญุฌู ุงูุฏูุนุฉ ุงูููุถู ููุงุณุจ ุงูุฐุงูุฑุฉุ ููุง ููุฌุฏ ุณุจุจ ูุชุทุจูู ุชูููุงุช ุชุญุณูู ุงูุฐุงูุฑุฉ ูุฃููุง ูููู ุฃู ุชุจุทุฆ ุงูุชุฏุฑูุจ. ููุฌุฑุฏ ุฃู ุงููุฑุก ููููู ุงุณุชุฎุฏุงู ุญุฌู ุฏูุนุฉ ูุจูุฑุ ูุง ูุนูู ุจุงูุถุฑูุฑุฉ ุฃูู ููุจุบู ุนููู ุฐูู. ูุฌุฒุก ูู ุถุจุท ุงููุนููุงุชุ ูุฌุจ ุนููู ุชุญุฏูุฏ ุญุฌู ุงูุฏูุนุฉ ุงูุฐู ูุญูู ุฃูุถู ุงููุชุงุฆุฌุ ุซู ุชุญุณูู ุงูููุงุฑุฏ ููููุง ูุฐูู.

ูููู ุชุตููู ุงูุฃุณุงููุจ ูุงูุฃุฏูุงุช ุงููุดูููุฉ ูู ูุฐุง ุงูุฏููู ุจูุงุกู ุนูู ุงูุชุฃุซูุฑ ุงูุฐู ุชุญุฏุซู ุนูู ุนูููุฉ ุงูุชุฏุฑูุจ:

| ุงูุฃุณููุจ/ุงูุฃุฏุงุฉ | ุชุญุณูู ุณุฑุนุฉ ุงูุชุฏุฑูุจ | ุชุญุณูู ุงุณุชุฎุฏุงู ุงูุฐุงูุฑุฉ |
| :--------------------------- | :------------------------ | :----------------------------- |
| [ุงุฎุชูุงุฑ ุญุฌู ุงูุฏูุนุฉ](#batch-size-choice) | ูุนู | ูุนู |
| [ุชุฑุงูู ุงูุชุฏุฑุฌุงุช](#gradient-accumulation) | ูุง | ูุนู |
| [ุงูุชุฏููู ุงูุชุฏุฑูุฌู](#gradient-checkpointing) | ูุง | ูุนู |
| [ุชุฏุฑูุจ ุงูุฏูุฉ ุงููุฎุชูุทุฉ](#mixed-precision-training) | ูุนู | (ูุง) |
| [ุงุฎุชูุงุฑ ุงููุญุณู](#optimizer-choice) | ูุนู | ูุนู |
| [ุงูุชุญููู ุงููุณุจู ููุจูุงูุงุช](#data-preloading) | ูุนู | ูุง |
| [DeepSpeed Zero](#deepspeed-zero) | ูุง | ูุนู |
| [torch.compile](#using-torchcompile) | ูุนู | ูุง |
| [ุถุจุท ุฏููู ูุนุงู ูููุนููุงุช (PEFT)](#using--peft) | ูุง | ูุนู |

ููููู ุงูุฌูุน ุจูู ุงูุฃุณุงููุจ ุงููุฐููุฑุฉ ุฃุนูุงู ููุญุตูู ุนูู ุชุฃุซูุฑ ุชุฑุงููู. ุชุชููุฑ ูุฐู ุงูุชูููุงุช ุณูุงุก ููุช ุชุฏุฑุจ ูููุฐุฌู ุจุงุณุชุฎุฏุงู [`Trainer`] ุฃู ุชูุชุจ ุญููุฉ PyTorch ูููุฉุ ููู ูุฐู ุงูุญุงูุฉ ููููู [ุชูููู ูุฐู ุงูุชุญุณููุงุช ุจุงุณุชุฎุฏุงู ๐ค Accelerate](#using--accelerate).

ุฅุฐุง ูู ุชุคุฏ ูุฐู ุงูุฃุณุงููุจ ุฅูู ููุงุณุจ ูุงููุฉุ ูููููู ุงุณุชูุดุงู ุงูุฎูุงุฑุงุช ุงูุชุงููุฉ:

- [ุงูุงุทูุงุน ุนูู ุจูุงุก ุญุงููุฉ Docker ูุฎุตุตุฉ ุฎุงุตุฉ ุจู ูุน ุจุฑุงูุฌ ุงูุจูุงุก ุงููุนุงูุฉ ูุณุจููุง](#efficient-software-prebuilds)
- [ุงููุธุฑ ูู ูููุฐุฌ ูุณุชุฎุฏู ูุฒูุฌูุง ูู ุงูุฎุจุฑุงุก (MoE)](#mixture-of-experts)
- [ุชุญููู ูููุฐุฌู ุฅูู BetterTransformer ููุงุณุชูุงุฏุฉ ูู ุงูุงูุชูุงู ุงูุฃุตูู ูู PyTorch](#using-pytorch-native-attention-and-flash-attention)

ุฃุฎูุฑูุงุ ุฅุฐุง ูู ููู ูู ูุง ุณุจู ูุงูููุงุ ุญุชู ุจุนุฏ ุงูุชุจุฏูู ุฅูู ูุญุฏุฉ ูุนุงูุฌุฉ ุฑุณูููุงุช ูู ูุฆุฉ ุงูุฎูุงุฏู ูุซู A100ุ ูููุฑ ูู ุงูุงูุชูุงู ุฅูู ุฅุนุฏุงุฏ ูุชุนุฏุฏ ูุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณูููุงุช. ูุง ุชุฒุงู ุฌููุน ูุฐู ุงูุฃุณุงููุจ ุตุงูุญุฉ ูู ุฅุนุฏุงุฏ ูุชุนุฏุฏ ูุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณูููุงุชุ ุจุงูุฅุถุงูุฉ ุฅูู ุฐููุ ููููู ุงูุงุณุชูุงุฏุฉ ูู ุชูููุงุช ุงูุชูุงุฒู ุงูุฅุถุงููุฉ ุงูููุถุญุฉ ูู ูุณู [ูุชุนุฏุฏ ูุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณูููุงุช](perf_train_gpu_many).

## ุงุฎุชูุงุฑ ุญุฌู ุงูุฏูุนุฉ

ูุชุญููู ุงูุฃุฏุงุก ุงูุฃูุซูุ ุงุจุฏุฃ ุจุชุญุฏูุฏ ุญุฌู ุงูุฏูุนุฉ ุงูููุงุณุจ. ูููุตุญ ุจุงุณุชุฎุฏุงู ุฃุญุฌุงู ุฏูุนุงุช ูุฃุนุฏุงุฏ ุงูุนุตุจููุงุช ููุฅุฏุฎุงู/ุงูุฅุฎุฑุงุฌ ุงูุชู ุชููู ูู ุญุฌู 2^N. ุบุงูุจูุง ูุง ูููู ูุฐุง ุงูุนุฏุฏ ูุถุงุนููุง ูู 8ุ ููููู ูููู ุฃู ูููู ุฃุนูู ุงุนุชูุงุฏูุง ุนูู ุงูุฃุฌูุฒุฉ ุงููุณุชุฎุฏูุฉ ูููุน ุจูุงูุงุช ุงููููุฐุฌ.

ููุงุทูุงุน ุนูู ุฐููุ ุฑุงุฌุน ุชูุตูุฉ NVIDIA ุงูุฎุงุตุฉ ุจู [ุฃุนุฏุงุฏ ุงูุนุตุจููุงุช ููุฅุฏุฎุงู/ุงูุฅุฎุฑุงุฌ](https://docs.nvidia.com/deeplearning/performance/dl-performance-fully-connected/index.html#input-features) ู[ุญุฌู ุงูุฏูุนุฉ](https://docs.nvidia.com/deeplearning/performance/dl-performance-fully-connected/index.html#batch-size) ููุทุจูุงุช ุงููุชุตูุฉ ุจุงููุงูู (ุงูุชู ุชุดุงุฑู ูู ุนูููุงุช ุงูุถุฑุจ ุงููุตูููู ุงูุนุงู).

ุชุญุฏุฏ [ูุชุทูุจุงุช Tensor Core](https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc) ุงููุถุงุนู ุจูุงุกู ุนูู ููุน ุจูุงูุงุช ุงูุฃุฌูุฒุฉ ูุงูุฃุฌูุฒุฉ. ุนูู ุณุจูู ุงููุซุงูุ ุจุงููุณุจุฉ ูููุน ุจูุงูุงุช fp16ุ ููุตู ุจุงุณุชุฎุฏุงู ูุถุงุนู 8ุ ูุง ูู ุชูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช ูู ููุน A100ุ ููู ูุฐู ุงูุญุงูุฉ ุงุณุชุฎุฏู ูุถุงุนูุงุช 64.

ุจุงููุณุจุฉ ูููุนููุงุช ุงูุตุบูุฑุฉุ ุถุน ูู ุงุนุชุจุงุฑู ุฃูุถูุง [ุชุฃุซูุฑุงุช ุงูุชูููู ุงูุจุนุฏู](https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#dim-quantization). ููุง ูุญุฏุซ ุงูุชุจููุท ููููู ุฃู ูุคุฏู ุงููุถุงุนู ุงูุตุญูุญ ุฅูู ุชุณุฑูุน ูุจูุฑ.

## ุชุฑุงูู ุงูุชุฏุฑุฌุงุช

ููุฏู ุฃุณููุจ **ุชุฑุงูู ุงูุชุฏุฑุฌุงุช** ุฅูู ุญุณุงุจ ุงูุชุฏุฑุฌุงุช ุนูู ุฏูุนุงุช ุฃุตุบุฑ ุจุฏูุงู ูู ุญุณุงุจูุง ููุฏูุนุฉ ุจุฃููููุง ูุฑุฉ ูุงุญุฏุฉ. ููุทูู ูุฐุง ุงูููุฌ ุนูู ุญุณุงุจ ุงูุชุฏุฑุฌุงุช ุจุดูู ุชูุฑุงุฑู ุนูู ุฏูุนุงุช ุฃุตุบุฑ ูู ุฎูุงู ุชูููุฐ ุนูููุงุช ุชูุฑูุฑ ููุฃูุงู ูุงูุฎูู ุนุจุฑ ุงููููุฐุฌ ูุชุฑุงูู ุงูุชุฏุฑุฌุงุช ุฃุซูุงุก ูุฐู ุงูุนูููุฉ. ุจูุฌุฑุฏ ุชุฑุงูู ุนุฏุฏ ูุงูู ูู ุงูุชุฏุฑุฌุงุชุ ูุชู ุชูููุฐ ุฎุทูุฉ ุงูุชุญุณูู ุงูุฎุงุตุฉ ุจุงููููุฐุฌ. ูู ุฎูุงู ุงุณุชุฎุฏุงู ุชุฑุงูู ุงูุชุฏุฑุฌุงุชุ ูุตุจุญ ูู ุงููููู ุฒูุงุฏุฉ **ุญุฌู ุงูุฏูุนุฉ ุงููุนุงู** ุฅูู ูุง ุจุนุฏ ุงููููุฏ ุงูุชู ุชูุฑุถูุง ุณุนุฉ ุฐุงูุฑุฉ ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช. ููุน ุฐููุ ูู ุงูููู ููุงุญุธุฉ ุฃู ุนูููุงุช ุงูุชูุฑูุฑ ุงูุฅุถุงููุฉ ููุฃูุงู ูุงูุฎูู ุงูุชู ูุฏููุง ุชุฑุงูู ุงูุชุฏุฑุฌุงุช ูููู ุฃู ุชุจุทุฆ ุนูููุฉ ุงูุชุฏุฑูุจ.

ููููู ุชูููู ุชุฑุงูู ุงูุชุฏุฑุฌุงุช ุนู ุทุฑูู ุฅุถุงูุฉ ุญุฌุฉ `gradient_accumulation_steps` ุฅูู [`TrainingArguments`]:

```ุจุงูุซูู
training_args = TrainingArguments(per_device_train_batch_size=1, gradient_accumulation_steps=4, **default_args)
```

ูู ุงููุซุงู ุฃุนูุงูุ ูุตุจุญ ุญุฌู ุงูุฏูุนุฉ ุงููุนุงู ูุฏูู 4.

ุฃูุ ุงุณุชุฎุฏู ๐ค Accelerate ููุชุญูู ุงููุงูู ูู ุญููุฉ ุงูุชุฏุฑูุจ. ููููู ุงูุนุซูุฑ ุนูู ูุซุงู ๐ค Accelerate [ุฃุฏูุงู ูู ูุฐุง ุงูุฏููู](#using--accelerate).

ูู ุญูู ูููุตุญ ุจุฒูุงุฏุฉ ุงุณุชุฎุฏุงู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช ุฅูู ุงูุญุฏ ุงูุฃูุตู ูุฏุฑ ุงูุฅููุงูุ ูููู ุฃู ูุคุฏู ุงูุนุฏุฏ ุงููุจูุฑ ูู ุฎุทูุงุช ุชุฑุงูู ุงูุชุฏุฑุฌุงุช ุฅูู ุชุจุงุทุค ุชุฏุฑูุจ ุฃูุซุฑ ูุถูุญูุง. ุถุน ูู ุงุนุชุจุงุฑู ุงููุซุงู ุงูุชุงูู. ูููุชุฑุถ ุฃู `per_device_train_batch_size=4` ุจุฏูู ุชุฑุงูู ุงูุชุฏุฑุฌุงุช ูุตู ุฅูู ุญุฏ ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช. ุฅุฐุง ููุช ุชุฑุบุจ ูู ุงูุชุฏุฑูุจ ุจุงุณุชุฎุฏุงู ุฏูุนุงุช ูู ุญุฌู 64ุ ููุง ุชูู ุจุชุนููู `per_device_train_batch_size` ุฅูู 1 ู`gradient_accumulation_steps` ุฅูู 64. ุจุฏูุงู ูู ุฐููุ ุงุญุชูุธ ุจู `per_device_train_batch_size=4` ููู ุจุชุนููู `gradient_accumulation_steps=16`. ูุคุฏู ูุฐุง ุฅูู ููุณ ุญุฌู ุงูุฏูุนุฉ ุงููุนุงู ูุน ุงูุงุณุชูุงุฏุฉ ุจุดูู ุฃูุถู ูู ููุงุฑุฏ ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช ุงููุชุงุญุฉ.

ููุญุตูู ุนูู ูุนูููุงุช ุฅุถุงููุฉุ ููุฑุฌู ุงูุฑุฌูุน ุฅูู ูุนุงููุฑ ุญุฌู ุงูุฏูุนุฉ ูุชุฑุงูู ุงูุชุฏุฑุฌุงุช ูู [RTX-3090](https://github.com/huggingface/transformers/issues/14608#issuecomment-1004392537) ู[A100](https://github.com/huggingface/transformers/issues/15026#issuecomment-1005033957).

## ุงูุชุฏููู ุงูุชุฏุฑูุฌู ููุชุฏุฑุฌุงุช

ูุฏ ุชูุงุฌู ุจุนุถ ุงูููุงุฐุฌ ุงููุจูุฑุฉ ูุดููุงุช ูู ุงูุฐุงูุฑุฉ ุญุชู ุนูุฏ ุชุนููู ุญุฌู ุงูุฏูุนุฉ ุฅูู 1 ูุงุณุชุฎุฏุงู ุชุฑุงูู ุงูุชุฏุฑุฌุงุช. ููุฑุฌุน ุฐูู ุฅูู ูุฌูุฏ ููููุงุช ุฃุฎุฑู ุชุชุทูุจ ุฃูุถูุง ูุณุงุญุฉ ุชุฎุฒูู ูู ุงูุฐุงูุฑุฉ.

ูููู ุฃู ูุคุฏู ุญูุธ ุฌููุน ุงูุชูุดูุทุงุช ูู ุนูููุฉ ุงูุชูุฑูุฑ ููุฃูุงู ูู ุฃุฌู ุญุณุงุจ ุงูุชุฏุฑุฌุงุช ุฃุซูุงุก ุงูุชูุฑูุฑ ููุฎูู ุฅูู ุฒูุงุฏุฉ ูุจูุฑุฉ ูู ุงูุฐุงูุฑุฉ. ููู ุดุฃู ุงูููุฌ ุงูุจุฏูู ุงููุชูุซู ูู ุงูุชุฎูุต ูู ุงูุชูุดูุทุงุช ูุฅุนุงุฏุฉ ุญุณุงุจูุง ุนูุฏ ุงูุญุงุฌุฉ ุฃุซูุงุก ุงูุชูุฑูุฑ ููุฎูู ุฃู ููุฏุฎู ุฒูุงุฏุฉ ูุจูุฑุฉ ูู ุงูุญูุณุจุฉ ุชุจุทุฆ ุนูููุฉ ุงูุชุฏุฑูุจ.

ููุฏู **ุงูุชุฏููู ุงูุชุฏุฑูุฌู ููุชุฏุฑุฌุงุช** ุญู ูุณุท ุจูู ูุฐูู ุงูููุฌููุ ููุญูุธ ุชูุดูุทุงุช ูุฎุชุงุฑุฉ ุจุดูู ุงุณุชุฑุงุชูุฌู ูู ุฌููุน ุฃูุญุงุก ุงูุฑุณู ุงูุจูุงูู ุงูุญุณุงุจูุ ุจุญูุซ ูุง ููุฒู ุฅุนุงุฏุฉ ุญุณุงุจ ุณูู ุฌุฒุก ูู ุงูุชูุดูุทุงุช ููุชุฏุฑุฌุงุช. ููุญุตูู ุนูู ุดุฑุญ ูุชุนูู ููุชุฏููู ุงูุชุฏุฑูุฌู ููุชุฏุฑุฌุงุชุ ุฑุงุฌุน [ูุฐู ุงูููุงูุฉ ุงูุฑุงุฆุนุฉ](https://medium.com/tensorflow/fitting-larger-networks-into-memory-583e3c758ff9).

ูุชูููู ุงูุชุฏููู ุงูุชุฏุฑูุฌู ููุชุฏุฑุฌุงุช ูู [`Trainer`]ุ ูู ุจุชูุฑูุฑ ุงูุนูู ุงูููุงุจู ุฅูู [`TrainingArguments`]:

```ุจุงูุซูู
training_args = TrainingArguments(
    per_device_train_batch_size=1, gradient_accumulation_steps=4, gradient_checkpointing=True, **default_args
)
```

ุฃูุ ุงุณุชุฎุฏู ๐ค Accelerate - ููููู ุงูุนุซูุฑ ุนูู ูุซุงู ๐ค Accelerate [ุฃุฏูุงู ูู ูุฐุง ุงูุฏููู](#using--accelerate).

<ูุตูุญุฉ>

ูู ุญูู ุฃู ุงูุชุฏููู ุงูุชุฏุฑูุฌู ููุชุฏุฑุฌุงุช ูุฏ ูุญุณู ููุงุกุฉ ุงูุฐุงูุฑุฉุ ุฅูุง ุฃูู ูุจุทุฆ ุงูุชุฏุฑูุจ ุจูุณุจุฉ 20% ุชูุฑูุจูุง.

</ูุตูุญุฉ>
## ุงูุชุฏุฑูุจ ุฐู ุงูุฏูุฉ ุงููุฎุชูุทุฉ

ุชุนุฏ **ุงูุชุฏุฑูุจ ุฐู ุงูุฏูุฉ ุงููุฎุชูุทุฉ**  ุชูููุฉ ุชูุฏู ุฅูู ุชุญุณูู ุงูููุงุกุฉ ุงูุญุณุงุจูุฉ ูุชุฏุฑูุจ ุงูููุงุฐุฌ ูู ุฎูุงู ุงุณุชุฎุฏุงู ุชูุณููุงุช ุฑูููุฉ ุฃูู ุฏูุฉ ูุจุนุถ ุงููุชุบูุฑุงุช. ุชูููุฏููุงุ ุชุณุชุฎุฏู ูุนุธู ุงูููุงุฐุฌ ุฏูุฉ ุงูููุทุฉ ุงูุนุงุฆูุฉ 32 ุจุช (fp32 ุฃู float32) ูุชูุซูู ููุนุงูุฌุฉ ุงููุชุบูุฑุงุช. ููุน ุฐููุ ูุง ุชุชุทูุจ ุฌููุน ุงููุชุบูุฑุงุช ูุฐุง ุงููุณุชูู ุงูุนุงูู ูู ุงูุฏูุฉ ูุชุญููู ูุชุงุฆุฌ ุฏูููุฉ. ูู ุฎูุงู ุชูููู ุฏูุฉ ุจุนุถ ุงููุชุบูุฑุงุช ุฅูู ุชูุณููุงุช ุฑูููุฉ ุฃููุ ูุซู ุงูููุทุฉ ุงูุนุงุฆูุฉ 16 ุจุช (fp16 ุฃู float16)ุ ูููููุง ุชุณุฑูุน ุงูุนูููุงุช ุงูุญุณุงุจูุฉ. ูุธุฑูุง ูุฃู ุจุนุถ ุงูุนูููุงุช ุงูุญุณุงุจูุฉ ูู ูุฐุง ุงูููุฌ ูุชู ุฅุฌุฑุงุคูุง ุจูุตู ุงูุฏูุฉุ ุจูููุง ูุง ุชุฒุงู ุจุนุถูุง ุงูุขุฎุฑ ุจุฏูุฉ ูุงููุฉุ ููุทูู ุนูู ุงูููุฌ ุงุณู ุงูุชุฏุฑูุจ ุฐู ุงูุฏูุฉ ุงููุฎุชูุทุฉ.

ูุชู ุชุญููู ุงูุชุฏุฑูุจ ุฐู ุงูุฏูุฉ ุงููุฎุชูุทุฉ ูู ูุนุธู ุงูุฃุญูุงู ุจุงุณุชุฎุฏุงู ุฃููุงุน ุจูุงูุงุช fp16 (float16)ุ ููุน ุฐููุ ุชููุฑ ุจุนุถ ุจููุงุช GPU (ูุซู ุจููุฉ Ampere) ุฃููุงุน ุจูุงูุงุช bf16 ูtf32 (ููุน ุจูุงูุงุช CUDA ุงูุฏุงุฎูู). ุชุญูู ูู [ูุฏููุฉ NVIDIA](https://developer.nvidia.com/blog/accelerating-ai-training-with-tf32-tensor-cores/) ููุนุฑูุฉ ุงููุฒูุฏ ุนู ุงูุงุฎุชูุงูุงุช ุจูู ุฃููุงุน ุงูุจูุงูุงุช ูุฐู.

### fp16

ุชุฃุชู ุงูููุฒุฉ ุงูุฑุฆูุณูุฉ ููุชุฏุฑูุจ ุฐู ุงูุฏูุฉ ุงููุฎุชูุทุฉ ูู ุญูุธ ุงูุชูุดูุทุงุช ุจูุตู ุงูุฏูุฉ (fp16). ุนูู ุงูุฑุบู ูู ุฃู ุงูุชุฏุฑุฌุงุช ูุชู ุญุณุงุจูุง ุฃูุถูุง ุจูุตู ุงูุฏูุฉุ ุฅูุง ุฃููุง ุชูุญูู ูุฑุฉ ุฃุฎุฑู ุฅูู ุฏูุฉ ูุงููุฉ ูุฎุทูุฉ ุงูุชุญุณูู ุจุญูุซ ูุง ูุชู ุชูููุฑ ุงูุฐุงูุฑุฉ ููุง.

ูู ุญูู ุฃู ุงูุชุฏุฑูุจ ุฐู ุงูุฏูุฉ ุงููุฎุชูุทุฉ ูุคุฏู ุฅูู ุนูููุงุช ุญุณุงุจูุฉ ุฃุณุฑุนุ ุฅูุง ุฃูู ูููู ุฃู ูุคุฏู ุฃูุถูุง ุฅูู ุงุณุชุฎุฏุงู ุงููุฒูุฏ ูู ุฐุงูุฑุฉ GPUุ ุฎุงุตุฉ ูุญุฌู ุงูุฏูุนุงุช ุงูุตุบูุฑุฉ. ููุฑุฌุน ุฐูู ุฅูู ุฃู ุงููููุฐุฌ ููุฌูุฏ ุงูุขู ุนูู GPU ุจุฏูุฉ 16 ุจุช ู32 ุจุช (1.5x ูู ุงููููุฐุฌ ุงูุฃุตูู ุนูู GPU).

ูุชูููู ุงูุชุฏุฑูุจ ุฐู ุงูุฏูุฉ ุงููุฎุชูุทุฉุ ูู ุจุชุนููู ุนูุงูุฉ `fp16` ุนูู `True`:

```ุจู
training_args = TrainingArguments(per_device_train_batch_size=4, fp16=True, **default_args)
```

ุฅุฐุง ููุช ุชูุถู ุงุณุชุฎุฏุงู ๐ค Accelerateุ ูุงุจุญุซ ุนู ูุซุงู ๐ค Accelerate [ูููุง ุจุนุฏ ูู ูุฐุง ุงูุฏููู](#using-accelerate).

### BF16

ุฅุฐุง ูุงู ูุฏูู ุฅููุงููุฉ ุงููุตูู ุฅูู Ampere ุฃู ุฃุฌูุฒุฉ ุฃุญุฏุซุ ูููููู ุงุณุชุฎุฏุงู bf16 ููุชุฏุฑูุจ ูุงูุชูููู ุฐู ุงูุฏูุฉ ุงููุฎุชูุทุฉ. ูู ุญูู ุฃู ุฏูุฉ bf16 ุฃุณูุฃ ูู fp16ุ ุฅูุง ุฃู ููุง ูุทุงู ุฏููุงูููู ุฃูุจุฑ ุจูุซูุฑ. ูู fp16 ุฃูุจุฑ ุฑูู ูููู ุฃู ูููู ูู `65535` ูุฃู ุฑูู ุฃุนูู ูู ุฐูู ุณูุคุฏู ุฅูู ููุถ. ูููู ุฃู ูููู ุฑูู bf16 ูุจูุฑูุง ูุซู `3.39e+38` (!) ููู ูุง ููุงุซู ุชูุฑูุจูุง fp32 - ูุฃู ูููููุง ูุณุชุฎุฏู 8 ุจุชุงุช ูููุทุงู ุงูุฑููู.

ููููู ุชูููู BF16 ูู ๐ค Trainer ุจุงุณุชุฎุฏุงู ูุง ููู:

```ุจุงูุซูู
training_args = TrainingArguments(bf16=True, **default_args)
```

### TF32

ุชุณุชุฎุฏู ุฃุฌูุฒุฉ Ampere ููุน ุจูุงูุงุช ุณุญุฑู ูุณูู tf32. ูุฏููุง ููุณ ุงููุทุงู ุงูุฑููู ูุซู fp32 (8 ุจุช)ุ ูููู ุจุฏูุงู ูู 23 ุจุช ูู ุงูุฏูุฉุ ูุฏููุง ููุท 10 ุจุชุงุช (ููุณ fp16) ูุชุณุชุฎุฏู ููุท 19 ุจุช ูู ุงููุฌููุน. ุฅูู "ุณุญุฑู" ุจูุนูู ุฃูู ููููู ุงุณุชุฎุฏุงู ุฑูุฒ ุงูุชุฏุฑูุจ ู/ุฃู ุงูุงุณุชุฏูุงู fp32 ุงูุนุงุฏูุ ููู ุฎูุงู ุชูููู ุฏุนู tf32ุ ููููู ุงูุญุตูู ุนูู ุชุญุณู ูู ุงูุฅูุชุงุฌูุฉ ูุตู ุฅูู 3 ูุฑุงุช. ูู ูุง ุนููู ูุนูู ูู ุฅุถุงูุฉ ูุง ููู ุฅูู ุฑูุฒู:

```ุจุงูุซูู
ุงุณุชูุฑุงุฏ ุงูุดุนูุฉ

torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True
```

ุณูููู CUDA ุชููุงุฆููุง ุจุงูุชุจุฏูู ุฅูู ุงุณุชุฎุฏุงู tf32 ุจุฏูุงู ูู fp32 ุญูุซูุง ูุงู ุฐูู ูููููุงุ ุจุงูุชุฑุงุถ ุฃู GPU ุงููุณุชุฎุฏูุฉ ูู ูู ุณูุณูุฉ Ampere.

ููููุง ูุจุญุซ [NVIDIA](https://developer.nvidia.com/blog/accelerating-ai-training-with-tf32-tensor-cores/)ุ ูุฅู ุบุงูุจูุฉ ุฃุนุจุงุก ุนูู ุงูุชุฏุฑูุจ ุนูู ุงูุชุนูู ุงูุขูู ุชุธูุฑ ููุณ ุงูุบููุถ ูุงูุชูุงุฑุจ ูุน ุงูุชุฏุฑูุจ tf32 ููุง ูู ุงูุญุงู ูุน fp32. ุฅุฐุง ููุช ุชุณุชุฎุฏู ุจุงููุนู fp16 ุฃู bf16 ุงูุฏูุฉ ุงููุฎุชูุทุฉุ ููุฏ ูุณุงุนุฏ ุฐูู ูู ุงูุฅูุชุงุฌูุฉ ุฃูุถูุง.

ููููู ุชูููู ูุฐุง ุงููุถุน ูู ๐ค Trainer:

```ุจุงูุซูู
TrainingArguments(tf32=True, **default_args)
```

<Tip>

ูุง ูููู ุงููุตูู ุฅูู tf32 ูุจุงุดุฑุฉ ุนุจุฑ `tensor.to(dtype=torch.tf32)` ูุฃูู ููุน ุจูุงูุงุช CUDA ุฏุงุฎูู. ุชุญุชุงุฌ ุฅูู `torch>=1.7` ูุงุณุชุฎุฏุงู ุฃููุงุน ุจูุงูุงุช tf32.

</Tip>

ููุญุตูู ุนูู ูุนูููุงุช ุฅุถุงููุฉ ุญูู tf32 ููุงุจู ุงูุฏูุฉ ุงูุฃุฎุฑูุ ูุฑุฌู ุงูุฑุฌูุน ุฅูู ุงููุนุงููุฑ ุงููุฑุฌุนูุฉ ุงูุชุงููุฉ:
[RTX-3090](https://github.com/huggingface/transformers/issues/14608#issuecomment-1004390803) ู [A100](https://github.com/huggingface/transformers/issues/15026#issuecomment-1004543189).

## ููุงุด ุงูุงูุชุจุงู 2

ููููู ุชุณุฑูุน ุงูุฅูุชุงุฌูุฉ ุงูุชุฏุฑูุจูุฉ ูู ุฎูุงู ุงุณุชุฎุฏุงู ุชูุงูู Flash Attention 2 ูู ุงููุญููุงุช. ุชุญูู ูู ุงููุณู ุงูููุงุณุจ ูู [ูุณู GPU ุงููุฑุฏู](./perf_infer_gpu_one#Flash-Attention-2) ููุนุฑูุฉ ุงููุฒูุฏ ุญูู ููููุฉ ุชุญููู ูููุฐุฌ ุจุงุณุชุฎุฏุงู ูุญุฏุงุช Flash Attention 2.

## ุงุฎุชูุงุฑ ุงููุญุณู

ุงููุญุณู ุงูุฃูุซุฑ ุดููุนูุง ุงููุณุชุฎุฏู ูุชุฏุฑูุจ ููุงุฐุฌ ุงููุญูู ูู Adam ุฃู AdamW (Adam ูุน ุงูุฎูุงุถ ุงููุฒู). ูุญูู Adam ุชูุงุฑุจูุง ุฌูุฏูุง ูู ุฎูุงู ุชุฎุฒูู ุงููุชูุณุท ุงููุชุญุฑู ููุชุฏุฑุฌุงุช ุงูุณุงุจูุฉุ ููุน ุฐููุ ูุฅูู ูุถูู ุจุตูุฉ ุฐุงูุฑุฉ ุฅุถุงููุฉ ุจุญุฌู ุนุฏุฏ ูุนููุงุช ุงููููุฐุฌ. ููุนุงูุฌุฉ ุฐููุ ููููู ุงุณุชุฎุฏุงู ูุญุณู ุจุฏูู.

ุนูู ุณุจูู ุงููุซุงูุ ุฅุฐุง ูุงู ูุฏูู [NVIDIA/apex](https://github.com/NVIDIA/apex) ูุซุจุชูุง ูู GPUs NVIDIAุ ุฃู [ROCmSoftwarePlatform/apex](https://github.com/ROCmSoftwarePlatform/apex) ูู GPUs AMDุ ูุณูููุญู `adamw_apex_fused` ุฃุณุฑุน ุชุฌุฑุจุฉ ุชุฏุฑูุจ ุจูู ุฌููุน ูุญุณูุงุช AdamW ุงููุฏุนููุฉ.

ูุถู [`Trainer`] ูุฌููุนุฉ ูุชููุนุฉ ูู ุงููุญุณูุงุช ุงูุชู ูููู ุงุณุชุฎุฏุงููุง ูุจุงุดุฑุฉ ูู ุงูุตูุฏูู: `adamw_hf`ุ `adamw_torch`ุ `adamw_torch_fused`ุ `adamw_apex_fused`ุ `adamw_anyprecision`ุ `adafactor`ุ ุฃู `adamw_bnb_8bit`. ูููู ุชูุตูู ุงููุฒูุฏ ูู ุงููุญุณูุงุช ุนุจุฑ ุชูููุฐ ุฌูุฉ ุฎุงุฑุฌูุฉ.

ุฏุนูุง ูููู ูุธุฑุฉ ูุงุญุตุฉ ุนูู ุจุฏูููู ููุญุณู AdamW:

1. `adafactor` ุงููุชุงุญ ูู [`Trainer`]
2. `adamw_bnb_8bit` ูุชุงุญ ุฃูุถูุง ูู Trainerุ ูููู ูุชู ุชูููุฑ ุงูุชูุงูู ูุน ุฌูุฉ ุฎุงุฑุฌูุฉ ุฃุฏูุงู ููุชูุถูุญ.

ูููุงุฑูุฉ ุฐููุ ุจุงููุณุจุฉ ููููุฐุฌ ูุนููุงุช 3Bุ ูุซู "google-t5/t5-3b":

* ุณูู ูุญุชุงุฌ ูุญุณู AdamW ุงูููุงุณู ุฅูู 24 ุฌูุฌุงุจุงูุช ูู ุฐุงูุฑุฉ GPU ูุฃูู ูุณุชุฎุฏู 8 ุจุงูุชุงุช ููู ูุนููุฉ (8*3 => 24 ุฌูุฌุงุจุงูุช)
* ุณูู ูุญุชุงุฌ ูุญุณู Adafactor ุฅูู ุฃูุซุฑ ูู 12 ุฌูุฌุงุจุงูุช. ูุณุชุฎุฏู ุฃูุซุฑ ุจูููู ูู 4 ุจุงูุชุงุช ููู ูุนููุฉุ ูุฐุง 4*3 ุซู ุจุนุถ ุงูุฅุถุงูุงุช.
* ุณูู ูุณุชุฎุฏู ูุญุณู 8 ุจุช BNB ูููุฉ ุตุบูุฑุฉ ููุท (2*3) 6 ุฌูุฌุงุจุงูุช ุฅุฐุง ุชู ุชุญููู ุฌููุน ุญุงูุงุช ุงููุญุณู.

### Adafactor

ูุง ูููู Adafactor ุจุชุฎุฒูู ุงููุชูุณุทุงุช ุงููุชุญุฑูุฉ ููู ุนูุตุฑ ูู ุงููุตูููุงุช ุงููุฒููุฉ. ุจุฏูุงู ูู ุฐููุ ูุฅูู ูุญุชูุธ ุจุงููุนูููุงุช ุงููุฌูุนุฉ (ูุฌุงููุน ุงููุชูุณุทุงุช ุงููุชุญุฑูุฉ ุตููุง ูุนููุฏููุง)ุ ููุง ูููู ุจุดูู ูุจูุฑ ูู ุจุตูุชู. ููุน ุฐููุ ููุงุฑูุฉ ุจู Adamุ ูุฏ ูููู ูุฏู Adafactor ุชูุงุฑุจ ุฃุจุทุฃ ูู ุจุนุถ ุงูุญุงูุงุช.

ููููู ุงูุชุจุฏูู ุฅูู Adafactor ุนู ุทุฑูู ุชุนููู `optim="adafactor"` ูู [`TrainingArguments`]:

```ุจู
training_args = TrainingArguments(per_device_train_batch_size=4, optim="adafactor"ุ **default_args)
```

ุจุงูุฌูุน ุจูู ุงูููุฌ ุงูุฃุฎุฑู (ุชุฑุงูู ุงูุชุฏุฑุฌุงุชุ ููุฑุงุฌุนุฉ ุงูุชุฏุฑุฌุงุชุ ูุงูุชุฏุฑูุจ ุฐู ุงูุฏูุฉ ุงููุฎุชูุทุฉ)ุ ููููู ููุงุญุธุฉ ุชุญุณู ูุตู ุฅูู 3 ูุฑุงุช ูุน ุงูุญูุงุธ ุนูู ุงูุฅูุชุงุฌูุฉ! ููุน ุฐููุ ููุง ุฐูุฑูุง ุณุงุจููุงุ ูุฏ ูููู ุชูุงุฑุจ Adafactor ุฃุณูุฃ ูู Adam.

### Adam 8 ุจุช

ุจุฏูุงู ูู ุชุฌููุน ุญุงูุงุช ุงููุญุณู ูุซู Adafactorุ ูุญุชูุธ Adam 8 ุจุช ุจุงูุญุงูุฉ ุงููุงููุฉ ููููู ุจุชุญููููุง ุฅูู ุงููุทุงู. ูุนูู ุงูุชุญููู ุฃูู ูุชู ุชุฎุฒูู ุงูุญุงูุฉ ุจุฏูุฉ ุฃูู ููุชู ุฅูุบุงุก ุชุญููููุง ููุท ููุชุญุณูู. ูุฐุง ูุดุงุจู ููููุฑุฉ ูุฑุงุก ุงูุชุฏุฑูุจ ุฐู ุงูุฏูุฉ ุงููุฎุชูุทุฉ.

ูุงุณุชุฎุฏุงู `adamw_bnb_8bit`ุ ูุง ุนููู ุณูู ุชุนููู `optim="adamw_bnb_8bit"` ูู [`TrainingArguments`]:

```ุจู
training_args = TrainingArguments(per_device_train_batch_size=4, optim="adamw_bnb_8bit"ุ **default_args)
```

ููุน ุฐููุ ูููููุง ุฃูุถูุง ุงุณุชุฎุฏุงู ุชูููุฐ ุฌูุฉ ุฎุงุฑุฌูุฉ ููุญุณู 8 ุจุช ููุชูุถูุญ ุนูู ููููุฉ ุฏูุฌ ุฐูู.

ุฃููุงูุ ุงุชุจุน ุฏููู ุงูุชุซุจูุช ูู ูุณุชูุฏุน GitHub [repo](https://github.com/TimDettmers/bitsandbytes) ูุชุซุจูุช ููุชุจุฉ `bitsandbytes` ุงูุชู ุชููุฐ ูุญุณู Adam 8 ุจุช.

ุจุนุฏ ุฐููุ ุชุญุชุงุฌ ุฅูู ุชููุฆุฉ ุงููุญุณู. ููุทูู ุฐูู ุนูู ุฎุทูุชูู:

* ุฃููุงูุ ูู ุจุชูุณูู ูุนููุงุช ุงููููุฐุฌ ุฅูู ูุฌููุนุชูู - ูุงุญุฏุฉ ูุชู ุชุทุจูู ุงูุฎูุงุถ ุงููุฒู ุนูููุงุ ูุงูุฃุฎุฑู ูุง. ุนุงุฏุฉู ูุง ูุชู ุงุณุชุจุนุงุฏ ุงูุงูุญูุงุฒ ููุนููุงุช ุทุจูุฉ ุงูุชุทุจูุน ูู ุงูุฎูุงุถ ุงููุฒู.
* ุซู ูู ุจุชูุธูู ุงูุญุฌุฌ ูุงุณุชุฎุฏุงู ููุณ ุงููุนููุงุช ููุง ูู ุงูุญุงู ูู ูุญุณู AdamW ุงููุณุชุฎุฏู ุณุงุจููุง.

```ุจู
ุงุณุชูุฑุงุฏ ุจุชุณุงูุฏุจุงูุชุณ ุจุงุณู ุจุชุจ

ูู ุงูุดุนูุฉ ุงุณุชูุฑุงุฏ ูู

ูู transformers.trainer_pt_utils ุงุณุชูุฑุงุฏ get_parameter_names

training_args = TrainingArguments(per_device_train_batch_size=4, **default_args)

decay_parameters = get_parameter_names(model, [nn.LayerNorm])
decay_parameters = [name for name in decay_parameters if "bias" not in name]
optimizer_grouped_parameters = [
{
"params": [p for n, p in model.named_parameters() if n in decay_parameters],
"weight_decay": training_args.weight_decay,
},
{
"params": [p for n, p in model.named_parameters() if n not in decay_parameters],
"weight_decay": 0.0,
},
]

optimizer_kwargs = {
"betas": (training_args.adam_beta1, training_args.adam_beta2)ุ
"eps": training_args.adam_epsilon
}
optimizer_kwargs["lr"] = training_args.learning_rate
adam_bnb_optim = bnb.optim.Adam8bit(
optimizer_grouped_parameters,
betas=(training_args.adam_beta1, training_args.adam_beta2)ุ
eps=training_args.adam_epsilon,
lr=training_args.learning_rate,
)
```

ุฃุฎูุฑูุงุ ูู ุจุชูุฑูุฑ ุงููุญุณู ุงููุฎุตุต ูุญุฌุฉ ุฅูู `Trainer`:

```ุจู
ุงููุฏุฑุจ = Trainer(model=modelุ args=training_argsุ train_dataset=dsุ optimizers=(adam_bnb_optimุ None))
```

ุจุงูุฌูุน ุจูู ุงูููุฌ ุงูุฃุฎุฑู (ุชุฑุงูู ุงูุชุฏุฑุฌุงุชุ ููุฑุงุฌุนุฉ ุงูุชุฏุฑุฌุงุชุ ูุงูุชุฏุฑูุจ ุฐู ุงูุฏูุฉ ุงููุฎุชูุทุฉ)ุ ููููู ุชููุน ุงูุญุตูู ุนูู ุชุญุณู ูู ุงูุฐุงูุฑุฉ ูุจูุบ ุญูุงูู 3 ูุฑุงุช ูุญุชู ุฒูุงุฏุฉ ุทูููุฉ ูู ุงูุฅูุชุงุฌูุฉ ููุง ูู ุงูุญุงู ุนูุฏ ุงุณุชุฎุฏุงู Adafactor.

### multi_tensor

ูุฏู pytorch-nightly `torch.optim._multi_tensor` ุงูุฐู ูุฌุจ ุฃู ูุณุฑุน ุจุดูู ูุจูุฑ ุงููุญุณูุงุช ููููุงูู ุงูุชู ุชุญุชูู ุนูู ุงูุนุฏูุฏ ูู ุงูููุฒุงุช ุงูุตุบูุฑุฉ. ูุฌุจ ุฃู ูุตุจุญ ูุฐุง ูู ุงูุงูุชุฑุงุถู ูู ุงูููุงูุฉุ ูููู ุฅุฐุง ููุช ุชุฑูุฏ ุชุฌุฑุจุชู ูู ููุช ุฃูุฑุจุ ูุฑุงุฌุน ูุดููุฉ GitHub ูุฐู [issue](https://github.com/huggingface/transformers/issues/9965).
## ุงูุชุญููู ุงููุณุจู ููุจูุงูุงุช

ูู ุงููุชุทูุจุงุช ุงููููุฉ ูููุตูู ุฅูู ุณุฑุนุฉ ุชุฏุฑูุจ ุนุงููุฉ ูู ุงููุฏุฑุฉ ุนูู ุชุบุฐูุฉ ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU) ุจุฃูุตู ุณุฑุนุฉ ูููููุง ุงูุชุนุงูู ูุนูุง. ุจุดูู ุงูุชุฑุงุถูุ ูุญุฏุซ ูู ุดูุก ูู ุงูุนูููุฉ ุงูุฑุฆูุณูุฉุ ููุฏ ูุง ุชุชููู ูู ูุฑุงุกุฉ ุงูุจูุงูุงุช ูู ุงููุฑุต ุจุณุฑุนุฉ ูุงููุฉุ ููุง ูุคุฏู ุฅูู ุงุฎุชูุงู ูุคุฏู ุฅูู ุงูุงุณุชุฎุฏุงู ุงููุงูุต ููุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช. ูู ุจุชูููู ุงูุญุฌุฌ ุงูุชุงููุฉ ููุญุฏ ูู ุงูุงุฎุชูุงู:

- `DataLoader(pin_memory=True, ...)` - ูุถูู ุชุญููู ุงูุจูุงูุงุช ูุณุจููุง ูู ุงูุฐุงูุฑุฉ ุงููุซุจุชุฉ ุนูู ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ (CPU) ููุคุฏู ุนุงุฏุฉู ุฅูู ููู ุฃุณุฑุน ุจูุซูุฑ ูู ุฐุงูุฑุฉ ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ ุฅูู ุฐุงูุฑุฉ ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช.

- `DataLoader(num_workers=4, ...)` - ูู ุจุชุดุบูู ุนุฏุฉ ุนูุงู ูุชุญููู ุงูุจูุงูุงุช ุจุดูู ุฃุณุฑุน. ุฃุซูุงุก ุงูุชุฏุฑูุจุ ุฑุงูุจ ุฅุญุตุงุฆูุงุช ุงุณุชุฎุฏุงู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุชุ ุฅุฐุง ูุงู ุจุนูุฏูุง ุนู 100%ุ ูุฌุฑูุจ ุฒูุงุฏุฉ ุนุฏุฏ ุงูุนูุงู. ุจุงูุทุจุนุ ูุฏ ุชููู ุงููุดููุฉ ูู ููุงู ุขุฎุฑุ ูุฐูู ูุฏ ูุง ูุคุฏู ุฒูุงุฏุฉ ุนุฏุฏ ุงูุนูุงู ุฅูู ุชุญุณูู ุงูุฃุฏุงุก.

ุนูุฏ ุงุณุชุฎุฏุงู [`Trainer`]ุ ุชููู ุญุฌุฌ [`TrainingArguments`] ุงูููุงุจูุฉ ูู: `dataloader_pin_memory` (`True` ุจุดูู ุงูุชุฑุงุถู)ุ ู`dataloader_num_workers` (ุงูุชุฑุงุถููุง `0`).

## DeepSpeed ZeRO

DeepSpeed ูู ููุชุจุฉ ุชุญุณูู ููุชุนูู ุงูุนููู ููุชูุญุฉ ุงููุตุฏุฑ ูุฏูุฌุฉ ูุน ๐ค Transformers ู๐ค Accelerate. ูููุฑ ูุฌููุนุฉ ูุงุณุนุฉ ูู ุงูููุฒุงุช ูุงูุชุญุณููุงุช ุงููุตููุฉ ูุชุญุณูู ููุงุกุฉ ููุทุงู ุชุฏุฑูุจ ุงูุชุนูู ุงูุนููู ูุงุณุน ุงููุทุงู.

ุฅุฐุง ูุงู ูููุฐุฌู ููุงุณุจ ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU) ูุงุญุฏุฉ ููุฏูู ูุณุงุญุฉ ูุงููุฉ ูุชูุงุณุจ ุญุฌู ุฏูุนุฉ ุตุบูุฑุ ููุง ุชุญุชุงุฌ ุฅูู ุงุณุชุฎุฏุงู DeepSpeed ูุฃูู ุณูุจุทุฆ ุงูุฃููุฑ ููุท. ููุน ุฐููุ ุฅุฐุง ูู ููุงุณุจ ุงููููุฐุฌ ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU) ูุงุญุฏุฉ ุฃู ูุง ููููู ุชูุงุณุจ ุญุฌู ุฏูุนุฉ ุตุบูุฑุ ูููููู ุงูุงุณุชูุงุฏุฉ ูู DeepSpeed ZeRO + CPU Offloadุ ุฃู NVMe Offload ููููุงุฐุฌ ุงูุฃูุจุฑ ุญุฌููุง. ูู ูุฐู ุงูุญุงูุฉุ ุชุญุชุงุฌ ุฅูู ุชุซุจูุช ุงูููุชุจุฉ ุจุดูู ูููุตูุ ุซู ุงุชุจุน ุฃุญุฏ ุงูุฃุฏูุฉ ูุฅูุดุงุก ููู ุชูููู ูุชุดุบูู DeepSpeed:

* ููุญุตูู ุนูู ุฏููู ูุชุนูู ุญูู ุชูุงูู DeepSpeed ูุน [`Trainer`]`ุ ุฑุงุฌุน [ูุซุงุฆู](main_classes/deepspeed) ุงูููุงุจูุฉุ ูุชุญุฏูุฏูุง [ุงููุณู ุงูุฎุงุต ุจูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU) ูุงุญุฏุฉ](main_classes/deepspeed#deployment-with-one-gpu). ูุทููุจ ุจุนุถ ุงูุชุนุฏููุงุช ูุงุณุชุฎุฏุงู DeepSpeed ูู ุฏูุชุฑ ููุงุญุธุงุชุ ูุฑุฌู ุฅููุงุก ูุธุฑุฉ ุนูู [ุงูุฏููู ุงูููุงุจู](main_classes/deepspeed#deployment-in-notebooks).

* ุฅุฐุง ููุช ุชูุถู ุงุณุชุฎุฏุงู ๐ค Accelerateุ ูุฑุฌู ุงูุฑุฌูุน ุฅูู [ุฏููู DeepSpeed ูู ๐ค Accelerate](https://huggingface.co/docs/accelerate/en/usage_guides/deepspeed).

## ุงุณุชุฎุฏุงู torch.compile

ูุฏู PyTorch 2.0 ุฏุงูุฉ ุชุฌููุน ุฌุฏูุฏุฉ ูุง ุชุชุทูุจ ุฃู ุชุนุฏูู ุนูู ููุฏ PyTorch ุงูููุฌูุฏ ูููู ูููููุง ุชุญุณูู ููุฏู ุนู ุทุฑูู ุฅุถุงูุฉ ุณุทุฑ ูุงุญุฏ ูู ุงูููุฏ: `model = torch.compile(model)`.

ุฅุฐุง ููุช ุชุณุชุฎุฏู [`Trainer`]`ุ ูุฃูุช ุจุญุงุฌุฉ ููุท ุฅูู ุชูุฑูุฑ` `torch_compile` option ูู [`TrainingArguments`]:

```python
training_args = TrainingArguments(torch_compile=True, **default_args)
```

ูุณุชุฎุฏู `torch.compile` ูุงุฌูุฉ ุจุฑูุฌุฉ ุชุทุจููุงุช ุชูููู ุงูุฅุทุงุฑ ุงูุฎุงุตุฉ ุจู Python ูุฅูุดุงุก ุฑุณู ุจูุงูู ุชููุงุฆููุง ูู ุจุฑุงูุฌ PyTorch ุงูููุฌูุฏุฉ. ุจุนุฏ ุงูุชูุงุท ุงูุฑุณู ุงูุจูุงููุ ูููู ูุดุฑ backends ูุฎุชููุฉ ูุฎูุถ ุงูุฑุณู ุงูุจูุงูู ุฅูู ูุญุฑู ูุญุณูู.

ููููู ุงูุนุซูุฑ ุนูู ูุฒูุฏ ูู ุงูุชูุงุตูู ูุงูุงุฎุชุจุงุฑุงุช ุงููุนูุงุฑูุฉ ูู [ูุซุงุฆู PyTorch](https://pytorch.org/get-started/pytorch-2.0/).

ูุฏู `torch.compile` ูุงุฆูุฉ ูุชุฒุงูุฏุฉ ูู backendsุ ูุงูุชู ูููู ุงูุนุซูุฑ ุนูููุง ุนู ุทุฑูู ุงุณุชุฏุนุงุก `torchdynamo.list_backends()`ุ ููู ูููุง ุชุจุนูุงุชู ุงูุงุฎุชูุงุฑูุฉ.

ุญุฏุฏ backend ุงูุฐู ุชุฑูุฏ ุงุณุชุฎุฏุงูู ุนู ุทุฑูู ุชุญุฏูุฏู ุนุจุฑ `torch_compile_backend` ูู [`TrainingArguments`]. ุจุนุถ ูู backends ุงูุฃูุซุฑ ุงุณุชุฎุฏุงููุง ูู:

**backends ุงูุชุตุญูุญ**:

* `dynamo.optimize("eager")` - ูุณุชุฎุฏู PyTorch ูุชุดุบูู GraphModule ุงููุณุชุฎุฑุฌ. ูุฐุง ูููุฏ ุฌุฏูุง ูู ุชุตุญูุญ ูุดููุงุช TorchDynamo.

* `dynamo.optimize("aot_eager")` - ูุณุชุฎุฏู AotAutograd ุจุฏูู ูุชุฑุฌูุ ุฃู ุจุงุณุชุฎุฏุงู Eager ุงูุฎุงุต ุจู PyTorch ููุฑุณูู ุงูุจูุงููุฉ ููุฃูุงู ูุงูุฎูู ุงููุณุชุฎุฑุฌุฉ ูู AotAutograd. ูุฐุง ูููุฏ ููุชุตุญูุญุ ููู ุบูุฑ ุงููุฑุฌุญ ุฃู ูุนุทู ุณุฑุนุงุช.

**backends ุงูุชุฏุฑูุจ ูุงูุงุณุชุฏูุงู**:

* `dynamo.optimize("inductor")` - ูุณุชุฎุฏู backend TorchInductor ูุน AotAutograd ูcudagraphs ุนู ุทุฑูู ุงูุงุณุชูุงุฏุฉ ูู ููุงุฉ Triton ุงููุฑูุฒุฉ [ุงูุฑุฃ ุงููุฒูุฏ](https://dev-discuss.pytorch.org/t/torchinductor-a-pytorch-native-compiler-with-define-by-run-ir-and-symbolic-shapes/747)

* `dynamo.optimize("nvfuser")` - nvFuser ูุน TorchScript. [ุงูุฑุฃ ุงููุฒูุฏ](https://dev-discuss.pytorch.org/t/tracing-with-primitives-update-1-nvfuser-and-its-primitives/593)

* `dynamo.optimize("aot_nvfuser")` - nvFuser ูุน AotAutograd. [ุงูุฑุฃ ุงููุฒูุฏ](https://dev-discuss.pytorch.org/t/tracing-with-primitives-update-1-nvfuser-and-its-primitives/593)

* `dynamo.optimize("aot_cudagraphs")` - cudagraphs ูุน AotAutograd. [ุงูุฑุฃ ุงููุฒูุฏ](https://github.com/pytorch/torchdynamo/pull/757)

**backends ุงูุงุณุชุฏูุงู ููุท**:

* `dynamo.optimize("ofi")` - ูุณุชุฎุฏู Torchscript optimize_for_inference. [ุงูุฑุฃ ุงููุฒูุฏ](https://pytorch.org/docs/stable/generated/torch.jit.optimize_for_inference.html)

* `dynamo.optimize("fx2trt")` - ูุณุชุฎุฏู NVIDIA TensorRT ูุชุญุณูู ุงูุงุณุชุฏูุงู. [ุงูุฑุฃ ุงููุฒูุฏ](https://pytorch.org/TensorRT/tutorials/getting_started_with_fx_path.html)

* `dynamo.optimize("onnxrt")` - ูุณุชุฎุฏู ONNXRT ููุงุณุชุฏูุงู ุนูู ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ/ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช. [ุงูุฑุฃ ุงููุฒูุฏ](https://onnxruntime.ai/)

* `dynamo.optimize("ipex")` - ูุณุชุฎุฏู IPEX ููุงุณุชุฏูุงู ุนูู ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ. [ุงูุฑุฃ ุงููุฒูุฏ](https://github.com/intel/intel-extension-for-pytorch)

ููุซุงู ุนูู ุงุณุชุฎุฏุงู `torch.compile` ูุน ๐ค Transformersุ ุชุญูู ูู [ููุดูุฑ ุงููุฏููุฉ ุญูู ุถุจุท ุฏููู ููููุฐุฌ BERT ูุชุตููู ุงููุตูุต ุจุงุณุชุฎุฏุงู ุฃุญุฏุซ ููุฒุงุช PyTorch 2.0](https://www.philschmid.de/getting-started-pytorch-2.0-transformers)

## ุงุณุชุฎุฏุงู ๐ค PEFT

ุชููู [ุทุฑู ุงูุถุจุท ุงูุฏููู ุงููุนุงูุฉ ูููุนููุงุช (PEFT)](https://huggingface.co/blog/peft) ุจุชุฌููุฏ ูุนููุงุช ุงููููุฐุฌ ุงููุณุจู ุงูุชุฏุฑูุจ ุฃุซูุงุก ุงูุถุจุท ุงูุฏููู ูุฅุถุงูุฉ ุนุฏุฏ ุตุบูุฑ ูู ุงููุนููุงุช ุงููุงุจูุฉ ููุชุฏุฑูุจ (ุงูููุงูุฆุงุช) ูููู.

ููุชูุฌุฉ ูุฐููุ ูุชู ุชูููู [ุงูุฐุงูุฑุฉ ุงููุฑุชุจุทุฉ ุจุญุงูุงุช ุงูููุญูุณููู ูุงูุชุฏุฑุฌุงุช](https://huggingface.co/docs/transformers/model_memory_anatomy#anatomy-of-models-memory) ุจุดูู ูุจูุฑ.

ุนูู ุณุจูู ุงููุซุงูุ ูุน AdamW ุงููุงูููุงุ ุณูููู ูุชุทูุจ ุงูุฐุงูุฑุฉ ูุญุงูุฉ ุงูููุญูุณููู ุนูู ุงููุญู ุงูุชุงูู:

* ูุณุฎุฉ fp32 ูู ุงููุนููุงุช: 4 bytes/param

* ุงูุฒุฎู: 4 bytes/param

* ุงูุชุจุงูู: 4 bytes/param

ูููุชุฑุถ ูุฌูุฏ ูููุฐุฌ ุจู 7 ูููุงุฑุงุช ูุนููุฉ ู200 ููููู ูุนููุฉ ุชู ุญูููุง ุจุงุณุชุฎุฏุงู [ุงูููุงูุฆุงุช ุฐุงุช ุงูุฑุชุจุฉ ุงูููุฎูุถุฉ](https://huggingface.co/docs/peft/conceptual_guides/lora).

ุณูููู ูุชุทูุจ ุงูุฐุงูุฑุฉ ูุญุงูุฉ ุงูููุญูุณููู ูููููุฐุฌ ุงูุนุงุฏู 12 * 7 = 84 ุฌูุฌุงุจุงูุช (ุจุงูุชุฑุงุถ 7 ูููุงุฑุงุช ูุนููุฉ ูุงุจูุฉ ููุชุฏุฑูุจ).

ุชุถูู Lora ุฒูุงุฏุฉ ุทูููุฉ ูู ุงูุฐุงูุฑุฉ ุงููุฑุชุจุทุฉ ุจุฃูุฒุงู ุงููููุฐุฌ ูุชููู ุจุดูู ูุจูุฑ ูู ูุชุทูุจุงุช ุงูุฐุงูุฑุฉ ูุญุงูุฉ ุงูููุญูุณููู ุฅูู 12 * 0.2 = 2.4 ุฌูุฌุงุจุงูุช.

ุงูุฑุฃ ุงููุฒูุฏ ุญูู PEFT ูุงุณุชุฎุฏุงูู ุงูููุตู ูู [ูุซุงุฆู PEFT](https://huggingface.co/docs/peft/) ุฃู [ูุณุชูุฏุน PEFT](https://github.com/huggingface/peft).

## ุงุณุชุฎุฏุงู ๐ค Accelerate

ูุน [๐ค Accelerate](https://huggingface.co/docs/accelerate/index) ููููู ุงุณุชุฎุฏุงู ุงูุทุฑู ุงููุฐููุฑุฉ ุฃุนูุงู ูุน ุงูุชุณุงุจ ุงูุชุญูู ุงููุงูู ูู ุญููุฉ ุงูุชุฏุฑูุจ ูููููู ูู ุงูุฃุณุงุณ ูุชุงุจุฉ ุงูุญููุฉ ูู PyTorch ุงูููู ูุน ุจุนุถ ุงูุชุนุฏููุงุช ุงูุทูููุฉ.

ูููุชุฑุถ ุฃูู ููุช ุจุฏูุฌ ุงูุทุฑู ูู [`TrainingArguments`] ููุง ููู:

```py
training_args = TrainingArguments(
per_device_train_batch_size=1,
gradient_accumulation_steps=4,
gradient_checkpointing=True,
fp16=True,
**default_args,
)
```

ูุซุงู ุญููุฉ ุงูุชุฏุฑูุจ ุงููุงูู ูุน ๐ค Accelerate ุนุจุงุฑุฉ ุนู ุนุฏุฏ ูููู ูู ุฃุณุทุฑ ุงูููุฏ:

```py
from accelerate import Accelerator
from torch.utils.data.dataloader import DataLoader

dataloader = DataLoader(ds, batch_size=training_args.per_device_train_batch_size)

if training_args.gradient_checkpointing:
model.gradient_checkpointing_enable()

accelerator = Accelerator(fp16=training_args.fp16)
model, optimizer, dataloader = accelerator.prepare(model, adam_bnb_optim, dataloader)

model.train()
for step, batch in enumerate(dataloader, start=1):
loss = model(**batch).loss
loss = loss / training_args.gradient_accumulation_steps
accelerator.backward(loss)
if step % training_args.gradient_accumulation_steps == 0:
optimizer.step()
optimizer.zero_grad()
```

ุฃููุงูุ ูููู ุจุชุบููู ูุฌููุนุฉ ุงูุจูุงูุงุช ูู [`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader).

ุจุนุฏ ุฐููุ ูููููุง ุชูููู ุงูุชุญูู ูู ุงูุชุฏุฑุฌ ุนู ุทุฑูู ุงุณุชุฏุนุงุก ุทุฑููุฉ [`~PreTrainedModel.gradient_checkpointing_enable`] ูููููุฐุฌ.

ุนูุฏ ุชููุฆุฉ [`Accelerator`](https://huggingface.co/docs/accelerate/package_reference/accelerator#accelerate.Accelerator)

ูููููุง ุชุญุฏูุฏ ูุง ุฅุฐุง ููุง ูุฑูุฏ ุงุณุชุฎุฏุงู ุงูุชุฏุฑูุจ ุจุงูุฏูุฉ ุงููุฎุชูุทุฉ ูุณูู ูุนุชูู ุจุฐูู ุจุงููุณุจุฉ ููุง ูู ููุงููุฉ [`prepare`]

ุฃุซูุงุก ููุงููุฉ [`prepare`](https://huggingface.co/docs/accelerate/package_reference/accelerator#accelerate.Accelerator.prepare)

ุณูุชู ุฃูุถูุง ุชูุฒูุน dataloader ุนุจุฑ ุงูุนูุงู ุฅุฐุง ููุง ูุณุชุฎุฏู ูุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU) ูุชุนุฏุฏุฉ. ูุณุชุฎุฏู [ูุญุณู 8 ุจุช](#8-bit-adam) ููุณู ูู ุงููุซุงู ุงูุณุงุจู.

ุฃุฎูุฑูุงุ ูููููุง ุฅุถุงูุฉ ุญููุฉ ุงูุชุฏุฑูุจ ุงูุฑุฆูุณูุฉ. ูุงุญุธ ุฃู ููุงููุฉ `backward` ุชุชู ูู ูุจู ๐ค Accelerate. ูููููุง ุฃูุถูุง ุฃู ูุฑู ููู ูุนูู ุชุฑุงูู ุงูุชุฏุฑุฌ: ูููู ุจุชุทุจูุน ุงูุฎุณุงุฑุฉุ ูุฐุง ูุญุตู ุนูู ุงููุชูุณุท ูู ููุงูุฉ ุงูุชุฑุงูู ูุจูุฌุฑุฏ ุฃู ูููู ูุฏููุง ุนุฏุฏ ูุงูู ูู ุงูุฎุทูุงุชุ ูููู ุจุชุดุบูู ุงูุชุญุณูู.

ูุง ูุณุชุบุฑู ุชูููุฐ ุชูููุงุช ุงูุชุญุณูู ูุฐู ุจุงุณุชุฎุฏุงู ๐ค Accelerate ุณูู ุนุฏุฏ ูููู ูู ุฃุณุทุฑ ุงูููุฏ ููุฃุชู ุจููุฒุฉ ุงููุฑููุฉ ูู ุญููุฉ ุงูุชุฏุฑูุจ. ููุงุทูุงุน ุนูู ุงููุซุงุฆู ุงููุงููุฉ ูุฌููุน ุงูููุฒุงุชุ ุฑุงุฌุน [ูุซุงุฆู Accelerate](https://huggingface.co/docs/accelerate/index).
## ุญุฒู ุงูุจุฑุงูุฌ ุงูููุณุจูุฉ ุงููุนุงูุฉ

ูููู ุฃู ูุชุทูุจ ุงูุฃูุฑ ูู ุจุนุถ ุงูุฃุญูุงู ุจุฐู ุฌููุฏ ุฅุถุงููุฉ ูุจูุงุก ุจุนุถ ุงูููููุงุช ูุณุจููุง. ุนูู ุณุจูู ุงููุซุงูุ ุฅุฐุง ููุช ุชุณุชุฎุฏู ููุชุจุงุช ูุซู "ุฃุจููุณ" ุงูุชู ูุง ุชุฃุชู ูุฌูุนุฉ ูุณุจููุง. ููู ููุงูู ุฃุฎุฑูุ ูููู ุฃู ูููู ูู ุงููุนูุฏ ูุนุฑูุฉ ููููุฉ ุชุซุจูุช ุญุฒูุฉ "ููุฏุง ุชููููุช" ุงูููุงุณุจุฉ ุนูู ูุณุชูู ุงููุธุงู.

ูููุนุงูุฌุฉ ูุฐู ุงูุณููุงุฑูููุงุชุ ุฃุตุฏุฑุช "ุจุงู ุชูุฑุด" ู"ุฅูููุฏูุง" ูุณุฎุฉ ุฌุฏูุฏุฉ ูู ุญุงููุฉ "ุฅู ุฌู ุณู" ุงูุฎุงุตุฉ ุจู"ุฏุงููุฑ" ูุงูุชู ุชุฃุชู ุจุงููุนู ูุน ูู ุดูุก ูุฌูุน ูุณุจููุง. ูู ูุง ุนููู ูู ุชุซุจูุช ุจุฑุงูุฌู ุนูููุงุ ูุณุชุนูู ุนูู ุงูููุฑ.

ููุฐุง ุงูููุฌ ูููุฏ ุฃูุถูุง ุฅุฐุง ููุช ุชุฑุบุจ ูู ุถุจุท ูุตุฏุฑ "ุจุงู ุชูุฑุด" ู/ุฃู ุฅูุดุงุก ุจูุงุก ูุฎุตุต ุฌุฏูุฏ.

ููุนุซูุฑ ุนูู ุฅุตุฏุงุฑ ุตูุฑุฉ "ุฏุงููุฑ" ุงูุฐู ุชุฑูุฏูุ ุงุจุฏุฃ ุจู[ููุงุญุธุงุช ุฅุตุฏุงุฑ "ุจุงู ุชูุฑุด"](https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/)ุ ูุงุฎุชุฑ ุฃุญุฏุซ ุงูุฅุตุฏุงุฑุงุช ุงูุดูุฑูุฉ. ุงูุชูู ุฅูู ููุงุญุธุงุช ุงูุฅุตุฏุงุฑ ููุฅุตุฏุงุฑ ุงููุทููุจุ ูุชุญูู ูู ุฃู ููููุงุช ุงูุจูุฆุฉ ุชุชุทุงุจู ูุน ุงุญุชูุงุฌุงุชู (ุจูุง ูู ุฐูู ูุชุทูุจุงุช ุจุฑูุงูุฌ ุชุดุบูู "ุฅูููุฏูุง"!)ุ ุซู ูู ุฃุนูู ุชูู ุงููุซููุฉุ ุงูุชูู ุฅูู ุตูุญุฉ "ุฅู ุฌู ุณู" ุงูููุงุจูุฉ. ุฅุฐุง ุถููุช ุงูุทุฑูู ูุฃู ุณุจุจุ ููุฐุง ูู [ููุฑุณ ุฌููุน ุตูุฑ ุจุงู ุชูุฑุด ุฅู ุฌู ุณู](https://ngc.nvidia.com/catalog/containers/nvidia:pytorch).

ุจุนุฏ ุฐููุ ุงุชุจุน ุงูุชุนูููุงุช ูุชูุฒูู ููุดุฑ ุตูุฑุฉ "ุฏุงููุฑ".

## ูุฒูุฌ ุงูุฎุจุฑุงุก

ุฃูุงุฏุช ุจุนุถ ุงูุฃูุฑุงู ุงูุจุญุซูุฉ ุงูุญุฏูุซุฉ ุนู ุชุณุฑูุน ุงูุชุฏุฑูุจ ุจูุนุฏู 4-5 ูุฑุงุช ูุชุณุฑูุน ุงูุงุณุชุฏูุงู ุนู ุทุฑูู ุฏูุฌ ูุฒูุฌ ูู ุงูุฎุจุฑุงุก (MoE) ูู ููุงุฐุฌ ุงููุญูู.

ููุธุฑูุง ูุฃูู ูุฏ ุงูุชูุดู ุฃู ุงููุฒูุฏ ูู ุงููุนููุงุช ุชุคุฏู ุฅูู ุฃุฏุงุก ุฃูุถูุ ุชุชูุญ ูุฐู ุงูุชูููุฉ ุฒูุงุฏุฉ ุนุฏุฏ ุงููุนููุงุช ุจููุฏุงุฑ ุนุดุฑุฉ ุฃุถุนุงู ุฏูู ุฒูุงุฏุฉ ุชูุงููู ุงูุชุฏุฑูุจ.

ููู ูุฐุง ุงูููุฌุ ูุชู ุงุณุชุจุฏุงู ูู ุทุจูุฉ ุดุจูุฉ ุนุตุจูุฉ ุงุตุทูุงุนูุฉ ุฃุฎุฑู ุจุทุจูุฉ MoE ุชุชุฃูู ูู ุงูุนุฏูุฏ ูู ุงูุฎุจุฑุงุกุ ูุน ุฏุงูุฉ ุจูุงุจุฉ ุชููู ุจุชุฏุฑูุจ ูู ุฎุจูุฑ ุจุทุฑููุฉ ูุชูุงุฒูุฉ ุงุนุชูุงุฏูุง ุนูู ููุถุน ุฑูุฒ ุงูุฅุฏุฎุงู ูู ุชุณูุณู.

ูููู ุงูุนุซูุฑ ุนูู ุชูุงุตูู ูููุงุฑูุงุช ุดุงููุฉ ูู ุงูุฃูุฑุงู ุงูุจุญุซูุฉ ุงููุฏุฑุฌุฉ ูู ููุงูุฉ ูุฐุง ุงููุณู.

ุงูุฌุงูุจ ุงูุณูุจู ุงูุฑุฆูุณู ููุฐุง ุงูููุฌ ูู ุฃูู ูุชุทูุจ ูููุงุช ูุฐููุฉ ูู ุฐุงูุฑุฉ ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช - ุฃูุจุฑ ุจุญูุงูู ุนุดุฑุฉ ุฃุถุนุงู ูู ูุธูุฑุชูุง ุงููุซููุฉ. ููุฏ ุงูุชุฑุญุช ุนูููุงุช ุชูุทูุฑ ูููุฌ ูุฎุชููุฉ ููุชุบูุจ ุนูู ูุชุทูุจุงุช ุงูุฐุงูุฑุฉ ุงูุฃุนูู ุจูุซูุฑ.

ูููู ููุงู ููุงุถูุฉ ูุจุงุดุฑุฉุ ุญูุซ ููููู ุงุณุชุฎุฏุงู ุนุฏุฏ ูููู ููุท ูู ุงูุฎุจุฑุงุก ูุน ูููุฐุฌ ุฃุณุงุณู ุฃุตุบุฑ ุจููุฏุงุฑ 2-3 ูุฑุงุช ุจุฏูุงู ูู ุนุดุฑุงุช ุฃู ูุฆุงุช ุงูุฎุจุฑุงุก ููุง ูุคุฏู ุฅูู ูููุฐุฌ ุฃุตุบุฑ ุจููุฏุงุฑ 5 ูุฑุงุช ูุจุงูุชุงูู ุฒูุงุฏุฉ ุณุฑุนุฉ ุงูุชุฏุฑูุจ ุจุดูู ูุนุชุฏู ูุน ุฒูุงุฏุฉ ูุชุทูุจุงุช ุงูุฐุงูุฑุฉ ุจุดูู ูุนุชุฏู ุฃูุถูุง.

ุชุชูุญูุฑ ูุนุธู ุงูุฃูุฑุงู ุงูุจุญุซูุฉ ูุงูุชูููุฐุงุช ุฐุงุช ุงูุตูุฉ ุญูู "ุชููุณูุฑููู/ุชู ุจู ูู":

- [GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding](https://arxiv.org/abs/2006.16668)
- [Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity](https://arxiv.org/abs/2101.03961)
- [GLaM: Generalist Language Model (GLaM)](https://ai.googleblog.com/2021/12/more-efficient-in-context-learning-with.html)

ูุจุงููุณุจุฉ ูู"ุจุงู ุชูุฑุด"ุ ูุงูุช "ุฏูุจ ุณุจูุฏ" ุฃูุถูุง ุจุจูุงุก ูุงุญุฏ: [DeepSpeed-MoE: Advancing Mixture-of-Experts Inference and Training to Power Next-Generation AI Scale](https://arxiv.org/abs/2201.05596)ุ [Mixture of Experts](https://www.deepspeed.ai/tutorials/mixture-of-experts/) - ููุดูุฑุงุช ุงููุฏููุฉ: [1](https://www.microsoft.com/en-us/research/blog/deepspeed-powers-8x-larger-moe-model-training-with-high-performance/)ุ [2](https://www.microsoft.com/en-us/research/publication/scalable-and-efficient-moe-training-for-multitask-multilingual-models/)ุ ููุดุฑ ูุญุฏุฏ ูุน ููุงุฐุฌ ุชูููุฏ ุงููุบุฉ ุงูุทุจูุนูุฉ ุงููุจูุฑุฉ ุงููุงุฆูุฉ ุนูู ุงููุญูู: [ููุดูุฑ ุงููุฏููุฉ](https://www.deepspeed.ai/2021/12/09/deepspeed-moe-nlg.html)ุ [ูุฑุน ููุบุงุชูุฑู-ุฏูุจ ุณุจูุฏ](https://github.com/microsoft/Megatron-DeepSpeed/tree/moe-training).

## ุงุณุชุฎุฏุงู ุจุงู ุชูุฑุด ููุงูุชูุงู ุงูุฃุตูู ูุงูุชูุงู ููุงุด

ูููู ุฃูุถูุง ูู "ุจุงู ุชูุฑุด" [`torch.nn.functional.scaled_dot_product_attention`](https://pytorch.org/docs/master/generated/torch.nn.functional.scaled_dot_product_attention.html) (SDPA) ุงุณุชุฏุนุงุก "ููุงุด ุฃุชูุดู" ู"ููุฑููุฒ" ุงูุงูุชูุงู ุจููุงุกุฉ ุงูุฐุงูุฑุฉ ุชุญุช ุงูุบุทุงุก. ููุฌุฑู ุญุงูููุง ุฅุถุงูุฉ ุฏุนู SDPA ุจุดูู ุฃุตูู ูู "ุชุฑุงูุณููุฑูุฑุฒ" ููุชู ุงุณุชุฎุฏุงูู ุจุดูู ุงูุชุฑุงุถู ูู `torch>=2.1.1` ุนูุฏ ุชููุฑ ุงูุชูููุฐ. ูุฑุฌู ุงูุฑุฌูุน ุฅูู [ููุชุฌ ุจุงู ุชูุฑุด ุงูููุนุฏ ูุณุจููุง](https://huggingface.co/docs/transformers/perf_infer_gpu_one#pytorch-scaled-dot-product-attention) ููุญุตูู ุนูู ูุงุฆูุฉ ุจุงูููุงุฐุฌ ุงููุฏุนููุฉ ูุงููุฒูุฏ ูู ุงูุชูุงุตูู.

ุชููุฏ ูุฐุง [ุงูููุดูุฑ](https://pytorch.org/blog/out-of-the-box-acceleration/) ููุนุฑูุฉ ุงููุฒูุฏ ุญูู ุงูุชุณุฑูุน ููููุฑุงุช ุงูุฐุงูุฑุฉ ูุน SDPA.