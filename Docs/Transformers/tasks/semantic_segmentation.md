## ุงูุชูุทูุน ุงูุตูุฑู

ุชูุตู ููุงุฐุฌ ุงูุชูุทูุน ุงูุตูุฑู ุงูููุงุทู ุงูุชู ุชุชูุงูู ูุน ููุงุทู ูุฎุชููุฉ ุฐุงุช ุฃูููุฉ ูู ุตูุฑุฉ. ุชุนูู ูุฐู ุงูููุงุฐุฌ ุนู ุทุฑูู ุชุนููู ุชุณููุฉ ููู ุจูุณู. ููุงู ุนุฏุฉ ุฃููุงุน ูู ุงูุชูุทูุน: ุงูุชูุทูุน ุงูุฏูุงููุ ูุชูุทูุน ุงููุซููุ ูุงูุชูุทูุน ุงูุดุงูู.

ูู ูุฐุง ุงูุฏูููุ ุณูู:

1. [ุฅููุงุก ูุธุฑุฉ ุนูู ุฃููุงุน ูุฎุชููุฉ ูู ุงูุชูุทูุน](#ุฃููุงุน-ุงูุชูุทูุน).
2. [ูุฏูู ูุซุงู ุดุงูู ูุถุจุท ุฏููู ูุชูุทูุน ุฏูุงูู](#ุถุจุท-ุฏููู-ููููุฐุฌ-ูู-ุฃุฌู-ุงูุชูุทูุน).

ูุจู ุฃู ุชุจุฏุฃุ ุชุฃูุฏ ูู ุชุซุจูุช ุฌููุน ุงูููุชุจุงุช ุงูุถุฑูุฑูุฉ:

```py
# ูู ุจุฅูุบุงุก ุงูุชุนููู ูุชุซุจูุช ุงูููุชุจุงุช ุงูุถุฑูุฑูุฉ
!pip install -q datasets transformers evaluate accelerate
```

ูุญู ูุดุฌุนู ุนูู ุชุณุฌูู ุงูุฏุฎูู ุฅูู ุญุณุงุจู ูู Hugging Face ุญุชู ุชุชููู ูู ุชุญููู ููุดุงุฑูุฉ ูููุฐุฌู ูุน ุงููุฌุชูุน. ุนูุฏูุง ููุทูุจ ููู ุฐููุ ุฃุฏุฎู ุฑูุฒู ููุชุณุฌูู:

```py
>>> from huggingface_hub import notebook_login

>>> notebook_login()
```

## ุฃููุงุน ุงูุชูุทูุน

ูุนูู ุงูุชูุทูุน ุงูุฏูุงูู ุชุณููุฉ ุฃู ูุฆุฉ ููู ุจูุณู ูู ุตูุฑุฉ. ุฏุนููุง ูููู ูุธุฑุฉ ุนูู ุฅุฎุฑุงุฌ ูููุฐุฌ ุงูุชูุทูุน ุงูุฏูุงูู. ุณูู ูููู ุจุชุนููู ููุณ ุงููุฆุฉ ููู ูุซูู ูู ูุงุฆู ูุตุงุฏูู ูู ุตูุฑุฉุ ุนูู ุณุจูู ุงููุซุงูุ ุณูุชู ุชุตููู ุฌููุน ุงููุทุท ุนูู ุฃููุง "ูุทุฉ" ุจุฏูุงู ูู "ูุทุฉ-1"ุ "ูุทุฉ-2".

ูููููุง ุงุณุชุฎุฏุงู ุฎุท ุฃูุงุจูุจ ุงูุชูุทูุน ุงูุตูุฑู ูู ุงููุญููุงุช ููุชูุจุค ุจุณุฑุนุฉ ุจูููุฐุฌ ุงูุชูุทูุน ุงูุฏูุงูู. ุฏุนููุง ูููู ูุธุฑุฉ ุนูู ุตูุฑุฉ ุงููุซุงู.

```python
from transformers import pipeline
from PIL import Image
import requests

url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/segmentation_input.jpg"
image = Image.open(requests.get(url, stream=True).raw)
image
```

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/segmentation_input.jpg" alt="ุฅุฏุฎุงู ุงูุชูุทูุน"/>
</div>

ุณูุณุชุฎุฏู [nvidia/segformer-b1-finetuned-cityscapes-1024-1024](https://huggingface.co/nvidia/segformer-b1-finetuned-cityscapes-1024-1024).

```python
semantic_segmentation = pipeline("image-segmentation", "nvidia/segformer-b1-finetuned-cityscapes-1024-1024")
results = semantic_segmentation(image)
results
```

ูุดูู ุฅุฎุฑุงุฌ ุฎุท ุฃูุงุจูุจ ุงูุชูุทูุน ููุงุนูุง ููู ูุฆุฉ ูุชููุนุฉ.

```bash
[{'score': None,
'label': 'road',
'mask': <PIL.Image.Image image mode=L size=612x415>},
{'score': None,
'label': 'sidewalk',
'mask': <PIL.Image.Image image mode=L size=612x415>},
{'score': None,
'label': 'building',
'mask': <PIL.Image.Image image mode=L size=612x415>},
{'score': None,
'label': 'wall',
'mask': <PIL.Image.Image image mode=L size=612x415>},
{'score': None,
'label': 'pole',
'mask': <PIL.Image.Image image mode=L size=612x415>},
{'score': None,
'label': 'traffic sign',
'mask': <PIL.Image.Image image mode=L size=612x415>},
{'score': None,
'label': 'vegetation',
'mask': <PIL.Image.Image image mode=L size=612x415>},
{'score': None,
'label': 'terrain',
'mask': <PIL.Image.Image image mode=L size=612x415>},
{'score': None,
'label': 'sky',
'mask': <PIL.Image.Image image mode=L size=612x415>},
{'score': None,
'label': 'car',
'mask': <PIL.Image.Image image mode=L size=612x415>}]
```

ุนูุฏ ุงููุธุฑ ุฅูู ุงูููุงุน ููุฆุฉ ุงูุณูุงุฑุฉุ ูููููุง ุฃู ูุฑู ุฃู ูู ุณูุงุฑุฉ ูุตููุฉ ุจููุณ ุงูููุงุน.

```python
results[-1]["mask"]
```

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/semantic_segmentation_output.png" alt="ุฅุฎุฑุงุฌ ุงูุชูุทูุน ุงูุฏูุงูู"/>
</div>

ูู ุชูุทูุน ูุซููุ ุงููุฏู ููุณ ุชุตููู ูู ุจูุณูุ ูููู ุงูุชูุจุค ุจููุงุน ููู **ูุซูู ูู ูุงุฆู** ูู ุตูุฑุฉ ูุนููุฉ. ุฅูู ูุนูู ุจุดูู ูุดุงุจู ุฌุฏูุง ูููุดู ุนู ุงูุฃุดูุงุกุ ุญูุซ ููุฌุฏ ูุฑุจุน ุญุฏ ููู ูุซููุ ูููุงู ููุงุน ุชูุทูุน ุจุฏูุงู ูู ุฐูู. ุณูุณุชุฎุฏู [facebook/mask2former-swin-large-cityscapes-instance](https://huggingface.co/facebook/mask2former-swin-large-cityscapes-instance) ููุฐุง ุงูุบุฑุถ.

```python
instance_segmentation = pipeline("image-segmentation", "facebook/mask2former-swin-large-cityscapes-instance")
results = instance_segmentation(image)
results
```

ููุง ุชุฑูู ุฃุฏูุงูุ ููุงู ุงูุนุฏูุฏ ูู ุงูุณูุงุฑุงุช ุงููุตููุฉุ ููุง ููุฌุฏ ุชุตููู ููุจูุณูุงุช ุจุฎูุงู ุงูุจูุณูุงุช ุงูุชู ุชูุชูู ุฅูู ุณูุงุฑุฉ ููุซููุงุช ุงูุฃุดุฎุงุต.

```bash
[{'score': 0.999944,
'label': 'car',
'mask': <PIL.Image.Image image mode=L size=612x415>},
{'score': 0.999945,
'label': 'car',
'mask': <PIL.Image.Image image mode=L size=612x415>},
{'score': 0.999652,
'label': 'car',
'mask': <PIL.Image.Image image mode=L size=612x415>},
{'score': 0.903529,
'label': 'person',
'mask': <PIL.Image.Image image mode=L size=612x415>}]
```

ุชููุฏ ุฅุญุฏู ุฃููุนุฉ ุงูุณูุงุฑุงุช ุฃุฏูุงู.

```python
results[2]["mask"]
```

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/instance_segmentation_output.png" alt="ุฅุฎุฑุงุฌ ุงูุชูุทูุน ุงูุฏูุงูู"/>
</div>

ููุฏูุฌ ุงูุชูุทูุน ุงูุดุงูู ุจูู ุงูุชูุทูุน ุงูุฏูุงูู ูุชูุทูุน ุงููุซููุ ุญูุซ ูุชู ุชุตููู ูู ุจูุณู ุฅูู ูุฆุฉ ููุซูู ูู ุชูู ุงููุฆุฉุ ูููุงู ุฃููุนุฉ ูุชุนุฏุฏุฉ ููู ูุซูู ูู ูุฆุฉ. ูููููุง ุงุณุชุฎุฏุงู [facebook/mask2former-swin-large-cityscapes-panoptic](https://huggingface.co/facebook/mask2former-swin-large-cityscapes-panoptic) ููุฐุง ุงูุบุฑุถ.

```python
panoptic_segmentation = pipeline("image-segmentation", "facebook/mask2former-swin-large-cityscapes-panoptic")
results = panoptic_segmentation(image)
results
```

ููุง ุชุฑูู ุฃุฏูุงูุ ูุฏููุง ุงููุฒูุฏ ูู ุงููุฆุงุช. ุณูููู ูุงุญููุง ุจุชูุถูุญ ุฃู ูู ุจูุณู ูุตูู ุฅูู ูุงุญุฏุฉ ูู ุงููุฆุงุช.

```bash
[{'score': 0.999981,
'label': 'car',
'mask': <PIL.Image.Image image mode=L size=612x415>},
{'score': 0.999958,
'label': 'car',
'mask': <PIL.Image.Image image mode=L size=612x415>},
{'score': 0.99997,
'label': 'vegetation',
'mask': <PIL.Image.Image image mode=L size=612x415>},
{'score': 0.999575,
'label': 'pole',
'mask': <PIL.Image.Image image mode=L size=612x415>},
{'score': 0.999958,
'label': 'building',
'mask': <PIL.Image.Image image mode=L size=612x415>},
{'score': 0.999634,
'label': 'road',
'mask': <PIL.Image.Image image mode=L size=612x415>},
{'score': 0.996092,
'label': 'sidewalk',
'mask': <PIL.Image.Image image mode=L size=612x415>},
{'score': 0.999221,
'label': 'car',
'mask': <PIL.Image.Image image mode=L size=612x415>},
{'score': 0.99987,
'label': 'sky',
'mask': <PIL.Image.Image image mode=L size=612x415>}]
```

ุฏุนููุง ููุงุฑู ุฌูุจุง ุฅูู ุฌูุจ ุฌููุน ุฃููุงุน ุงูุชูุทูุน.

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/segmentation-comparison.png" alt="ุฎุฑุงุฆุท ุงูุชูุทูุน ููุงุฑูุฉ"/>
</div>

ุจุนุฏ ุฑุคูุฉ ุฌููุน ุฃููุงุน ุงูุชูุทูุนุ ุฏุนููุง ูุชุนูู ูู ุถุจุท ุฏููู ููููุฐุฌ ูู ุฃุฌู ุงูุชูุทูุน ุงูุฏูุงูู.

ุชุดูู ุงูุชุทุจููุงุช ุงููุงูุนูุฉ ุงูุดุงุฆุนุฉ ููุชูุทูุน ุงูุฏูุงูู ุชุฏุฑูุจ ุงูุณูุงุฑุงุช ุฐุงุชูุฉ ุงูููุงุฏุฉ ุนูู ุงูุชุนุฑู ุนูู ุงููุดุงุฉ ููุนูููุงุช ุงููุฑูุฑ ุงููููุฉุ ูุชุญุฏูุฏ ุงูุฎูุงูุง ูุงูุชุดููุงุช ูู ุงูุตูุฑ ุงูุทุจูุฉุ ูุฑุตุฏ ุงูุชุบูุฑุงุช ุงูุจูุฆูุฉ ูู ุตูุฑ ุงูุฃููุงุฑ ุงูุตูุงุนูุฉ.

## ุถุจุท ุฏููู ููููุฐุฌ ูู ุฃุฌู ุงูุชูุทูุน

ุณูููู ุงูุขู ุจูุง ููู:

1. ุถุจุท ุฏููู [SegFormer](https://huggingface.co/docs/transformers/main/en/model_doc/segformer#segformer) ุนูู ูุฌููุนุฉ ุจูุงูุงุช [SceneParse150](https://huggingface.co/datasets/scene_parse_150).
2. ุงุณุชุฎุฏุงู ูููุฐุฌู ุงููุถุจูุท ุจุฏูุฉ ููุชูุจุค.

<Tip>

ูุฑุคูุฉ ุฌููุน ุงูููุฏุณุงุช ูููุงุท ุงูุชุญูู ุงููุชูุงููุฉ ูุน ูุฐู ุงููููุฉุ ููุตู ุจุงูุชุญูู ูู [ุตูุญุฉ ุงููููุฉ](https://huggingface.co/tasks/image-segmentation)

</Tip>
ุจุงูุชุฃููุฏุ ุณุฃุชุจุน ุชุนูููุงุชู ูุณุฃุชุฑุฌู ููุท ุงููุต ุงูููุฌูุฏ ูู ุงูููุฑุงุช ูุงูุนูุงูููุ ูุน ุชุฌุงูู ุงููุตูุต ุงูุจุฑูุฌูุฉ ูุฑูุงุจุท ุงูุฑููุฒ.

### ุชุญููู ูุฌููุนุฉ ุจูุงูุงุช SceneParse150

ุงุจุฏุฃ ุจุชุญููู ูุฌููุนุฉ ูุฑุนูุฉ ุฃุตุบุฑ ูู ูุฌููุนุฉ ุจูุงูุงุช SceneParse150 ูู ููุชุจุฉ Datasets ุงูุฎุงุตุฉ ุจู ๐ค. ุณูุชูุญ ูู ุฐูู ุงููุฑุตุฉ ููุชุฌุฑุจุฉ ูุงูุชุฃูุฏ ูู ุฃู ูู ุดูุก ูุนูู ูุจู ุฅููุงู ุงููุฒูุฏ ูู ุงูููุช ูู ุงูุชุฏุฑูุจ ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงููุงููุฉ.

ูู ุจุชูุณูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงููููุณูุฉ ุนูู 'train' ูู ูุฌููุนุฉ ุจูุงูุงุช ุงูุชุฏุฑูุจ ูุงูุงุฎุชุจุงุฑ ุจุงุณุชุฎุฏุงู ุทุฑููุฉ Dataset.train_test_split:

ุจุนุฏ ุฐููุ ุงูู ูุธุฑุฉ ุนูู ูุซุงู:

- "image": ุตูุฑุฉ PIL ูููุดูุฏ.
- "annotation": ุตูุฑุฉ PIL ูุฎุฑูุทุฉ ุงูุชุฌุฒุฆุฉุ ูุงูุชู ุชุนุฏ ุฃูุถูุง ูุฏู ุงููููุฐุฌ.
- "scene_category": ูุนุฑู ูุฆุฉ ูุตู ูุดูุฏ ุงูุตูุฑุฉ ูุซู "ุงููุทุจุฎ" ุฃู "ุงูููุชุจ". ูู ูุฐุง ุงูุฏูููุ ุณุชุญุชุงุฌ ููุท ุฅูู "ุงูุตูุฑุฉ" ู"ุงูุชุณููุฉ ุงูุชูุถูุญูุฉ"ุ ูููุงููุง ุตูุฑ PIL.

ููุง ุชุฑูุฏ ุฅูุดุงุก ูุงููุณ ูููู ุจุชุนููู ูุนุฑู ุงูุชุณููุฉ ุงูุชูุถูุญูุฉ ุฅูู ูุฆุฉ ุงูุชุณููุฉ ุงูุชูุถูุญูุฉุ ูุงูุชู ุณุชููู ูููุฏุฉ ุนูุฏ ุฅุนุฏุงุฏ ุงููููุฐุฌ ูุงุญููุง. ูู ุจุชูุฒูู ุงูุชุนูููุงุช ูู Hub ูุฅูุดุงุก ุงูููุงููุณ id2label ูlabel2id:

### ูุฌููุนุฉ ุจูุงูุงุช ูุฎุตุตุฉ

ููููู ุฃูุถูุง ุฅูุดุงุก ูุฌููุนุฉ ุจูุงูุงุชู ุงูุฎุงุตุฉ ุฅุฐุง ููุช ุชูุถู ุงูุชุฏุฑูุจ ุจุงุณุชุฎุฏุงู ุงูุจุฑูุงูุฌ ุงููุตู run_semantic_segmentation.py ุจุฏูุงู ูู ูุซูู ุฏูุชุฑ ุงูููุงุญุธุงุช. ูุชุทูุจ ุงูุจุฑูุงูุฌ ุงููุตู ูุง ููู:

1. DatasetDict ุจู Dataset ูุน ุนููุฏูู Imageุ "image" ู"label".

2. ูุงููุณ id2label ูููู ุจุชุนููู ุฃุนุฏุงุฏ ุตุญูุญุฉ ูููุฆุฉ ุฅูู ุฃุณูุงุก ูุฆุงุชูุง.

ูููุซุงู ุนูู ุฐููุ ุงูู ูุธุฑุฉ ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช ูุฐู ุงูุชู ุชู ุฅูุดุงุคูุง ุจุงุณุชุฎุฏุงู ุงูุฎุทูุงุช ุงูููุถุญุฉ ุฃุนูุงู.

### ูุนุงูุฌุฉ ูุณุจูุฉ

ุงูุฎุทูุฉ ุงูุชุงููุฉ ูู ุชุญููู ูุนุงูุฌ ุตูุฑ SegFormer ูุฅุนุฏุงุฏ ุงูุตูุฑ ูุงูุชุนูููุงุช ุงูุชูุถูุญูุฉ ูููููุฐุฌ. ุชุณุชุฎุฏู ุจุนุถ ูุฌููุนุงุช ุงูุจูุงูุงุชุ ูุซู ูุฐูุ ุงูููุฑุณ ุตูุฑ ููุฆุฉ ุฎูููุฉ. ููุน ุฐููุ ูุฅู ูุฆุฉ ุงูุฎูููุฉ ุบูุฑ ูุฏุฑุฌุฉ ุจุงููุนู ูู 150 ูุฆุฉุ ูุฐูู ุณุชุญุชุงุฌ ุฅูู ุชุนููู do_reduce_labels=True ูุทุฑุญ ูุงุญุฏ ูู ุฌููุน ุงูุชุณููุงุช ุงูุชูุถูุญูุฉ. ูุชู ุงุณุชุจุฏุงู ุงูููุฑุณ ุตูุฑ ุจู 255 ุญุชู ูุชู ุชุฌุงููู ุจูุงุณุทุฉ ุฏุงูุฉ ุงูุฎุณุงุฑุฉ ูู SegFormer:

<frameworkcontent>
<pt>
ูู ุงูุดุงุฆุน ุชุทุจูู ุจุนุถ ุนูููุงุช ุฒูุงุฏุฉ ุงูุจูุงูุงุช ุนูู ูุฌููุนุฉ ุจูุงูุงุช ุงูุตูุฑ ูุฌุนู ุงููููุฐุฌ ุฃูุซุฑ ููุฉ ุถุฏ ุงูุฅูุฑุงุท ูู ุงูุชูุงุฆู. ูู ูุฐุง ุงูุฏูููุ ุณุชุณุชุฎุฏู ุฏุงูุฉ ColorJitter ูู torchvision ูุชุบููุฑ ุฎุตุงุฆุต ุงูุฃููุงู ููุตูุฑุฉ ุจุดูู ุนุดูุงุฆูุ ูููู ููููู ุฃูุถูุง ุงุณุชุฎุฏุงู ุฃู ููุชุจุฉ ุตูุฑ ุชูุถููุง.

ุงูุขูุ ูู ุจุฅูุดุงุก ุฏุงูุชูู ูููุนุงูุฌุฉ ุงููุณุจูุฉ ูุฅุนุฏุงุฏ ุงูุตูุฑ ูุงูุชุนูููุงุช ุงูุชูุถูุญูุฉ ูููููุฐุฌ. ุชููู ูุฐู ุงูุฏูุงู ุจุชุญููู ุงูุตูุฑ ุฅูู "pixel_values" ูุงูุชุนูููุงุช ุงูุชูุถูุญูุฉ ุฅูู "labels". ุจุงููุณุจุฉ ููุฌููุนุฉ ุจูุงูุงุช ุงูุชุฏุฑูุจุ ูุชู ุชุทุจูู "jitter" ูุจู ุชูููุฑ ุงูุตูุฑ ููุนุงูุฌ ุงูุตูุฑ. ุจุงููุณุจุฉ ููุฌููุนุฉ ุงูุงุฎุชุจุงุฑุ ูููู ูุนุงูุฌ ุงูุตูุฑ ุจุงูุชุตุงุต ูุชุทุจูุน "ุงูุตูุฑ"ุ ููููู ููุท ุจุงูุชุตุงุต "ุงูุชุณููุงุช" ูุฃู ุฒูุงุฏุฉ ุงูุจูุงูุงุช ูุง ูุชู ุชุทุจูููุง ุฃุซูุงุก ุงูุงุฎุชุจุงุฑ.

ูุชุทุจูู "jitter" ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุจุฃููููุงุ ุงุณุชุฎุฏู ูุธููุฉ Dataset.set_transform ูู ููุชุจุฉ Datasets:

</pt>
</frameworkcontent>

<frameworkcontent>
<tf>
ูู ุงูุดุงุฆุน ุชุทุจูู ุจุนุถ ุนูููุงุช ุฒูุงุฏุฉ ุงูุจูุงูุงุช ุนูู ูุฌููุนุฉ ุจูุงูุงุช ุงูุตูุฑ ูุฌุนู ุงููููุฐุฌ ุฃูุซุฑ ููุฉ ุถุฏ ุงูุฅูุฑุงุท ูู ุงูุชูุงุฆู. ูู ูุฐุง ุงูุฏูููุ ุณุชุณุชุฎุฏู ูุญุฏุฉ tf.image ูุชุบููุฑ ุฎุตุงุฆุต ุงูุฃููุงู ููุตูุฑุฉ ุจุดูู ุนุดูุงุฆูุ ูููู ููููู ุฃูุถูุง ุงุณุชุฎุฏุงู ุฃู ููุชุจุฉ ุตูุฑ ุชูุถููุง.

ูู ุจุชุนุฑูู ุฏุงูุชูู ููุชุญููู ูููุตูุชูู:

- ุชุญูููุงุช ุจูุงูุงุช ุงูุชุฏุฑูุจ ุงูุชู ุชุชุถูู ุฒูุงุฏุฉ ุงูุตูุฑ
- ุชุญูููุงุช ุจูุงูุงุช ุงูุชุญูู ุงูุชู ุชููู ููุท ุจุชุฑุงูุฒุณุชูุฑ ุงูุตูุฑุ ูุธุฑูุง ูุฃู ููุงุฐุฌ ุงูุฑุคูุฉ ุงูุญุงุณูุจูุฉ ูู ๐ค Transformers ุชุชููุน ุชุฎุทูุท ุงููููุงุช ุฃููุงู

ูู ุจุนุฏ ุฐูู ุจุฅูุดุงุก ุฏุงูุชูู ูููุนุงูุฌุฉ ุงููุณุจูุฉ ูุฅุนุฏุงุฏ ุฏูุนุงุช ุงูุตูุฑ ูุงูุชุนูููุงุช ุงูุชูุถูุญูุฉ ูููููุฐุฌ. ุชููู ูุฐู ุงูุฏูุงู ุจุชุทุจูู ุชุญูููุงุช ุงูุตูุฑ ูุงุณุชุฎุฏุงู ูุนุงูุฌ ุงูุตูุฑ ุงููุญูู ุณุงุจููุง ูุชุญููู ุงูุตูุฑ ุฅูู "pixel_values" ูุงูุชุนูููุงุช ุงูุชูุถูุญูุฉ ุฅูู "labels". ููุง ูุชููู ูุนุงูุฌ ุงูุตูุฑ ุฃูุถูุง ูุณุคูููุฉ ุชุบููุฑ ุญุฌู ุงูุตูุฑ ูุชุทุจูุนูุง.

ูุชุทุจูู ุชุญูููุงุช ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุจุฃููููุงุ ุงุณุชุฎุฏู ูุธููุฉ Dataset.set_transform ูู ููุชุจุฉ Datasets:

</tf>
</frameworkcontent>
### ุชูููู

ุบุงูุจูุง ูุง ูููู ุชุถููู ูููุงุณ ุฃุซูุงุก ุงูุชุฏุฑูุจ ูููุฏูุง ูุชูููู ุฃุฏุงุก ุงููููุฐุฌ. ููููู ุชุญููู ุทุฑููุฉ ุชูููู ุจุณุฑุนุฉ ุจุงุณุชุฎุฏุงู ููุชุจุฉ [Evaluate](https://huggingface.co/docs/evaluate/index) ูู ๐ค . ุจุงููุณุจุฉ ููุฐู ุงููููุฉุ ูู ุจุชุญููู ูููุงุณ [ูุชูุณุท Intersection over Union](https://huggingface.co/spaces/evaluate-metric/accuracy) (IoU) (ุฑุงุฌุน ุงูุฌููุฉ ุงูุณุฑูุนุฉ ูู ๐ค Evaluate [quick tour](https://huggingface.co/docs/evaluate/a_quick_tour) ููุนุฑูุฉ ุงููุฒูุฏ ุญูู ููููุฉ ุชุญููู ูุญุณุงุจ ูููุงุณ):

```py
>>> import evaluate

>>> metric = evaluate.load("mean_iou")
```

ุซู ูู ุจุฅูุดุงุก ุฏุงูุฉ ูู [`~evaluate.EvaluationModule.compute`] metrics. ูุฌุจ ุชุญููู ุชูุจุคุงุชู ุฅูู logits ุฃููุงูุ ุซู ุฅุนุงุฏุฉ ุชุดููููุง ููุทุงุจูุฉ ุญุฌู ุงูุชุณููุงุช ูุจู ุฃู ุชุชููู ูู ุงุณุชุฏุนุงุก [`~evaluate.EvaluationModule.compute`]:

<frameworkcontent>
<pt>

```py
>>> import numpy as np
>>> import torch
>>> from torch import nn

>>> def compute_metrics(eval_pred):
    with torch.no_grad():
        logits, labels = eval_pred
        logits_tensor = torch.from_numpy(logits)
        logits_tensor = nn.functional.interpolate(
            logits_tensor,
            size=labels.shape[-2:],
            mode="bilinear",
            align_corners=False,
        ).argmax(dim=1)

        pred_labels = logits_tensor.detach().cpu().numpy()
        metrics = metric.compute(
            predictions=pred_labels,
            references=labels,
            num_labels=num_labels,
            ignore_index=255,
            reduce_labels=False,
        )
        for key, value in metrics.items():
            if isinstance(value, np.ndarray):
                metrics[key] = value.tolist()
        return metrics
```

</pt>
</frameworkcontent>

<frameworkcontent>
<tf>

```py
>>> def compute_metrics(eval_pred):
    logits, labels = eval_pred
    logits = tf.transpose(logits, perm=[0, 2, 3, 1])
    logits_resized = tf.image.resize(
        logits,
        size=tf.shape(labels)[1:],
        method="bilinear",
    )

    pred_labels = tf.argmax(logits_resized, axis=-1)
    metrics = metric.compute(
        predictions=pred_labels,
        references=labels,
        num_labels=num_labels,
        ignore_index=-1,
        reduce_labels=image_processor.do_reduce_labels,
    )

    per_category_accuracy = metrics.pop("per_category_accuracy").tolist()
    per_category_iou = metrics.pop("per_category_iou").tolist()

    metrics.update({f"accuracy_{id2label[i]}": v for i, v in enumerate(per_category_accuracy)})
    metrics.update({f"iou_{id2label[i]}": v for i, v in enumerate(per_category_iou)})
    return {"val_" + k: v for k, v in metrics.items()}
```

</tf>
</frameworkcontent>

ุงูุขูุ ุฃุตุจุญุช ุฏุงูุฉ `compute_metrics` ุงูุฎุงุตุฉ ุจู ุฌุงูุฒุฉ ููุงุณุชุฎุฏุงูุ ูุณุชุนูุฏ ุฅูููุง ุนูุฏ ุฅุนุฏุงุฏ ุงูุชุฏุฑูุจ.

### ุชุฏุฑูุจ

<frameworkcontent>
<pt>

<Tip>

ุฅุฐุง ูู ุชูู ูุนุชุงุฏูุง ุนูู ุถุจุท ูููุฐุฌ ุจุงุณุชุฎุฏุงู [`Trainer`ุ]ุ ูุฑุงุฌุน ุงูุจุฑูุงูุฌ ุงูุชุนูููู ุงูุฃุณุงุณู [here](../training#finetune-with-trainer)!

</Tip>

ุฃูุช ุงูุขู ุนูู ุงุณุชุนุฏุงุฏ ูุจุฏุก ุชุฏุฑูุจ ูููุฐุฌู! ูู ุจุชุญููู SegFormer ุจุงุณุชุฎุฏุงู [`AutoModelForSemanticSegmentation`]ุ ููุฑุฑ ุฅูู ุงููููุฐุฌ ุงูุฎุฑูุทุฉ ุจูู ูุนุฑูุงุช ุงูุชุณููุงุช ููุฆุงุช ุงูุชุณููุงุช:

```py
>>> from transformers import AutoModelForSemanticSegmentation, TrainingArguments, Trainer

>>> model = AutoModelForSemanticSegmentation.from_pretrained(checkpoint, id2label=id2label, label2id=label2id)
```

ูู ูุฐู ุงููุฑุญูุฉุ ูู ูุชุจู ุณูู ุซูุงุซ ุฎุทูุงุช:

1. ุญุฏุฏ ูุฑุท ูุนููุงุช ุงูุชุฏุฑูุจ ุงูุฎุงุตุฉ ุจู ูู [`TrainingArguments`]. ูู ุงูููู ุฃูุง ุชููู ุจุฅุฒุงูุฉ ุงูุฃุนูุฏุฉ ุบูุฑ ุงููุณุชุฎุฏูุฉ ูุฃู ูุฐุง ุณูุคุฏู ุฅูู ุฅุณูุงุท ุนููุฏ "ุงูุตูุฑุฉ". ุจุฏูู ุนููุฏ "ุงูุตูุฑุฉ"ุ ูุง ููููู ุฅูุดุงุก `pixel_values`. ูู ุจุชุนููู `remove_unused_columns=False` ูููุน ูุฐุง ุงูุณููู! ุงูุญุฌุฉ ุงููุทููุจุฉ ุงููุญูุฏุฉ ุงูุฃุฎุฑู ูู `output_dir` ุงูุชู ุชุญุฏุฏ ุฃูู ูุชู ุญูุธ ูููุฐุฌู. ุณุชููู ุจุงูุฏูุน ุจูุฐุง ุงููููุฐุฌ ุฅูู Hub ุนู ุทุฑูู ุชุนููู `push_to_hub=True` (ูุฌุจ ุฃู ุชููู ูุณุฌูุงู ุงูุฏุฎูู ุฅูู Hugging Face ูุชุญููู ูููุฐุฌู). ูู ููุงูุฉ ูู ุญูุจุฉุ ุณูููู [`Trainer`] ุจุชูููู ูููุงุณ IoU ูุญูุธ ููุทุฉ ุงูุชุญูู ุงูุชุฏุฑูุจูุฉ.

2. ูุฑุฑ ุงูุญุฌุฌ ุงูุชุฏุฑูุจูุฉ ุฅูู [`Trainer`] ุฅูู ุฌุงูุจ ุงููููุฐุฌ ููุฌููุนุฉ ุงูุจูุงูุงุช ูุงููุญูู ุงููุบูู ููุฌูุน ุงูุจูุงูุงุช ู `compute_metrics` function.

3. ุงุณุชุฏุนุงุก [`~Trainer.train`] ูุถุจุท ูููุฐุฌู.

```py
>>> training_args = TrainingArguments(
    output_dir="segformer-b0-scene-parse-150",
    learning_rate=6e-5,
    num_train_epochs=50,
    per_device_train_batch_size=2,
    per_device_eval_batch_size=2,
    save_total_limit=3,
    eval_strategy="steps",
    save_strategy="steps",
    save_steps=20,
    eval_steps=20,
    logging_steps=1,
    eval_accumulation_steps=5,
    remove_unused_columns=False,
    push_to_hub=True,
)

>>> trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_ds,
    eval_dataset=test_ds,
    compute_metrics=compute_metrics,
)

>>> trainer.train()
```

ุจูุฌุฑุฏ ุงูุชูุงู ุงูุชุฏุฑูุจุ ุดุงุฑู ูููุฐุฌู ุนูู Hub ุจุงุณุชุฎุฏุงู ุทุฑููุฉ [`~transformers.Trainer.push_to_hub`] ุญุชู ูุชููู ุงูุฌููุน ูู ุงุณุชุฎุฏุงู ูููุฐุฌู:

```py
>>> trainer.push_to_hub()
```

</pt>
</frameworkcontent>

<frameworkcontent>
<tf>

<Tip>

ุฅุฐุง ูู ุชูู ูุนุชุงุฏูุง ุนูู ุถุจุท ูููุฐุฌ ุจุงุณุชุฎุฏุงู Kerasุ ูุฑุงุฌุน ุงูุจุฑูุงูุฌ ุงูุชุนูููู ุงูุฃุณุงุณู [basic tutorial](./training#train-a-tensorflow-model-with-keras) ุฃููุงู!

</Tip>

ูุถุจุท ูููุฐุฌ ูู TensorFlowุ ุงุชุจุน ุงูุฎุทูุงุช ุงูุชุงููุฉ:

1. ุญุฏุฏ ูุฑุท ูุนููุงุช ุงูุชุฏุฑูุจุ ููู ุจุฅุนุฏุงุฏ ูุญุณู ูุฌุฏูู ูุนุฏู ุงูุชุนูู.

2. ูู ุจุชุญููู ูููุฐุฌ ูุณุจู ุงูุชุฏุฑูุจ.

3. ูู ุจุชุญููู ูุฌููุนุฉ ุจูุงูุงุช ๐ค ุฅูู ุชูุณูู `tf.data.Dataset`.

4. ูู ุจุชุฌููุน ูููุฐุฌู.

5. ุฃุถู ุงุณุชุฏุนุงุกุงุช ููุฑุฌูุน ุฅูู ุงูุฎูู ูุญุณุงุจ ุงูููุงููุณ ูุชุญููู ูููุฐุฌู ุฅูู ๐ค Hub

6. ุงุณุชุฎุฏู ุทุฑููุฉ `fit()` ูุชุดุบูู ุงูุชุฏุฑูุจ.

ุงุจุฏุฃ ุจุชุญุฏูุฏ ูุฑุท ุงููุนููุงุช ูุงููุญุณู ูุฌุฏูู ูุนุฏู ุงูุชุนูู:

```py
>>> from transformers import create_optimizer

>>> batch_size = 2
>>> num_epochs = 50
>>> num_train_steps = len(train_ds) * num_epochs
>>> learning_rate = 6e-5
>>> weight_decay_rate = 0.01

>>> optimizer, lr_schedule = create_optimizer(
    init_lr=learning_rate,
    num_train_steps=num_train_steps,
    weight_decay_rate=weight_decay_rate,
    num_warmup_steps=0,
)
```

ุจุนุฏ ุฐููุ ูู ุจุชุญููู SegFormer ุจุงุณุชุฎุฏุงู [`TFAutoModelForSemanticSegmentation`] ุฅูู ุฌุงูุจ ุชุนูููุงุช ุงูุชุณููุงุชุ ููู ุจุชุฌููุนูุง ุจุงุณุชุฎุฏุงู ุงููุญุณู. ูุงุญุธ ุฃู ุฌููุน ููุงุฐุฌ Transformers ุชุญุชูู ุนูู ุฏุงูุฉ ุฎุณุงุฑุฉ ุฐุงุช ุตูุฉ ุจุงููููุฉ ุจุดูู ุงูุชุฑุงุถูุ ูุฐูู ูุง ุชุญุชุงุฌ ุฅูู ุชุญุฏูุฏ ูุงุญุฏุฉ ูุง ูู ุชุฑุบุจ ูู ุฐูู:

```py
>>> from transformers import TFAutoModelForSemanticSegmentation

>>> model = TFAutoModelForSemanticSegmentation.from_pretrained(
    checkpoint,
    id2label=id2label,
    label2id=label2id,
)
>>> model.compile(optimizer=optimizer) # ูุง ุชูุฌุฏ ุญุฌุฉ ุงูุฎุณุงุฑุฉ!
```

ูู ุจุชุญููู ูุฌููุนุงุช ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจู ุฅูู ุชูุณูู `tf.data.Dataset` ุจุงุณุชุฎุฏุงู [`~datasets.Dataset.to_tf_dataset`] ู [`DefaultDataCollator`]:

```py
>>> from transformers import DefaultDataCollator

>>> data_collator = DefaultDataCollator(return_tensors="tf")

>>> tf_train_dataset = train_ds.to_tf_dataset(
    columns=["pixel_values", "label"],
    shuffle=True,
    batch_size=batch_size,
    collate_fn=data_collator,
)

>>> tf_eval_dataset = test_ds.to_tf_dataset(
    columns=["pixel_values", "label"],
    shuffle=True,
    batch_size=batch_size,
    collate_fn=data_collator,
)
```

ูุญุณุงุจ ุงูุฏูุฉ ูู ุงูุชูุจุคุงุช ูุชุญููู ูููุฐุฌู ุฅูู ๐ค Hubุ ุงุณุชุฎุฏู [Keras callbacks](../main_classes/keras_callbacks).

ูุฑุฑ ุฏุงูุฉ `compute_metrics` ุงูุฎุงุตุฉ ุจู ุฅูู [`KerasMetricCallback`]ุ
ูุงุณุชุฎุฏู [`PushToHubCallback`] ูุชุญููู ุงููููุฐุฌ:

```py
>>> from transformers.keras_callbacks import KerasMetricCallback, PushToHubCallback

>>> metric_callback = KerasMetricCallback(
    metric_fn=compute_metrics, eval_dataset=tf_eval_dataset, batch_size=batch_size, label_cols=["labels"]
)

>>> push_to_hub_callback = PushToHubCallback(output_dir="scene_segmentation", tokenizer=image_processor)

>>> callbacks = [metric_callback, push_to_hub_callback]
```

ุฃุฎูุฑูุงุ ุฃูุช ูุณุชุนุฏ ูุชุฏุฑูุจ ูููุฐุฌู! ุงุชุตู ุจู `fit()` ุจุงุณุชุฎุฏุงู ูุฌููุนุงุช ุงูุจูุงูุงุช ุงูุชุฏุฑูุจูุฉ ูุงูุชุญูู ูู ุตุญุชูุงุ ูุนุฏุฏ ุงูุนุตูุฑุ
ูุงุณุชุฏุนุงุกุงุช ุงูุฑุฌูุน ุงูุฎุงุตุฉ ุจู ูุถุจุท ุงููููุฐุฌ:

```py
>>> model.fit(
    tf_train_dataset,
    validation_data=tf_eval_dataset,
    callbacks=callbacks,
    epochs=num_epochs,
)
```

ุชูุงูููุง! ููุฏ ุถุจุทุช ูููุฐุฌู ูุดุงุฑูุชู ุนูู ๐ค Hub. ููููู ุงูุขู ุงุณุชุฎุฏุงูู ููุงุณุชูุชุงุฌ!

</tf>
</frameworkcontent>
### ุงูุงุณุชูุชุงุฌ
ุฑุงุฆุนุ ุงูุขู ุจุนุฏ ุฃู ููุช ุจุถุจุท ูููุฐุฌูุ ููููู ุงุณุชุฎุฏุงูู ููุงุณุชูุชุงุฌ!

ูู ุจุฅุนุงุฏุฉ ุชุญููู ูุฌููุนุฉ ุงูุจูุงูุงุช ูุชุญููู ุตูุฑุฉ ููุงุณุชูุชุงุฌ.

```python
>>> from datasets import load_dataset

>>> ds = load_dataset("scene_parse_150", split="train[:50]")
>>> ds = ds.train_test_split(test_size=0.2)
>>> test_ds = ds["test"]
>>> image = ds["test"][0]["image"]
>>> image
```

ุณูุฑู ุงูุขู ููููุฉ ุงูุงุณุชูุชุงุฌ ุจุฏูู ุฎุท ุฃูุงุจูุจ. ูู ุจูุนุงูุฌุฉ ุงูุตูุฑุฉ ุจุงุณุชุฎุฏุงู ูุนุงูุฌ ุงูุตูุฑ ููุถุน `pixel_values` ุนูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU):

```python
>>> device = torch.device("cuda" if torch.cuda.is_available() else "cpu") # ุงุณุชุฎุฏู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช ุฅุฐุง ูุงูุช ูุชููุฑุฉุ ูุฅูุง ุงุณุชุฎุฏู ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ
>>> encoding = image_processor(image, return_tensors="pt")
>>> pixel_values = encoding.pixel_values.to(device)
```

ูุฑุฑ ุงููุฏุฎูุงุช ุฅูู ุงููููุฐุฌ ูุฃุนุฏ `logits`:

```python
>>> outputs = model(pixel_values=pixel_values)
>>> logits = outputs.logits.cpu()
```

ุจุนุฏ ุฐููุ ูู ุจุฅุนุงุฏุฉ ุชุญุฌูู `logits` ุฅูู ุญุฌู ุงูุตูุฑุฉ ุงูุฃุตูู:

```python
>>> upsampled_logits = nn.functional.interpolate(
...     logits,
...     size=image.size[::-1],
...     mode="bilinear",
...     align_corners=False,
... )

>>> pred_seg = upsampled_logits.argmax(dim=1)[0]
```

ูู ุจุชุญููู ูุนุงูุฌ ุงูุตูุฑ ูุชุญุถูุฑ ุงูุตูุฑุฉ ูุฅุฑุฌุงุน ุงููุฏุฎูุงุช ุนูู ุฃููุง ุชูุงุธุฑุงุช TensorFlow:

```python
>>> from transformers import AutoImageProcessor

>>> image_processor = AutoImageProcessor.from_pretrained("MariaK/scene_segmentation")
>>> inputs = image_processor(image, return_tensors="tf")
```

ูุฑุฑ ุงููุฏุฎูุงุช ุฅูู ุงููููุฐุฌ ูุฃุนุฏ `logits`:

```python
>>> from transformers import TFAutoModelForSemanticSegmentation

>>> model = TFAutoModelForSemanticSegmentation.from_pretrained("MariaK/scene_segmentation")
>>> logits = model(**inputs).logits
```

ุจุนุฏ ุฐููุ ูู ุจุฅุนุงุฏุฉ ุชุญุฌูู `logits` ุฅูู ุญุฌู ุงูุตูุฑุฉ ุงูุฃุตูู ููู ุจุชุทุจูู `argmax` ุนูู ุงูุจุนุฏ ุงูุทุจูู:

```python
>>> logits = tf.transpose(logits, [0, 2, 3, 1])

>>> upsampled_logits = tf.image.resize(
...     logits,
...     # ูุนูุณ ุดูู `image` ูุฃู `image.size` ูุนูุฏ ุงูุนุฑุถ ูุงูุงุฑุชูุงุน.
...     image.size[::-1],
... )

>>> pred_seg = tf.math.argmax(upsampled_logits, axis=-1)[0]
```

ูุนุฑุถ ุงููุชุงุฆุฌุ ูู ุจุชุญููู ููุญุฉ ุฃููุงู ูุฌููุนุฉ ุงูุจูุงูุงุช ููุง ูู ููุถุญ ูู [ade_palette()] (https://github.com/tensorflow/models/blob/3f1ca33afe3c1631b733ea7e40c294273b9e406d/research/deeplab/utils/get_dataset_colormap.py#L51) ุงูุชู ุชููู ุจูุงุจ ูู ูุฆุฉ ุฅูู ููู RGB ุงูุฎุงุตุฉ ุจูุง.

```python
def ade_palette():
    return np.asarray([
        [0, 0, 0],
        [120, 120, 120],
        [180, 120, 120],
        [6, 230, 230],
        [80, 50, 50],
        [4, 200, 3],
        [120, 120, 80],
        [140, 140, 140],
        [204, 5, 255],
        [230, 230, 230],
        [4, 250, 7],
        [224, 5, 255],
        [235, 255, 7],
        [150, 5, 61],
        [120, 120, 70],
        [8, 255, 51],
        [255, 6, 82],
        [143, 255, 140],
        [204, 255, 4],
        [255, 51, 7],
        [204, 70, 3],
        [0, 102, 200],
        [61, 230, 250],
        [255, 6, 51],
        [11, 102, 255],
        [255, 7, 71],
        [255, 9, 224],
        [9, 7, 230],
        [220, 220, 220],
        [255, 9, 92],
        [112, 9, 255],
        [8, 255, 214],
        [7, 255, 224],
        [255, 184, 6],
        [10, 255, 71],
        [255, 41, 10],
        [7, 255, 255],
        [224, 255, 8],
        [102, 8, 255],
        [255, 61, 6],
        [255, 194, 7],
        [255, 122, 8],
        [0, 255, 20],
        [255, 8, 41],
        [255, 5, 153],
        [6, 51, 255],
        [235, 12, 255],
        [160, 150, 20],
        [0, 163, 255],
        [140, 140, 140],
        [250, 10, 15],
        [20, 255, 0],
        [31, 255, 0],
        [255, 31, 0],
        [255, 224, 0],
        [153, 255, 0],
        [0, 0, 255],
        [255, 71, 0],
        [0, 235, 255],
        [0, 173, 255],
        [31, 0, 255],
        [11, 200, 200],
        [255, 82, 0],
        [0, 255, 245],
        [0, 61, 255],
        [0, 255, 112],
        [0, 255, 133],
        [255, 0, 0],
        [255, 163, 0],
        [255, 102, 0],
        [194, 255, 0],
        [0, 143, 255],
        [51, 255, 0],
        [0, 82, 255],
        [0, 255, 41],
        [0, 255, 173],
        [10, 0, 255],
        [173, 255, 0],
        [0, 255, 153],
        [255, 92, 0],
        [255, 0, 255],
        [255, 0, 245],
        [255, 0, 102],
        [255, 173, 0],
        [255, 0, 20],
        [255, 184, 184],
        [0, 31, 255],
        [0, 255, 61],
        [0, 71, 255],
        [255, 0, 204],
        [0, 255, 194],
        [0, 255, 82],
        [0, 10, 255],
        [0, 112, 255],
        [51, 0, 255],
        [0, 194, 255],
        [0, 122, 255],
        [0, 255, 163],
        [255, 153, 0],
        [0, 255, 10],
        [255, 112, 0],
        [143, 255, 0],
        [82, 0, 255],
        [163, 255, 0],
        [255, 235, 0],
        [8, 184, 170],
        [133, 0, 255],
        [0, 255, 92],
        [184, 0, 255],
        [255, 0, 31],
        [0, 184, 255],
        [0, 214, 255],
        [255, 0, 112],
        [92, 255, 0],
        [0, 224, 255],
        [112, 224, 255],
        [70, 184, 160],
        [163, 0, 255],
        [153, 0, 0],
        [71, 255, 0],
        [255, 0, 163],
        [255, 204, 0],
        [255, 0, 143],
        [0, 255, 235],
        [133, 255, 0],
        [255, 0, 235],
        [245, 0, 255],
        [255, 0, 122],
        [255, 245, 0],
        [10, 190, 212],
        [214, 255, 0],
        [0, 204, 255],
        [20, 0, 255],
        [255, 255, 0],
        [0, 153, 255],
        [0, 41, 255],
        [0, 255, 204],
        [41, 0, 255],
        [41, 255, 0],
        [173, 0, 255],
        [0, 245, 255],
        [71, 0, 255],
        [122, 0, 255],
        [0, 255, 184],
        [0, 92, 255],
        [184, 255, 0],
        [0, 133, 255],
        [255, 214, 0],
        [25, 194, 194],
        [102, 255, 0],
        [92, 0, 255],
    ])
```

ุจุนุฏ ุฐููุ ููููู ุฏูุฌ ุฎุฑูุทุฉ ุงูุตูุฑุฉ ูุฎุฑูุทุฉ ุงูุชุฌุฒุฆุฉ ุงููุชููุนุฉ ูุนุฑุถููุง:

```python
>>> import matplotlib.pyplot as plt
>>> import numpy as np

>>> color_seg = np.zeros((pred_seg.shape[0], pred_seg.shape[1], 3), dtype=np.uint8)
>>> palette = np.array(ade_palette())
>>> for label, color in enumerate(palette):
...     color_seg[pred_seg == label, :] = color
>>> color_seg = color_seg[..., ::-1] # ุชุญููู ุฅูู BGR

>>> img = np.array(image) * 0.5 + color_seg * 0.5 # ุนุฑุถ ุงูุตูุฑุฉ ูุน ุฎุฑูุทุฉ ุงูุชุฌุฒุฆุฉ
>>> img = img.astype(np.uint8)

>>> plt.figure(figsize=(15, 10))
>>> plt.imshow(img)
>>> plt.show()
```