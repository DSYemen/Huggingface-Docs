## Ø§Ù„Ø§Ø®ØªÙŠØ§Ø± Ù…Ù† Ù…ØªØ¹Ø¯Ø¯

ØªØªØ´Ø§Ø¨Ù‡ Ù…Ù‡Ù…Ø© Ø§Ù„Ø§Ø®ØªÙŠØ§Ø± Ù…Ù† Ù…ØªØ¹Ø¯Ø¯ Ù…Ø¹ Ù…Ù‡Ù…Ø© Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©ØŒ Ø¨Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø£Ù†Ù‡ ÙŠØªÙ… ØªÙˆÙÙŠØ± Ø¹Ø¯Ø© Ø¥Ø¬Ø§Ø¨Ø§Øª Ù…Ø±Ø´Ø­Ø© Ø¥Ù„Ù‰ Ø¬Ø§Ù†Ø¨ Ø§Ù„Ø³ÙŠØ§Ù‚ØŒ ÙˆÙŠØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„ØµØ­ÙŠØ­Ø©.

Ø³ÙŠÙˆØ¶Ø­ Ù‡Ø°Ø§ Ø§Ù„Ø¯Ù„ÙŠÙ„ ÙƒÙŠÙÙŠØ©:

1. Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ BERT Ø§Ù„Ø¯Ù‚ÙŠÙ‚ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ‡ÙŠØ¦Ø© "Ø§Ù„Ø¹Ø§Ø¯ÙŠØ©" Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª SWAG Ù„Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ø¥Ø¬Ø§Ø¨Ø© Ù…Ù† Ø¨ÙŠÙ† Ø¹Ø¯Ø© Ø®ÙŠØ§Ø±Ø§Øª ÙˆØ³ÙŠØ§Ù‚ Ù…Ø¹ÙŠÙ†.
2. Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¶Ø¨ÙˆØ· Ø¯Ù‚ÙŠÙ‚Ù‹Ø§ Ù„Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬.

Ù‚Ø¨Ù„ Ø§Ù„Ø¨Ø¯Ø¡ØŒ ØªØ£ÙƒØ¯ Ù…Ù† ØªØ«Ø¨ÙŠØª Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ø¶Ø±ÙˆØ±ÙŠØ©:

```bash
pip install transformers datasets evaluate
```

Ù†Ø­Ù† Ù†Ø´Ø¬Ø¹Ùƒ Ø¹Ù„Ù‰ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø¥Ù„Ù‰ Ø­Ø³Ø§Ø¨ Hugging Face Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ Ø­ØªÙ‰ ØªØªÙ…ÙƒÙ† Ù…Ù† ØªØ­Ù…ÙŠÙ„ ÙˆÙ…Ø´Ø§Ø±ÙƒØ© Ù†Ù…ÙˆØ°Ø¬Ùƒ Ù…Ø¹ Ø§Ù„Ù…Ø¬ØªÙ…Ø¹. Ø¹Ù†Ø¯Ù…Ø§ ÙŠÙØ·Ù„Ø¨ Ù…Ù†Ùƒ Ø°Ù„ÙƒØŒ Ø£Ø¯Ø®Ù„ Ø±Ù…Ø²Ùƒ Ù„Ù„ØªØ³Ø¬ÙŠÙ„:

```py
>>> from huggingface_hub import notebook_login

>>> notebook_login()
```

## ØªØ­Ù…ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª SWAG

Ø§Ø¨Ø¯Ø£ Ø¨ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙ‡ÙŠØ¦Ø© "Ø§Ù„Ø¹Ø§Ø¯ÙŠØ©" Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª SWAG Ù…Ù† Ù…ÙƒØªØ¨Ø© Datasets ğŸ¤—:

```py
>>> from datasets import load_dataset

>>> swag = load_dataset("swag", "regular")
```

Ø«Ù… Ø§Ù„Ù‚ Ù†Ø¸Ø±Ø© Ø¹Ù„Ù‰ Ù…Ø«Ø§Ù„:

```py
>>> swag["train"][0]
{'ending0': 'passes by walking down the street playing their instruments.',
'ending1': 'has heard approaching them.',
'ending2': "arrives and they're outside dancing and asleep.",
'ending3': 'turns the lead singer watches the performance.',
'fold-ind': '3416',
'gold-source': 'gold',
'label': 0,
'sent1': 'Members of the procession walk down the street holding small horn brass instruments.',
'sent2': 'A drum line',
'startphrase': 'Members of the procession walk down the street holding small horn brass instruments. A drum line',
'video-id': 'anetv_jkn6uvmqwh4'}
```

Ø¹Ù„Ù‰ Ø§Ù„Ø±ØºÙ… Ù…Ù† Ø£Ù†Ù‡ ÙŠØ¨Ø¯Ùˆ Ø£Ù† Ù‡Ù†Ø§Ùƒ Ø§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„Ø­Ù‚ÙˆÙ„ Ù‡Ù†Ø§ØŒ Ø¥Ù„Ø§ Ø£Ù†Ù‡Ø§ ÙÙŠ Ø§Ù„ÙˆØ§Ù‚Ø¹ ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…Ø¨Ø§Ø´Ø±Ø©:

- `sent1` Ùˆ `sent2`: ØªÙˆØ¶Ø­ Ù‡Ø°Ù‡ Ø§Ù„Ø­Ù‚ÙˆÙ„ ÙƒÙŠÙ ØªØ¨Ø¯Ø£ Ø§Ù„Ø¬Ù…Ù„Ø©ØŒ ÙˆØ¥Ø°Ø§ Ù‚Ù…Øª Ø¨Ø¯Ù…Ø¬ Ø§Ù„Ø§Ø«Ù†ÙŠÙ† Ù…Ø¹Ù‹Ø§ØŒ ÙØ³ØªØ­ØµÙ„ Ø¹Ù„Ù‰ Ø­Ù‚Ù„ `startphrase`.
- `ending`: ÙŠÙ‚ØªØ±Ø­ Ù†Ù‡Ø§ÙŠØ© Ù…Ø­ØªÙ…Ù„Ø© Ù„ÙƒÙŠÙÙŠØ© Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø¬Ù…Ù„Ø©ØŒ ÙˆÙ„ÙƒÙ† ÙˆØ§Ø­Ø¯Ø© Ù…Ù†Ù‡Ø§ ÙÙ‚Ø· ØµØ­ÙŠØ­Ø©.
- `label`: ÙŠØ­Ø¯Ø¯ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø¬Ù…Ù„Ø© Ø§Ù„ØµØ­ÙŠØ­Ø©.

## Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø³Ø¨Ù‚Ø©

Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„ØªØ§Ù„ÙŠØ© Ù‡ÙŠ ØªØ­Ù…ÙŠÙ„ Ù…Ø­Ø¯Ø¯ Ø±Ù…ÙˆØ² BERT Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨Ø¯Ø§ÙŠØ§Øª Ø§Ù„Ø¬Ù…Ù„ ÙˆØ§Ù„Ù†Ù‡Ø§ÙŠØ§Øª Ø§Ù„Ø£Ø±Ø¨Ø¹ Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©:

```py
>>> from transformers import AutoTokenizer

>>> tokenizer = AutoTokenizer.from_pretrained("google-bert/bert-base-uncased")
```

ØªØ­ØªØ§Ø¬ Ø¯Ø§Ù„Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³Ø¨Ù‚Ø© Ø§Ù„ØªÙŠ ØªØ±ÙŠØ¯ Ø¥Ù†Ø´Ø§Ø¤Ù‡Ø§ Ø¥Ù„Ù‰:

1. Ø¹Ù…Ù„ Ø£Ø±Ø¨Ø¹ Ù†Ø³Ø® Ù…Ù† Ø­Ù‚Ù„ `sent1` ÙˆØ¯Ù…Ø¬ ÙƒÙ„ Ù…Ù†Ù‡Ø§ Ù…Ø¹ `sent2` Ù„Ø¥Ø¹Ø§Ø¯Ø© Ø¥Ù†Ø´Ø§Ø¡ ÙƒÙŠÙÙŠØ© Ø¨Ø¯Ø¡ Ø§Ù„Ø¬Ù…Ù„Ø©.
2. Ø¯Ù…Ø¬ `sent2` Ù…Ø¹ ÙƒÙ„ Ù…Ù† Ø§Ù„Ù†Ù‡Ø§ÙŠØ§Øª Ø§Ù„Ø£Ø±Ø¨Ø¹ Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø© Ù„Ù„Ø¬Ù…Ù„Ø©.
3. ØªØ³Ø·ÙŠØ­ Ù‡Ø§ØªÙŠÙ† Ø§Ù„Ù‚Ø§Ø¦Ù…ØªÙŠÙ† Ø­ØªÙ‰ ØªØªÙ…ÙƒÙ† Ù…Ù† ØªÙˆÙƒÙŠØ¯Ù‡Ù…Ø§ØŒ Ø«Ù… Ø¥Ù„ØºØ§Ø¡ ØªØ³Ø·ÙŠØ­Ù‡Ù…Ø§ Ù„Ø§Ø­Ù‚Ù‹Ø§ Ø¨Ø­ÙŠØ« ÙŠÙƒÙˆÙ† Ù„ÙƒÙ„ Ù…Ø«Ø§Ù„ Ø­Ù‚ÙˆÙ„ `input_ids` Ùˆ `attention_mask` Ùˆ `labels` Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„Ø©.

```py
>>> ending_names = ["ending0", "ending1", "ending2", "ending3"]


>>> def preprocess_function(examples):
    first_sentences = [[context] * 4 for context in examples["sent1"]]
    question_headers = examples["sent2"]
    second_sentences = [
        [f"{header} {examples[end][i]}" for end in ending_names] for i, header in enumerate(question_headers)
    ]

    first_sentences = sum(first_sentences, [])
    second_sentences = sum(second_sentences, [])

    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)
    return {k: [v[i : i + 4] for i in range(0, len(v), 4)] for k, v in tokenized_examples.items()}
```

Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¯Ø§Ù„Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³Ø¨Ù‚Ø© Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø£ÙƒÙ…Ù„Ù‡Ø§ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø·Ø±ÙŠÙ‚Ø© [`~datasets.Dataset.map`] ÙÙŠ Ù…ÙƒØªØ¨Ø© ğŸ¤— Datasets. ÙŠÙ…ÙƒÙ†Ùƒ ØªØ³Ø±ÙŠØ¹ Ø¯Ø§Ù„Ø© `map` Ø¹Ù† Ø·Ø±ÙŠÙ‚ ØªØ¹ÙŠÙŠÙ† `batched=True` Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¹Ø¯Ø© Ø¹Ù†Ø§ØµØ± Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ ÙˆÙ‚Øª ÙˆØ§Ø­Ø¯:

```py
tokenized_swag = swag.map(preprocess_function, batched=True)
```

Ù„Ø§ ØªØ­ØªÙˆÙŠ Ù…ÙƒØªØ¨Ø© ğŸ¤— Transformers Ø¹Ù„Ù‰ Ø¬Ø§Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø§Ø®ØªÙŠØ§Ø± Ù…Ù† Ù…ØªØ¹Ø¯Ø¯ØŒ Ù„Ø°Ù„Ùƒ Ø³ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªÙƒÙŠÙŠÙ Ø¬Ø§Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª [`DataCollatorWithPadding`] Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø¯ÙØ¹Ø© Ù…Ù† Ø§Ù„Ø£Ù…Ø«Ù„Ø©. Ù…Ù† Ø§Ù„Ø£ÙƒØ«Ø± ÙƒÙØ§Ø¡Ø© Ø£Ù† ØªÙ‚ÙˆÙ… Ø¨Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ Ù„Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø¥Ù„Ù‰ Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„Ø£Ø·ÙˆÙ„ ÙÙŠ Ø¯ÙØ¹Ø© Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¬Ù…ÙŠØ¹ØŒ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† ØªØ­ÙˆÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø£ÙƒÙ…Ù„Ù‡Ø§ Ø¥Ù„Ù‰ Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„Ø£Ù‚ØµÙ‰.

ÙŠÙ‚ÙˆÙ… `DataCollatorForMultipleChoice` Ø¨ØªØ³Ø·ÙŠØ­ Ø¬Ù…ÙŠØ¹ Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ØŒ Ø«Ù… ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­ÙˆÙŠÙ„ØŒ Ø«Ù… Ø¥Ù„ØºØ§Ø¡ ØªØ³Ø·ÙŠØ­ Ø§Ù„Ù†ØªØ§Ø¦Ø¬:

<frameworkcontent>
<pt>
```py
>>> from dataclasses import dataclass
>>> from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy
>>> from typing import Optional, Union
>>> import torch


>>> @dataclass
... class DataCollatorForMultipleChoice:
...     """
...     Data collator that will dynamically pad the inputs for multiple choice received.
...     """

...     tokenizer: PreTrainedTokenizerBase
...     padding: Union[bool, str, PaddingStrategy] = True
...     max_length: Optional[int] = None
...     pad_to_multiple_of: Optional[int] = None

...     def __call__(self, features):
...         label_name = "label" if "label" in features[0].keys() else "labels"
...         labels = [feature.pop(label_name) for feature in features]
...         batch_size = len(features)
...         num_choices = len(features[0]["input_ids"])
...         flattened_features = [
...             [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features
...         ]
...         flattened_features = sum(flattened_features, [])

...         batch = self.tokenizer.pad(
...             flattened_features,
...             padding=self.padding,
...             max_length=self.max_length,
...             pad_to_multiple_of=self.pad_to_multiple_of,
...             return_tensors="pt",
...         )

...         batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}
...         batch["labels"] = torch.tensor(labels, dtype=torch.int64)
...         return batch
```
</pt>
<tf>
```py
>>> from dataclasses import dataclass
>>> from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy
>>> from typing import Optional, Union
>>> import tensorflow as tf


>>> @dataclass
... class DataCollatorForMultipleChoice:
...     """
...     Data collator that will dynamically pad the inputs for multiple choice received.
...     """

...     tokenizer: PreTrainedTokenizerBase
...     padding: Union[bool, str, PaddingStrategy] = True
...     max_length: Optional[int] = None
...     pad_to_multiple_of: Optional[int] = None

...     def __call__(self, features):
...         label_name = "label" if "label" in features[0].keys() else "labels"
...         labels = [feature.pop(label_name) for feature in features]
...         batch_size = len(features)
...         num_choices = len(features[0]["input_ids"])
...         flattened_features = [
...             [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features
...         ]
...         flattened_features = sum(flattened_features, [])

...         batch = self.tokenizer.pad(
...             flattened_features,
...             padding=self.padding,
...             max_length=self.max_length,
...             pad_to_multiple_of=self.pad_to_multiple_of,
...             return_tensors="tf",
...         )

...         batch = {k: tf.reshape(v, (batch_size, num_choices, -1)) for k, v in batch.items()}
...         batch["labels"] = tf.convert_to_tensor(labels, dtype=tf.int64)
...         return batch
```
</tf>
</frameworkcontent>

## ØªÙ‚ÙŠÙŠÙ…

ØºØ§Ù„Ø¨Ù‹Ø§ Ù…Ø§ ÙŠÙƒÙˆÙ† ØªØ¶Ù…ÙŠÙ† Ù…Ù‚ÙŠØ§Ø³ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù…ÙÙŠØ¯Ù‹Ø§ Ù„ØªÙ‚ÙŠÙŠÙ… Ø£Ø¯Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬Ùƒ. ÙŠÙ…ÙƒÙ†Ùƒ ØªØ­Ù…ÙŠÙ„ Ø·Ø±ÙŠÙ‚Ø© ØªÙ‚ÙŠÙŠÙ… Ø¨Ø³Ø±Ø¹Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙƒØªØ¨Ø© ğŸ¤— [Evaluate](https://huggingface.co/docs/evaluate/index). Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù‡Ù…Ø©ØŒ Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ù…Ù‚ÙŠØ§Ø³ [Ø§Ù„Ø¯Ù‚Ø©](https://huggingface.co/spaces/evaluate-metric/accuracy) (Ø±Ø§Ø¬Ø¹ Ø¬ÙˆÙ„Ø© ğŸ¤— Evaluate [Ø§Ù„Ø³Ø±ÙŠØ¹Ø©](https://huggingface.co/docs/evaluate/a_quick_tour) Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯ Ø­ÙˆÙ„ ÙƒÙŠÙÙŠØ© ØªØ­Ù…ÙŠÙ„ ÙˆØ­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚ÙŠØ§Ø³):

```py
>>> import evaluate

>>> accuracy = evaluate.load("accuracy")
```

Ø«Ù… Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø¯Ø§Ù„Ø© ØªÙ…Ø±Ø± ØªÙ†Ø¨Ø¤Ø§ØªÙƒ ÙˆØªØ³Ù…ÙŠØ§ØªÙƒ Ø¥Ù„Ù‰ [`~evaluate.EvaluationModule.compute`] Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø©:

```py
>>> import numpy as np


>>> def compute_metrics(eval_pred):
...     predictions, labels = eval_pred
...     predictions = np.argmax(predictions, axis=1)
...     return accuracy.compute(predictions=predictions, references=labels)
```

Ø¯Ø§Ù„ØªÙƒ `compute_metrics` Ø¬Ø§Ù‡Ø²Ø© Ø§Ù„Ø¢Ù†ØŒ ÙˆØ³ØªØ¹ÙˆØ¯ Ø¥Ù„ÙŠÙ‡Ø§ Ø¹Ù†Ø¯ Ø¥Ø¹Ø¯Ø§Ø¯ ØªØ¯Ø±ÙŠØ¨Ùƒ.
## Ø§Ù„ØªØ¯Ø±ÙŠØ¨

Ø£Ù†Øª Ø§Ù„Ø¢Ù† Ù…Ø³ØªØ¹Ø¯ Ù„Ø¨Ø¯Ø¡ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬Ùƒ! Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ BERT Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [AutoModelForMultipleChoice]:

```python
>>> from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer

>>> model = AutoModelForMultipleChoice.from_pretrained("google-bert/bert-base-uncased")
```

ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø­Ù„Ø©ØŒ Ù„Ù… ÙŠØªØ¨Ù‚ Ø³ÙˆÙ‰ Ø«Ù„Ø§Ø« Ø®Ø·ÙˆØ§Øª:

1. Ø­Ø¯Ø¯ ÙØ±Ø· Ù…Ø¹Ù„Ù…Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ ÙÙŠ [TrainingArguments]. Ø§Ù„Ù…Ø¹Ù„Ù…Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ø§Ù„ÙˆØ­ÙŠØ¯Ø© Ù‡ÙŠ output_dir Ø§Ù„ØªÙŠ ØªØ­Ø¯Ø¯ Ù…ÙƒØ§Ù† Ø­ÙØ¸ Ù†Ù…ÙˆØ°Ø¬Ùƒ. Ø³ÙˆÙ ØªÙ‚ÙˆÙ… Ø¨Ø¯ÙØ¹ Ù‡Ø°Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø­ÙˆØ± Ø¹Ù† Ø·Ø±ÙŠÙ‚ ØªØ¹ÙŠÙŠÙ† push_to_hub=True (ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ù…Ø³Ø¬Ù„Ø§Ù‹ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø¥Ù„Ù‰ Hugging Face Ù„ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬Ùƒ). ÙÙŠ Ù†Ù‡Ø§ÙŠØ© ÙƒÙ„ Ø­Ù‚Ø¨Ø©ØŒ Ø³ÙŠÙ‚ÙˆÙ… [Trainer] Ø¨ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¯Ù‚Ø© ÙˆØ­ÙØ¸ Ù†Ù‚Ø·Ø© ØªÙØªÙŠØ´ Ø§Ù„ØªØ¯Ø±ÙŠØ¨.

2. Ù‚Ù… Ø¨ØªÙ…Ø±ÙŠØ± ÙØ±Ø· Ù…Ø¹Ù„Ù…Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¥Ù„Ù‰ [Trainer] Ø¬Ù†Ø¨Ù‹Ø§ Ø¥Ù„Ù‰ Ø¬Ù†Ø¨ Ù…Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆÙ…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆÙ…Ø¹ÙŠÙ‘Ù† Ø§Ù„Ø±Ù…ÙˆØ² ÙˆÙ…Ù„Ù ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆÙˆØ¸ÙŠÙØ© compute_metrics.

3. Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ [~ Trainer.train] Ù„Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬Ùƒ Ø¨Ø´ÙƒÙ„ Ø¯Ù‚ÙŠÙ‚.

```python
>>> training_args = TrainingArguments(
...     output_dir="my_awesome_swag_model"ØŒ
...     eval_strategy="epoch"ØŒ
...     save_strategy="epoch"ØŒ
...     load_best_model_at_end=TrueØŒ
...     learning_rate=5e-5ØŒ
...     per_device_train_batch_size=16ØŒ
...     per_device_eval_batch_size=16ØŒ
...     num_train_epochs=3ØŒ
...     weight_decay=0.01ØŒ
...     push_to_hub=TrueØŒ
... )

>>> trainer = Trainer(
...     model=modelØŒ
...     args=training_argsØŒ
...     train_dataset=tokenized_swag["train"]ØŒ
...     eval_dataset=tokenized_swag["validation"]ØŒ
...     tokenizer=tokenizerØŒ
...     data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer)ØŒ
...     compute_metrics=compute_metricsØŒ
... )

>>> trainer.train()
```

Ø¨Ù…Ø¬Ø±Ø¯ Ø§ÙƒØªÙ…Ø§Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ØŒ Ø´Ø§Ø±Ùƒ Ù†Ù…ÙˆØ°Ø¬Ùƒ ÙÙŠ Ø§Ù„Ù…Ø­ÙˆØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø·Ø±ÙŠÙ‚Ø© [~ transformers.Trainer.push_to_hub] Ø­ØªÙ‰ ÙŠØªÙ…ÙƒÙ† Ø§Ù„Ø¬Ù…ÙŠØ¹ Ù…Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬Ùƒ:

```python
>>> trainer.push_to_hub()
```

Ù„Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ TensorFlowØŒ Ø§Ø¨Ø¯Ø£ Ø¨Ø¥Ø¹Ø¯Ø§Ø¯ Ø¯Ø§Ù„Ø© Ù…Ø­Ø³Ù† ÙˆÙ…Ø¹Ø¯Ù„ ØªØ¹Ù„Ù… ÙˆØ¬Ø¯ÙˆÙ„ Ø²Ù…Ù†ÙŠ ÙˆØ¨Ø¹Ø¶ ÙØ±Ø· Ù…Ø¹Ù„Ù…Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨:

```python
>>> from transformers import create_optimizer

>>> batch_size = 16
>>> num_train_epochs = 2
>>> total_train_steps = (len(tokenized_swag["train"]) // batch_size) * num_train_epochs
>>> optimizer, schedule = create_optimizer(init_lr=5e-5, num_warmup_steps=0, num_train_steps=total_train_steps)
```

Ø«Ù… ÙŠÙ…ÙƒÙ†Ùƒ ØªØ­Ù…ÙŠÙ„ BERT Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [TFAutoModelForMultipleChoice]:

```python
>>> from transformers import TFAutoModelForMultipleChoice

>>> model = TFAutoModelForMultipleChoice.from_pretrained("google-bert/bert-base-uncased")
```

Ù‚Ù… Ø¨ØªØ­ÙˆÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ `tf.data.Dataset` Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [~ transformers.TFPreTrainedModel.prepare_tf_dataset]:

```python
>>> data_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)
>>> tf_train_set = model.prepare_tf_dataset(
...     tokenized_swag["train"]ØŒ
...     shuffle=TrueØŒ
...     batch_size=batch_sizeØŒ
...     collate_fn=data_collatorØŒ
... )

>>> tf_validation_set = model.prepare_tf_dataset(
...     tokenized_swag["validation"]ØŒ
...     shuffle=FalseØŒ
...     batch_size=batch_sizeØŒ
...     collate_fn=data_collatorØŒ
... )
```

Ù‚Ù… Ø¨ØªÙƒÙˆÙŠÙ† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [compile](https://keras.io/api/models/model_training_apis/#compile-method). Ù„Ø§Ø­Ø¸ Ø£Ù† Ø¬Ù…ÙŠØ¹ Ù†Ù…Ø§Ø°Ø¬ Transformers Ø¨Ù‡Ø§ Ø¯Ø§Ù„Ø© Ø®Ø³Ø§Ø±Ø© Ø°Ø§Øª ØµÙ„Ø© Ø¨Ø§Ù„Ù…Ù‡Ù…Ø© Ø¨Ø´ÙƒÙ„ Ø§ÙØªØ±Ø§Ø¶ÙŠØŒ Ù„Ø°Ù„Ùƒ Ù„Ø§ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªØ­Ø¯ÙŠØ¯ ÙˆØ§Ø­Ø¯Ø© Ù…Ø§ Ù„Ù… ØªØ±ØºØ¨ ÙÙŠ Ø°Ù„Ùƒ:

```python
>>> model.compile(optimizer=optimizer)  # Ù„Ø§ ØªÙˆØ¬Ø¯ ÙˆØ³ÙŠØ·Ø© Ø®Ø³Ø§Ø±Ø©!
```

Ø§Ù„Ø£Ù…Ø±Ø§Ù† Ø§Ù„Ø£Ø®ÙŠØ±Ø§Ù† Ø§Ù„Ù„Ø°Ø§Ù† ÙŠØ¬Ø¨ Ø¥Ø¹Ø¯Ø§Ø¯Ù‡Ù…Ø§ Ù‚Ø¨Ù„ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù‡Ù…Ø§ Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø© Ù…Ù† Ø§Ù„ØªÙˆÙ‚Ø¹Ø§ØªØŒ ÙˆØªÙˆÙÙŠØ± Ø·Ø±ÙŠÙ‚Ø© Ù„Ø¯ÙØ¹ Ù†Ù…ÙˆØ°Ø¬Ùƒ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø­ÙˆØ±. ÙŠØªÙ… ØªÙ†ÙÙŠØ° ÙƒÙ„Ø§Ù‡Ù…Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [Keras callbacks](../main_classes/keras_callbacks).

Ù…Ø±Ø± Ø¯Ø§Ù„ØªÙƒ `compute_metrics` Ø¥Ù„Ù‰ [~ transformers.KerasMetricCallback]:

```python
>>> from transformers.keras_callbacks import KerasMetricCallback

>>> metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_validation_set)
```

Ø­Ø¯Ø¯ Ù…ÙƒØ§Ù† Ø¯ÙØ¹ Ù†Ù…ÙˆØ°Ø¬Ùƒ ÙˆÙ…Ø¹ÙŠÙ‘Ù† Ø§Ù„Ø±Ù…ÙˆØ² ÙÙŠ [~ transformers.PushToHubCallback]:

```python
>>> from transformers.keras_callbacks import PushToHubCallback

>>> push_to_hub_callback = PushToHubCallback(
...     output_dir="my_awesome_model"ØŒ
...     tokenizer=tokenizerØŒ
... )
```

Ø«Ù… Ù‚Ù… Ø¨ØªØ¬Ù…ÙŠØ¹ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡Ø§ØªÙƒ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰:

```python
>>> callbacks = [metric_callback, push_to_hub_callback]
```

Ø£Ø®ÙŠØ±Ù‹Ø§ØŒ Ø£Ù†Øª Ù…Ø³ØªØ¹Ø¯ Ù„Ø¨Ø¯Ø¡ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬Ùƒ! Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ [fit](https://keras.io/api/models/model_training_apis/#fit-method) Ù…Ø¹ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ÙŠØ© ÙˆØ§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­ØªÙ‡Ø§ØŒ ÙˆØ¹Ø¯Ø¯ Ø§Ù„Ø¹ØµÙˆØ±ØŒ ÙˆØ§Ø³ØªØ¯Ø¹Ø§Ø¡Ø§ØªÙƒ Ù„Ø¶Ø¨Ø· Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø¯Ù‚Ø©:

```python
>>> model.fit(x=tf_train_setØŒ validation_data=tf_validation_setØŒ epochs=2ØŒ callbacks=callbacks)
```

Ø¨Ù…Ø¬Ø±Ø¯ Ø§ÙƒØªÙ…Ø§Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ØŒ ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬Ùƒ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø­ÙˆØ± Ø­ØªÙ‰ ÙŠØªÙ…ÙƒÙ† Ø§Ù„Ø¬Ù…ÙŠØ¹ Ù…Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡!

Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø«Ø§Ù„ Ø£ÙƒØ«Ø± ØªØ¹Ù…Ù‚Ù‹Ø§ Ø­ÙˆÙ„ ÙƒÙŠÙÙŠØ© Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ø§Ø®ØªÙŠØ§Ø± Ù…Ù† Ù…ØªØ¹Ø¯Ø¯ØŒ Ø±Ø§Ø¬Ø¹ Ø§Ù„Ø¯ÙØªØ± Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„
[Ø¯ÙØªØ± Ù…Ù„Ø§Ø­Ø¸Ø§Øª PyTorch](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/multiple_choice.ipynb)
Ø£Ùˆ [Ø¯ÙØªØ± TensorFlow](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/multiple_choice-tf.ipynb).

## Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬

Ø±Ø§Ø¦Ø¹ØŒ Ø§Ù„Ø¢Ù† Ø¨Ø¹Ø¯ Ø£Ù† Ø¶Ø¨Ø·Øª Ù†Ù…ÙˆØ°Ø¬Ù‹Ø§ØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ Ù„Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬!

ÙÙƒØ± ÙÙŠ Ø¨Ø¹Ø¶ Ø§Ù„Ù†ØµÙˆØµ ÙˆØ¥Ø¬Ø§Ø¨ØªÙŠÙ† Ù…Ø±Ø´Ø­ØªÙŠÙ†:

```python
>>> prompt = "France has a bread law, Le DÃ©cret Pain, with strict rules on what is allowed in a traditional baguette."
>>> candidate1 = "The law does not apply to croissants and brioche."
>>> candidate2 = "The law applies to baguettes."
```

Ù‚Ù… Ø¨Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒÙ„ Ø²ÙˆØ¬ Ù…Ù† Ø§Ù„Ù†ØµÙˆØµ ÙˆØ§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ù…Ø±Ø´Ø­Ø© ÙˆÙ‚Ù… Ø¨Ø¥Ø±Ø¬Ø§Ø¹ tensers PyTorch. ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ Ø£ÙŠØ¶Ù‹Ø§ Ø¥Ù†Ø´Ø§Ø¡ Ø¨Ø¹Ø¶ `labels`:

```python
>>> from transformers import AutoTokenizer

>>> tokenizer = AutoTokenizer.from_pretrained("my_awesome_swag_model")
>>> inputs = tokenizer([[prompt, candidate1], [prompt, candidate2]]ØŒ return_tensors="pt"ØŒ padding=True)
>>> labels = torch.tensor(0).unsqueeze(0)
```

Ù…Ø±Ø± Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª ÙˆØ§Ù„Ù…Ù„ØµÙ‚Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ Ø¥Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ£Ø¹Ø¯ Ø§Ù„ÙˆØ³ÙŠØ·Ø§Øª:

```python
>>> from transformers import AutoModelForMultipleChoice

>>> model = AutoModelForMultipleChoice.from_pretrained("my_awesome_swag_model")
>>> outputs = model(**{k: v.unsqueeze(0) for k, v in inputs.items()}, labels=labels)
>>> logits = outputs.logits
```

Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø§Ù„ÙØ¦Ø© Ø°Ø§Øª Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø§Ù„Ø£Ø¹Ù„Ù‰:

```python
>>> predicted_class = logits.argmax().item()
>>> predicted_class
'0'
```

Ù‚Ù… Ø¨Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒÙ„ Ø²ÙˆØ¬ Ù…Ù† Ø§Ù„Ù†ØµÙˆØµ ÙˆØ§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ù…Ø±Ø´Ø­Ø© ÙˆØ¥Ø±Ø¬Ø§Ø¹ tensers TensorFlow:

```python
>>> from transformers import AutoTokenizer

>>> tokenizer = AutoTokenizer.from_pretrained("my_awesome_swag_model")
>>> inputs = tokenizer([[prompt, candidate1], [prompt, candidate2]]ØŒ return_tensors="tf"ØŒ padding=True)
```

Ù…Ø±Ø± Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ø¥Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ£Ø¹Ø¯ Ø§Ù„ÙˆØ³ÙŠØ·Ø§Øª:

```python
>>> from transformers import TFAutoModelForMultipleChoice

>>> model = TFAutoModelForMultipleChoice.from_pretrained("my_awesome_swag_model")
>>> inputs = {k: tf.expand_dims(v, 0) for k, v in inputs.items()}
>>> outputs = model(inputs)
>>> logits = outputs.logits
```

Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø§Ù„ÙØ¦Ø© Ø°Ø§Øª Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø§Ù„Ø£Ø¹Ù„Ù‰:

```python
>>> predicted_class = int(tf.math.argmax(logits, axis=-1)[0])
>>> predicted_class
'0'
```