## دليل إرشادي لاستخدام نماذج اللغة الضخمة

تعد نماذج اللغة الضخمة مثل Falcon وLLaMA، من نماذج المحول المسبقة التدريب التي تم تدريبها في البداية للتنبؤ بالرمز التالي بناءً على نص الإدخال. تمتلك هذه النماذج عادةً مليارات من المعلمات وقد تم تدريبها على تريليونات من الرموز لفترة طويلة من الزمن. ونتيجة لذلك، أصبحت هذه النماذج قوية ومتعددة الاستخدامات، ويمكنك استخدامها لحل العديد من مهام معالجة اللغات الطبيعية مباشرة من خلال توجيه النماذج باستخدام إرشادات اللغة الطبيعية.

غالبًا ما يُطلق على تصميم هذه الإرشادات لضمان الحصول على الإخراج الأمثل "هندسة الإرشادات". وهندسة الإرشادات هي عملية تكرارية تتطلب قدرًا كبيرًا من التجريب. اللغات الطبيعية أكثر مرونة وتعبيرية من لغات البرمجة، ولكنها يمكن أن تُدخل بعض الغموض أيضًا. وفي الوقت نفسه، تكون الإرشادات في اللغة الطبيعية حساسة للغاية للتغييرات. حتى التعديلات الطفيفة في الإرشادات يمكن أن تؤدي إلى نتائج مختلفة تمامًا.

في حين لا توجد وصفة دقيقة لإنشاء إرشادات تتطابق مع جميع الحالات، فقد توصل الباحثون إلى عدد من أفضل الممارسات التي تساعد على تحقيق نتائج مثالية بشكل أكثر اتساقًا.

يغطي هذا الدليل أفضل الممارسات في هندسة الإرشادات لمساعدتك في صياغة إرشادات أفضل لنماذج اللغة الضخمة وحل مختلف مهام معالجة اللغات الطبيعية. ستتعلم ما يلي:

- أساسيات الإرشادات
- أفضل الممارسات في إرشادات نماذج اللغة الضخمة
- تقنيات الإرشادات المتقدمة: الإرشادات قليلة الأمثلة وسلسلة الأفكار
- متى يجب الضبط الدقيق بدلاً من استخدام الإرشادات

## أساسيات الإرشادات

### أنواع النماذج

معظم نماذج اللغة الضخمة الحديثة هي من نوع محولات فك التشفير فقط. بعض الأمثلة تشمل: LLaMA وLlama2 وFalcon وGPT2. ومع ذلك، قد تصادف أيضًا نماذج محول الترميز-فك الترميز لنماذج اللغة الضخمة، على سبيل المثال، Flan-T5 وBART.

تُستخدم نماذج الترميز-فك الترميز بشكل شائع في المهام التوليدية حيث يعتمد الإخراج بشكل كبير على الإدخال، كما هو الحال في الترجمة والتلخيص. بينما تُستخدم نماذج فك التشفير فقط لجميع الأنواع الأخرى من المهام التوليدية.

عند استخدام خط أنابيب لتوليد النص باستخدام نموذج لغة ضخمة، من المهم معرفة نوع نموذج اللغة الضخمة الذي تستخدمه، لأنها تستخدم خطوط أنابيب مختلفة.

قم بتشغيل الاستنتاج باستخدام نماذج فك التشفير فقط مع خط أنابيب "text-generation":

```python
>>> from transformers import pipeline
>>> import torch

>>> torch.manual_seed(0) # doctest: +IGNORE_RESULT

>>> generator = pipeline('text-generation', model = 'openai-community/gpt2')
>>> prompt = "Hello, I'm a language model"

>>> generator(prompt, max_length = 30)
[{'generated_text': "Hello, I'm a language model programmer so you can use some of my stuff. But you also need some sort of a C program to run."}]
```

لتشغيل الاستنتاج باستخدام نموذج الترميز-فك الترميز، استخدم خط أنابيب "text2text-generation":

```python
>>> text2text_generator = pipeline("text2text-generation", model = 'google/flan-t5-base')
>>> prompt = "Translate from English to French: I'm very happy to see you"

>>> text2text_generator(prompt)
[{'generated_text': 'Je suis très heureuse de vous rencontrer.'}]
```

### النماذج الأساسية مقابل نماذج التعليمات/الدردشة

تأتي معظم نقاط التحقق الحديثة لنماذج اللغة الضخمة المتوفرة على Hugging Face Hub في إصدارين: الإصدار الأساسي وإصدار التعليمات (أو الدردشة). على سبيل المثال، "tiiuae/falcon-7b" و"tiiuae/falcon-7b-instruct".

النماذج الأساسية ممتازة في استكمال النص عند إعطائها إرشادًا أوليًا، ولكنها ليست مثالية لمهام معالجة اللغات الطبيعية حيث تحتاج إلى اتباع التعليمات، أو للاستخدام في المحادثات. وهنا يأتي دور إصدارات التعليمات (الدردشة). هذه نقاط تحقق ناتجة عن الضبط الدقيق الإضافي للإصدارات الأساسية المسبقة التدريب على تعليمات وبيانات المحادثة. يجعلها هذا الضبط الدقيق الإضافي خيارًا أفضل للعديد من مهام معالجة اللغات الطبيعية.

دعونا نوضح بعض الإرشادات البسيطة التي يمكنك استخدامها مع "tiiuae/falcon-7b-instruct" لحل بعض مهام معالجة اللغات الطبيعية الشائعة.
### مهام معالجة اللغات الطبيعية

الآن بعد أن قمنا بتحميل النموذج عبر الأنبوب، دعونا نستكشف كيف يمكنك استخدام المطالبات لحل مهام معالجة اللغات الطبيعية.

#### تصنيف النص

يعد تحليل المشاعر أحد أكثر أشكال تصنيف النصوص شيوعًا، والذي يقوم بتعيين علامة مثل "إيجابي" أو "سلبي" أو "محايد" لمقطع نصي. دعونا نكتب مطالبة توضح للنماذج تصنيف نص معين (مراجعة فيلم). سنبدأ بإعطاء التعليمات، ثم تحديد النص لتصنيفه. لاحظ أنه بدلاً من تركه على هذا النحو، فإننا نضيف أيضًا بداية الاستجابة - `"Sentiment: "`:

```python
>>> تسلسل = pipe(
...     "صنف النص إلى محايد أو سلبي أو إيجابي.
... النص: هذا الفيلم هو بالتأكيد أحد أفلامي المفضلة من نوعه. إن التفاعل بين الشخصيات المحترمة والقوية أخلاقياً هو نشيد الفروسية وشرف قانون الشرف بين اللصوص ورجال الشرطة.
... الشعور:
... "،
...     max_new_tokens=10,
... )

>>> لكل تسلسل في التسلسلات:
...     طباعة (ف "النتيجة: {sequence['generated_text']}")
النتيجة: صنف النص إلى محايد أو سلبي أو إيجابي.
النص: هذا الفيلم هو بالتأكيد أحد أفلامي المفضلة من نوعه. إن التفاعل بين الشخصيات المحترمة والقوية أخلاقياً هو نشيد الفروسية وشرف قانون الشرف بين اللصوص ورجال الشرطة.
المشاعر:
إيجابية
```

وكنتيجة لذلك، يحتوي الإخراج على تصنيف العلامات من القائمة التي قدمناها في التعليمات، وهو صحيح!

#### التعرف على الكيانات المسماة

التعرف على الكيانات المسماة (NER) هي مهمة العثور على كيانات مسماة في قطعة من النص، مثل شخص أو موقع أو منظمة.

دعونا نعدل التعليمات في المطالبة لجعل LLM يؤدي هذه المهمة. هنا، دعونا أيضًا نحدد `return_full_text = False` بحيث لا يحتوي الإخراج على المطالبة:

```python
>>> تسلسل = pipe(
...     "إرجاع قائمة بالكيانات المسماة في النص.
... النص: محاربو جولدن ستيت هم فريق كرة سلة أمريكي محترف يقع في سان فرانسيسكو.
... الكيانات المسماة:
... "،
...     max_new_tokens=15،
...     return_full_text = False،
... )

>>> لكل تسلسل في التسلسلات:
...     طباعة (ف"{sequence['generated_text']}")
- محاربو جولدن ستيت
- سان فرانسيسكو
```

كما ترون، حدد النموذج بشكل صحيح كيانين مسمى من النص المعطى.

#### الترجمة

المهمة الأخرى التي يمكن أن تؤديها LLMs هي الترجمة. يمكنك اختيار استخدام نماذج الترميز فك الترميز لهذه المهمة، ومع ذلك، هنا، من أجل بساطة الأمثلة، سوف نواصل استخدام Falcon-7b-instruct، والذي يقوم بعمل جيد. مرة أخرى، إليك كيفية كتابة مطالبة أساسية لتعليم النموذج ترجمة قطعة نص من الإنجليزية إلى الإيطالية:

```python
>>> تسلسل = pipe(
...     "ترجمة النص الإنجليزي إلى الإيطالية.
... النص: أحيانًا، أعتقد أن هناك ستة أشياء مستحيلة قبل الإفطار.
... الترجمة:
... "،
...     max_new_tokens=20،
...     do_sample=True،
...     top_k=10،
...     return_full_text = False،
... )

>>> لكل تسلسل في التسلسلات:
...     طباعة (ف"{sequence['generated_text']}")
A volte، ho creduto a sei impossibili cose prima di colazione.
```

هنا أضفنا `do_sample=True` و`top_k=10` للسماح للنموذج بالمزيد من المرونة عند إنشاء الإخراج.

#### تلخيص النص

على غرار الترجمة، يعد تلخيص النص مهمة توليدية أخرى يعتمد فيها الإخراج **بشدة** على الإدخال، ويمكن أن تكون نماذج الترميز فك الترميز خيارًا أفضل. ومع ذلك، يمكن أيضًا استخدام نماذج نمط فك التشفير لهذه المهمة.

في السابق، وضعنا التعليمات في بداية المطالبة. ومع ذلك، فإن نهاية المطالبة يمكن
أيضًا أن يكون موقعًا مناسبًا للتعليمات. عادةً، من الأفضل وضع التعليمات في أحد الطرفين.

```python
>>> تسلسل = pipe(
...     "الزراعة الدائمة هي عملية تصميم تحاكي تنوع النظم البيئية الطبيعية ووظائفها وقدرتها على التكيف. يتم استخلاص المبادئ والممارسات من المعرفة الإيكولوجية التقليدية للثقافات الأصلية بالاقتران مع الفهم العلمي الحديث والابتكارات التكنولوجية. يوفر تصميم الزراعة الدائمة إطارًا لمساعدة الأفراد والمجتمعات على تطوير استراتيجيات مبتكرة وإبداعية وفعالة لتلبية الاحتياجات الأساسية مع الاستعداد لتأثيرات تغير المناخ والتخفيف من حدتها.
... اكتب ملخصًا للنص أعلاه.
... ملخص:
... "،
...     max_new_tokens=30،
...     do_sample=True،
...     top_k=10،
...     return_full_text = False،
... )

>>> لكل تسلسل في التسلسلات:
...     طباعة (ف"{sequence['generated_text']}")
الزراعة الدائمة هي تصميم إيكولوجي يحاكي النظم البيئية الطبيعية لتلبية الاحتياجات الأساسية والاستعداد لتغير المناخ. إنه يعتمد على المعرفة التقليدية والفهم العلمي.
```

#### الإجابة على الأسئلة

لمهمة الإجابة على الأسئلة، يمكننا هيكلة المطالبة إلى المكونات المنطقية التالية: التعليمات، والسياق، والسؤال،
وكلمة أو عبارة رائدة ("الإجابة:") لحث النموذج على بدء إنشاء الإجابة:

```python
>>> تسلسل = pipe(
...     "الإجابة على السؤال باستخدام السياق أدناه.
... السياق: غازباتشو هو حساء بارد ومشروب مصنوع من الخضار النيئة والممزوجة. يحتوي معظم الغازباتشو على الخبز الجاف والطماطم والخيار والبصل والفلفل الحلو والثوم وزيت الزيتون وخل النبيذ والماء والملح. غالبًا ما تتضمن الوصفات الشمالية الكمون و/أو البابريكا المدخنة (البابريكا الحلوة المدخنة). تقليديًا، كان يتم صنع الغازباتشو عن طريق دق الخضار في هاون باستخدام مدقة؛ لا تزال هذه الطريقة الأكثر صعوبة تُستخدم أحيانًا لأنها تساعد في الحفاظ على برودة الغازباتشو وتجنب الرغوة والقوام الحريري لنسخ الخلاط أو معالجات الطعام.
... السؤال: ما هي الأداة الحديثة المستخدمة في صنع الغازباتشو؟
... الإجابة:
... "،
...     max_new_tokens=10،
...     do_sample=True،
...     top_k=10،
...     return_full_text = False،
... )

>>> لكل تسلسل في التسلسلات:
...     طباعة (ف "النتيجة: {sequence['generated_text']}")
النتيجة: غالبًا ما تشمل الأدوات الحديثة المستخدمة في صنع الغازباتشو
```

#### الاستدلال

الاستدلال هو إحدى أصعب المهام بالنسبة لـ LLMs، وغالبًا ما يتطلب تحقيق نتائج جيدة تطبيق تقنيات المطالبة المتقدمة، مثل
[سلسلة من التفكير](#chain-of-thought).

دعونا نجرب ما إذا كان بإمكاننا جعل النموذج يستدل على مهمة حسابية بسيطة باستخدام مطالبة أساسية:

```python
>>> تسلسل = pipe(
...     "هناك 5 مجموعات من الطلاب في الفصل. يحتوي كل مجموعة على 4 طلاب. كم عدد الطلاب في الفصل؟"
...     max_new_tokens=30،
...     do_sample=True،
...     top_k=10،
...     return_full_text = False،
... )

>>> لكل تسلسل في التسلسلات:
...     طباعة (ف "النتيجة: {sequence['generated_text']}")
النتيجة:
هناك ما مجموعه 5 مجموعات، لذلك هناك 5 × 4 = 20 طالبًا في الفصل.
```

صحيح! دعونا نزيد التعقيد قليلاً ونرى ما إذا كان بإمكاننا الابتعاد عن مطالبة أساسية:

```python
>>> تسلسل = pipe(
...     "لقد خبزت 15 كعكة صغيرة. أكلت 2 كعكة صغيرة وأعطيت 5 كعكة صغيرة لجاري. ثم اشترى شريكي 6 كعك صغيرة أخرى وأكل 2. كم عدد الكعك التي لدينا الآن؟"
...     max_new_tokens=10،
...     do_sample=True،
...     top_k=10،
...     return_full_text = False،
... )

>>> لكل تسلسل في التسلسلات:
...     طباعة (ف "النتيجة: {sequence['generated_text']}")
النتيجة:
إجمالي عدد الكعك الآن هو 21
```

هذه إجابة خاطئة، يجب أن تكون 12. في هذه الحالة، قد يكون ذلك بسبب المطالبة الأساسية جدًا، أو بسبب اختيار
النموذج، بعد كل شيء، لقد اخترنا الإصدار الأصغر من Falcon. الاستدلال صعب على النماذج من جميع الأحجام، ولكن من المحتمل أن تؤدي النماذج الأكبر حجمًا أداءً أفضل.
## أفضل الممارسات في كتابة الأوامر للنماذج اللغوية الكبيرة 

في هذا القسم من الدليل، جمعنا قائمة بأفضل الممارسات التي من شأنها أن تحسن نتائج الأوامر: 

* عند اختيار النموذج للعمل معه، من المرجح أن تقدم أحدث النماذج وأكثرها قدرة أداءً أفضل. 
* ابدأ بأمر بسيط وقصير، ثم طور الأمر من هناك. 
* ضع التعليمات في بداية الأمر أو في نهايته تمامًا. فعند العمل بسياق كبير، تطبق النماذج تحسينًا متنوعًا لمنع تعقيد الانتباه من التصاعد التربيعي. وقد يجعل هذا النموذج أكثر انتباهًا لبداية أو نهاية الأمر من منتصفه. 
* افصل التعليمات عن النص الذي تنطبق عليه بوضوح - المزيد عن هذا في القسم التالي. 
* كن محددًا وواضحًا بشأن المهمة والنتيجة المرجوة - تنسيقها، وطولها، وأسلوبها، ولغتها، وما إلى ذلك. 
* تجنب الأوصاف والتعليمات الغامضة. 
* فضل التعليمات التي توضح "ماذا تفعل" بدلاً من تلك التي توضح "ماذا لا تفعل". 
* "وجه" النتيجة في الاتجاه الصحيح من خلال كتابة الكلمة الأولى (أو حتى البدء في الجملة الأولى للنموذج). 
* استخدم التقنيات المتقدمة مثل [الأمر باستخدام أمثلة قليلة](#few-shot-prompting) و[سلسلة الفكر](#chain-of-thought) 
* اختبر أوامرك مع نماذج مختلفة لتقييم متانتها. 
* قم بإصدار أوامرك وتتبع أدائها. 

## تقنيات متقدمة في كتابة الأوامر 

### الأمر باستخدام أمثلة قليلة 

الأوامر الأساسية في الأقسام أعلاه هي أمثلة على أوامر "الصفر-shot"، وهذا يعني أن النموذج قد تلقى تعليمات وسياقًا، ولكن بدون أمثلة وحلول. النماذج اللغوية الكبيرة التي تم ضبطها بدقة على مجموعات بيانات التعليمات، تؤدي بشكل عام بشكل جيد في مهام "الصفر-shot". ومع ذلك، قد تجد أن مهمتك أكثر تعقيدًا أو دقة، وربما لديك بعض المتطلبات للنتيجة التي لا يلتقطها النموذج فقط من التعليمات. في هذه الحالة، يمكنك تجربة تقنية تسمى الأمر باستخدام أمثلة قليلة. 

في الأمر باستخدام أمثلة قليلة، نقدم أمثلة في الأمر لإعطاء النموذج مزيدًا من السياق لتحسين الأداء. وتوجه الأمثلة النموذج لتوليد النتيجة باتباع الأنماط الموجودة في الأمثلة. 

هذا مثال: 

في مقتطف الكود أعلاه، استخدمنا مثالًا واحدًا لتوضيح النتيجة المرجوة للنموذج، لذا يمكن تسميته "one-shot prompting". ومع ذلك، اعتمادًا على تعقيد المهمة، قد تحتاج إلى استخدام أكثر من مثال. 

قيود تقنية الأمر باستخدام أمثلة قليلة: 

- في حين أن النماذج اللغوية الكبيرة يمكنها استيعاب الأنماط الموجودة في الأمثلة، إلا أن هذه التقنية لا تعمل بشكل جيد في مهام الاستدلال المعقدة. 
- يتطلب الأمر باستخدام أمثلة قليلة إنشاء أوامر مطولة. وقد تزيد الأوامر التي تحتوي على عدد كبير من الرموز من الحساب والوقت. هناك أيضًا حد لطول الأوامر. 
- في بعض الأحيان، عندما يتم إعطاء النماذج عددًا من الأمثلة، يمكنها تعلم أنماط لم تكن تقصد منها تعلمها، على سبيل المثال، أن مراجعة الفيلم الثالث دائمًا ما تكون سلبية. 

### سلسلة الفكر 

سلسلة الفكر هي تقنية تدفع النموذج إلى إنتاج خطوات استدلال وسيطة، وبالتالي تحسين النتائج في مهام الاستدلال المعقدة. 

هناك طريقتان لتوجيه النموذج لإنتاج خطوات الاستدلال: 

- الأمر باستخدام أمثلة قليلة من خلال توضيح الأمثلة بإجابات مفصلة للأسئلة، وإظهار النموذج كيفية حل المشكلة. 
- من خلال توجيه النموذج للاستدلال بإضافة عبارات مثل "دعنا نفكر خطوة بخطوة" أو "خذ نفسًا عميقًا وحل المشكلة خطوة بخطوة". 

إذا طبقنا تقنية سلسلة الفكر على مثال الكعك من قسم [الاستدلال](#reasoning) واستخدمنا نموذجًا أكبر، مثل (`tiiuae/falcon-180B-chat`) الذي يمكنك تجربته في [HuggingChat](https://huggingface.co/chat/)، فسنحصل على تحسن كبير في نتيجة الاستدلال: 

"دعنا نمر خلال هذا خطوة بخطوة: 

1. تبدأ بـ 15 كعكة. 
2. تأكل 2 كعكة، مما يترك لك 13 كعكة. 
3. تعطي 5 كعكات لجارك، مما يترك لك 8 كعكات. 
4. يشتري شريكك 6 كعكات أخرى، مما يجعل العدد الإجمالي للكعك 14. 
5. يأكل شريكك كعكتين، مما يترك لك 12 كعكة. 

لذلك، لديك الآن 12 كعكة." 

## كتابة الأوامر مقابل الضبط الدقيق 

يمكنك تحقيق نتائج رائعة من خلال تحسين أوامرك، ومع ذلك، قد تتساءل عما إذا كان الضبط الدقيق للنموذج سيعمل بشكل أفضل لحالتك. فيما يلي بعض السيناريوهات التي قد يكون فيها ضبط نموذج أصغر بدقة خيارًا مفضلًا: 

- مجالك مختلف تمامًا عما تم ضبط النماذج اللغوية الكبيرة عليه مسبقًا ولم يحقق ضبط الأوامر نتائج كافية. 
- تحتاج إلى أن يعمل نموذجك بشكل جيد في لغة منخفضة الموارد. 
- تحتاج إلى تدريب النموذج على بيانات حساسة تخضع لتنظيم صارم. 
- يتعين عليك استخدام نموذج صغير بسبب التكلفة أو الخصوصية أو البنية التحتية أو قيود أخرى. 

في جميع الأمثلة أعلاه، ستحتاج إلى التأكد من أن لديك أو يمكنك بسهولة الحصول على مجموعة بيانات خاصة بالمجال كبيرة بما يكفي لضبط نموذج بدقة بشكل معقول. ستحتاج أيضًا إلى الوقت والموارد الكافية لضبط نموذج بدقة. 

إذا لم تكن الأمثلة المذكورة أعلاه تنطبق عليك، فقد يكون تحسين الأوامر أكثر فائدة.