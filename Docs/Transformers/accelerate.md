# Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ÙˆØ²Ø¹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ðŸ¤— Accelerate

Ù…Ø¹ ØªØ²Ø§ÙŠØ¯ Ø­Ø¬Ù… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ØŒ Ø¨Ø±Ø²Øª Ø§Ù„Ù…ÙˆØ§Ø²Ø§Ø© ÙƒØ§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø£ÙƒØ¨Ø± Ø¹Ù„Ù‰ Ø£Ø¬Ù‡Ø²Ø© Ù…Ø­Ø¯ÙˆØ¯Ø©ØŒ ÙˆØªØ³Ø±ÙŠØ¹ Ø³Ø±Ø¹Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ø¹Ø¯Ø© Ø±ØªØ¨ Ù…Ù† Ø§Ù„Ø­Ø¬Ù…. ÙˆÙÙŠ Hugging FaceØŒ Ù‚Ù…Ù†Ø§ Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù…ÙƒØªØ¨Ø© [ðŸ¤— Accelerate](https://huggingface.co/docs/accelerate) Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø¹Ù„Ù‰ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ ðŸ¤— Transformers Ø¨Ø³Ù‡ÙˆÙ„Ø© Ø¹Ù„Ù‰ Ø£ÙŠ Ù†ÙˆØ¹ Ù…Ù† Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…ÙˆØ²Ø¹Ø©ØŒ Ø³ÙˆØ§Ø¡ ÙƒØ§Ù†Øª Ø¹Ø¯Ø© ÙˆØ­Ø¯Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø±Ø³ÙˆÙ…ÙŠØ© (GPU) Ø¹Ù„Ù‰ Ø¬Ù‡Ø§Ø² ÙˆØ§Ø­Ø¯ Ø£Ùˆ Ø¹Ø¯Ø© ÙˆØ­Ø¯Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø±Ø³ÙˆÙ…ÙŠØ© Ø¹Ø¨Ø± Ø¹Ø¯Ø© Ø£Ø¬Ù‡Ø²Ø©. ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø¯Ø±Ø³ØŒ ØªØ¹Ù„Ù… ÙƒÙŠÙÙŠØ© ØªØ®ØµÙŠØµ Ø­Ù„Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø£ØµÙ„ÙŠØ© Ù„Ù€ PyTorch Ù„ØªÙ…ÙƒÙŠÙ† Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙÙŠ Ø¨ÙŠØ¦Ø© Ù…ÙˆØ²Ø¹Ø©.

## Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯

Ø§Ø¨Ø¯Ø£ Ø¨ØªØ«Ø¨ÙŠØª ðŸ¤— Accelerate:

```bash
pip install accelerate
```

Ø«Ù… Ù‚Ù… Ø¨Ø§Ø³ØªÙŠØ±Ø§Ø¯ ÙˆØ¥Ù†Ø´Ø§Ø¡ ÙƒØ§Ø¦Ù† [`~accelerate.Accelerator`]. Ø³ÙŠÙ‚ÙˆÙ… ÙƒØ§Ø¦Ù† [`~accelerate.Accelerator`] ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ø¨Ø§ÙƒØªØ´Ø§Ù Ù†ÙˆØ¹ Ø¥Ø¹Ø¯Ø§Ø¯Ùƒ Ø§Ù„Ù…ÙˆØ²Ø¹ ÙˆØªØ­Ø³ÙŠÙ† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù„Ø§Ø²Ù…Ø© Ù„Ù„ØªØ¯Ø±ÙŠØ¨. Ù„Ø§ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ÙˆØ¶Ø¹ Ù†Ù…ÙˆØ°Ø¬Ùƒ Ø¹Ù„Ù‰ Ø¬Ù‡Ø§Ø² Ø¨Ø´ÙƒÙ„ ØµØ±ÙŠØ­.

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
```

## Ø§Ù„Ø§Ø³ØªØ¹Ø¯Ø§Ø¯ Ù„Ù„ØªØ³Ø±ÙŠØ¹

Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„ØªØ§Ù„ÙŠØ© Ù‡ÙŠ ØªÙ…Ø±ÙŠØ± Ø¬Ù…ÙŠØ¹ ÙƒØ§Ø¦Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø°Ø§Øª Ø§Ù„ØµÙ„Ø© Ø¥Ù„Ù‰ Ø·Ø±ÙŠÙ‚Ø© [`~accelerate.Accelerator.prepare`]. ÙˆÙŠØ´Ù…Ù„ Ø°Ù„Ùƒ DataLoaders Ù„Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªÙ‚ÙŠÙŠÙ…ØŒ ÙˆÙ†Ù…ÙˆØ°Ø¬Ù‹Ø§ØŒ ÙˆÙ…ÙØ­ÙŽØ³ÙÙ‘Ù†Ù‹Ø§:

```py
>>> train_dataloader, eval_dataloader, model, optimizer = accelerator.prepare(
...     train_dataloader, eval_dataloader, model, optimizer
... )
```

## Ø§Ù„Ø®Ù„ÙÙŠ

Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø£Ø®ÙŠØ±Ø© Ù‡ÙŠ Ø§Ø³ØªØ¨Ø¯Ø§Ù„ "loss.backward()" Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ÙŠØ© ÙÙŠ Ø­Ù„Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ Ø¨Ø·Ø±ÙŠÙ‚Ø© ðŸ¤— Accelerate [`~accelerate.Accelerator.backward`]:

```py
>>> for epoch in range(num_epochs):
...     for batch in train_dataloader:
...         outputs = model(**batch)
...         loss = outputs.loss
...         accelerator.backward(loss)

...         optimizer.step()
...         lr_scheduler.step()
...         optimizer.zero_grad()
...         progress_bar.update(1)
```

ÙƒÙ…Ø§ ØªØ±ÙˆÙ† ÙÙŠ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ø§Ù„ØªØ§Ù„ÙŠØ©ØŒ ÙƒÙ„ Ù…Ø§ ØªØ­ØªØ§Ø¬Ù‡ Ù‡Ùˆ Ø¥Ø¶Ø§ÙØ© Ø£Ø±Ø¨Ø¹ Ø£Ø³Ø·Ø± Ù…Ù† Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ø¥Ù„Ù‰ Ø­Ù„Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ Ù„ØªÙ…ÙƒÙŠÙ† Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ÙˆØ²Ø¹!

```diff
+ from accelerate import Accelerator
  from transformers import AdamW, AutoModelForSequenceClassification, get_scheduler

+ accelerator = Accelerator()

  model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)
  optimizer = AdamW(model.parameters(), lr=3e-5)

- device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
- model.to(device)

+ train_dataloader, eval_dataloader, model, optimizer = accelerator.prepare(
+     train_dataloader, eval_dataloader, model, optimizer
+ )

  num_epochs = 3
  num_training_steps = num_epochs * len(train_dataloader)
  lr_scheduler = get_scheduler(
      "linear",
      optimizer=optimizer,
      num_warmup_steps=0,
      num_training_steps=num_training_steps
  )

  progress_bar = tqdm(range(num_training_steps))

  model.train()
  for epoch in range(num_epochs):
      for batch in train_dataloader:
-         batch = {k: v.to(device) for k, v in batch.items()}
          outputs = model(**batch)
          loss = outputs.loss
-         loss.backward()
+         accelerator.backward(loss)

          optimizer.step()
          lr_scheduler.step()
          optimizer.zero_grad()
          progress_bar.update(1)
```

## Ø§Ù„ØªØ¯Ø±ÙŠØ¨

Ø¨Ù…Ø¬Ø±Ø¯ Ø¥Ø¶Ø§ÙØ© Ø£Ø³Ø·Ø± Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©ØŒ Ù‚Ù… Ø¨ØªØ´ØºÙŠÙ„ ØªØ¯Ø±ÙŠØ¨Ùƒ ÙÙŠ Ù†Øµ Ø¨Ø±Ù…Ø¬ÙŠ Ø£Ùˆ Ø¯ÙØªØ± Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù…Ø«Ù„ Colaboratory.

### Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Øµ Ø¨Ø±Ù…Ø¬ÙŠ

Ø¥Ø°Ø§ ÙƒÙ†Øª ØªÙ‚ÙˆÙ… Ø¨ØªØ´ØºÙŠÙ„ ØªØ¯Ø±ÙŠØ¨Ùƒ Ù…Ù† Ù†Øµ Ø¨Ø±Ù…Ø¬ÙŠØŒ ÙÙ‚Ù… Ø¨ØªØ´ØºÙŠÙ„ Ø§Ù„Ø£Ù…Ø± Ø§Ù„ØªØ§Ù„ÙŠ Ù„Ø¥Ù†Ø´Ø§Ø¡ ÙˆØ­ÙØ¸ Ù…Ù„Ù ØªÙƒÙˆÙŠÙ†:

```bash
accelerate config
```

Ø«Ù… Ù‚Ù… Ø¨ØªØ´ØºÙŠÙ„ ØªØ¯Ø±ÙŠØ¨Ùƒ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù…:

```bash
accelerate launch train.py
```

### Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¯ÙØªØ± Ù…Ù„Ø§Ø­Ø¸Ø§Øª

ÙŠÙ…ÙƒÙ† Ù„Ù€ ðŸ¤— Accelerate Ø£ÙŠØ¶Ù‹Ø§ ØªØ´ØºÙŠÙ„Ù‡ ÙÙŠ Ø¯ÙØªØ± Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ®Ø·Ø· Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆØ­Ø¯Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª (TPUs) Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù€ Colaboratory. Ù‚Ù… Ø¨ØªØºÙ„ÙŠÙ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„Ø© Ø¹Ù† Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙÙŠ Ø¯Ø§Ù„Ø©ØŒ ÙˆÙ…Ø±Ø±Ù‡Ø§ Ø¥Ù„Ù‰ [`~accelerate.notebook_launcher`]:

```py
>>> from accelerate import notebook_launcher

>>> notebook_launcher(training_function)
```

Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø­ÙˆÙ„ ðŸ¤— Accelerate ÙˆÙ…ÙŠØ²Ø§ØªÙ‡ Ø§Ù„ØºÙ†ÙŠØ©ØŒ ÙŠØ±Ø¬Ù‰ Ø²ÙŠØ§Ø±Ø© [Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚](https://huggingface.co/docs/accelerate).