# ุญูุฑุฉ ุงูููุงุฐุฌ ุฐุงุช ุงูุทูู ุงูุซุงุจุช

ุญูุฑุฉ (PPL) ูู ูุงุญุฏุฉ ูู ุฃูุซุฑ ุงูููุงููุณ ุดููุนูุง ูุชูููู ููุงุฐุฌ ุงููุบุฉ. ูุจู ุงูุบูุต ูู ุงูููุถูุนุ ูุฌุจ ุฃู ููุงุญุธ ุฃู ุงููููุงุณ ููุทุจู ุจุดูู ุฎุงุต ุนูู ููุงุฐุฌ ุงููุบุฉ ุงูููุงุณูููุฉ (ููุทูู ุนูููุง ุฃุญูุงููุง ููุงุฐุฌ ุงููุบุฉ ุงูุฐุงุชูุฉ ุงูุชุนุฒูุฒ ุฃู ุงูุณุจุจูุฉ) ููู ุบูุฑ ูุญุฏุฏุฉ ุฌูุฏูุง ูููุงุฐุฌ ุงููุบุฉ ุงููููุนุฉ ูุซู BERT (ุฑุงุฌุน [ููุฎุต ุงูููุงุฐุฌ](model_summary)).

ุชูุนุฑููู ุงูุญูุฑุฉ ุนูู ุฃููุง ุงูุฃุณ ุงูุฃุณุงุณู ูููุชูุณุท ุงูููุบุงุฑูุชูู ุงูุงุญุชูุงูู ุงูุณูุจู ูุชุณูุณู. ุฅุฐุง ูุงู ูุฏููุง ุชุณูุณู ูููุฒ \\(X = (x_0, x_1, \dots, x_t)\\)ุ ูุฅู ุญูุฑุฉ \\(X\\) ููุ

$$\text{PPL}(X) = \exp \left\{ {-\frac{1}{t}\sum_i^t \log p_\theta (x_i|x_{<i}) } \right\}$$

ุญูุซ \\(\log p_\theta (x_i|x_{<i})\\) ูู ุงูููุบุงุฑูุชู ุงูุงุญุชูุงูู ููุฑูุฒ i ุงููุดุฑูุท ุจุงูุฑููุฒ ุงูุณุงุจูุฉ \\(x_{<i}\\) ููููุง ููููุฐุฌูุง. ููู ุงููุงุญูุฉ ุงูุจุฏูููุฉุ ูููู ุงุนุชุจุงุฑูุง ุชูููููุง ููุฏุฑุฉ ุงููููุฐุฌ ุนูู ุงูุชูุจุค ุจุดูู ููุญุฏ ุจูู ูุฌููุนุฉ ูู ุงูุฑููุฒ ุงููุญุฏุฏุฉ ูู ูุฌููุนุฉ ูู ุงููุตูุต. ููู ุงูููู ุฃู ููุงุญุธ ุฃู ูุฐุง ูุนูู ุฃู ุฅุฌุฑุงุก ุงูุชูููุฒ ุจูู ุงูุฑููุฒ ูู ุชุฃุซูุฑ ูุจุงุดุฑ ุนูู ุญูุฑุฉ ุงููููุฐุฌุ ูุงูุชู ูุฌุจ ุฃู ุชุคุฎุฐ ุฏุงุฆููุง ูู ุงูุงุนุชุจุงุฑ ุนูุฏ ููุงุฑูุฉ ุงูููุงุฐุฌ ุงููุฎุชููุฉ.

ููุฐุง ูุนุงุฏู ุฃูุถูุง ุฃุณ ุงูุฃุณุงุณ ููุงูุชุฑูุจูุง ุงููุดุชุฑูุฉ ุจูู ุงูุจูุงูุงุช ูุชูุจุคุงุช ุงููููุฐุฌ. ููุฒูุฏ ูู ุงูุจุฏูููุงุช ุญูู ุงูุญูุฑุฉ ูุนูุงูุชูุง ุจู Bits Per Character (BPC) ูุถุบุท ุงูุจูุงูุงุชุ ุชุญูู ูู ูุฐู [ุงูุชุฏูููุฉ ุงูุฑุงุฆุนุฉ ุนูู The Gradient](https://thegradient.pub/understanding-evaluation-metrics-for-language-models/).

## ุญุณุงุจ PPL ูุน ุงูููุงุฐุฌ ุฐุงุช ุงูุทูู ุงูุซุงุจุช

ุฅุฐุง ูู ููู ูููุฏูู ุจุญุฌู ุณูุงู ุงููููุฐุฌุ ูุณูููู ุจุชูููู ุญูุฑุฉ ุงููููุฐุฌ ุนู ุทุฑูู ุชูููู ุชุณูุณู ุจุทุฑููุฉ ุฐุงุชูุฉ ุงูุชุนุฒูุฒ ูุงูุชุนุงูู ุงูุดุฑุทู ูุน ุงูุชุณูุณู ุงููุฑุนู ุงูุณุงุจู ุจุงููุงูู ูู ูู ุฎุทูุฉุ ููุง ูู ููุถุญ ุฃุฏูุงู.

![ุงูุชูููู ุงููุงูู ูุชุณูุณู ูุน ุทูู ุณูุงู ุบูุฑ ูุญุฏูุฏ](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/ppl_full.gif)

ููุน ุฐููุ ุนูุฏ ุงูุนูู ูุน ุงูููุงุฐุฌ ุงูุชูุฑูุจูุฉุ ุนุงุฏุฉ ูุง ูููู ูุฏููุง ููุฏ ุนูู ุนุฏุฏ ุงูุฑููุฒ ุงูุชู ูููู ูููููุฐุฌ ูุนุงูุฌุชูุง. ุนูู ุณุจูู ุงููุซุงูุ ุชุญุชูู ุฃูุจุฑ ูุณุฎุฉ ูู [GPT-2](model_doc/gpt2) ุนูู ุทูู ุซุงุจุช ูุจูุบ 1024 ุฑูุฒูุงุ ูุฐูู ูุง ูููููุง ุญุณุงุจ \\(p_\theta(x_t|x_{<t})\\) ูุจุงุดุฑุฉ ุนูุฏูุง \\(t\\) ุฃูุจุฑ ูู 1024.

ุจุฏูุงู ูู ุฐููุ ูุชู ุนุงุฏุฉู ุชูุณูู ุงูุชุณูุณู ุฅูู ุชุณูุณูุงุช ูุฑุนูุฉ ุชุณุงูู ุญุฌู ุงูุฅุฏุฎุงู ุงูุฃูุตู ูููููุฐุฌ. ุฅุฐุง ูุงู ุญุฌู ุงูุฅุฏุฎุงู ุงูุฃูุตู ูููููุฐุฌ ูู \\(k\\)ุ ูุฅููุง ูููู ุจุนุฏ ุฐูู ุจุชูุฑูุจ ุงุญุชูุงู ุงูุฑูุฒ \\(x_t\\) ุนู ุทุฑูู ุงูุชุนุงูู ุงูุดุฑุทู ููุท ูุน \\(k-1\\) ูู ุงูุฑููุฒ ุงูุชู ุชุณุจูู ุจุฏูุงู ูู ุงูุณูุงู ุจุฃูููู. ุนูุฏ ุชูููู ุญูุฑุฉ ุงููููุฐุฌ ูุชุณูุณูุ ููุงู ููุฌ ูุบุฑู ููููู ุฏูู ุงููุณุชูู ุงูุฃูุซู ููู ุชูุณูู ุงูุชุณูุณู ุฅูู ูุทุน ุบูุฑ ูุชุฏุงุฎูุฉ ูุฅุถุงูุฉ ุงูููุบุงุฑูุชููุงุช ุงูููููุฉ ููู ุฌุฒุก ุจุดูู ูุณุชูู.

![ุญูุฑุฉ ุบูุฑ ูุซุงููุฉ ูุง ุชุณุชููุฏ ูู ุงูุณูุงู ุงููุงูู ุงููุชุงุญ](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/ppl_chunked.gif)

ูุฐุง ุณุฑูุน ุงูุญุณุงุจ ูุฃู ุญูุฑุฉ ูู ุฌุฒุก ูููู ุญุณุงุจูุง ูู ุชูุฑูุฑ ูุงุญุฏ ููุฃูุงูุ ููููู ููุซู ุชูุฑูุจูุง ุณูุฆูุง ููุญูุฑุฉ ุงูููููุฉ ุจุงููุงูู ูุณูุคุฏู ุนุงุฏุฉู ุฅูู ุญูุฑุฉ ุฃุนูู (ุฃุณูุฃ) ูุฃู ุงููููุฐุฌ ุณูููู ูุฏูู ุณูุงู ุฃูู ูู ูุนุธู ุฎุทูุงุช ุงูุชูุจุค.

ุจุฏูุงู ูู ุฐููุ ูุฌุจ ุชูููู ุญูุฑุฉ ุงูููุงุฐุฌ ุฐุงุช ุงูุทูู ุงูุซุงุจุช ุจุงุณุชุฎุฏุงู ุฅุณุชุฑุงุชูุฌูุฉ ุงููุงูุฐุฉ ุงูููุฒููุฉ. ููุทูู ูุฐุง ุนูู ุชุญุฑูู ูุงูุฐุฉ ุงูุณูุงู ุจุดูู ูุชูุฑุฑ ุจุญูุซ ูููู ูููููุฐุฌ ุณูุงู ุฃูุจุฑ ุนูุฏ ุฅุฌุฑุงุก ูู ุชูุจุค.

![ุญูุฑุฉ ุงููุงูุฐุฉ ุงูููุฒููุฉ ุงูุชู ุชุณุชููุฏ ูู ูู ุงูุณูุงู ุงููุชุงุญ](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/ppl_sliding.gif)

ูุฐุง ุชูุฑูุจ ุฃูุซู ููุชูููู ุงูุญูููู ูุงุญุชูุงููุฉ ุงูุชุณูุณู ูุนุงุฏุฉ ูุง ูุคุฏู ุฅูู ูุชูุฌุฉ ุฃูุถู. ุงูุฌุงูุจ ุงูุณูุจู ูู ุฃูู ูุชุทูุจ ุชูุฑูุฑูุง ููุฃูุงู ููู ุฑูุฒ ูู ุงููุฌููุนุฉ. ุญู ูุณุท ุนููู ุฌูุฏ ูู ุงุณุชุฎุฏุงู ูุงูุฐุฉ ููุฒููุฉ ุฐุงุช ุฎุทูุฉุ ุญูุซ ุชุชุญุฑู ุงููุงูุฐุฉ ุจุฎุทูุงุช ุฃูุจุฑ ุจุฏูุงู ูู ุงูุงูุฒูุงู ุจููุฏุงุฑ 1 ุฑูุฒ ูู ูู ูุฑุฉ. ูุณูุญ ุฐูู ุจุฅุฌุฑุงุก ุงูุญุณุงุจ ุจุดูู ุฃุณุฑุน ูุน ุฅุนุทุงุก ุงููููุฐุฌ ุณูุงููุง ูุจูุฑูุง ููุชูุจุคุงุช ูู ูู ุฎุทูุฉ.

## ูุซุงู: ุญุณุงุจ ุงูุญูุฑุฉ ูุน GPT-2 ูู ๐ค Transformers

ุฏุนููุง ููุถุญ ูุฐู ุงูุนูููุฉ ูุน GPT-2.

```python
from transformers import GPT2LMHeadModel, GPT2TokenizerFast

device = "cuda"
model_id = "openai-community/gpt2-large"
model = GPT2LMHeadModel.from_pretrained(model_id).to(device)
tokenizer = GPT2TokenizerFast.from_pretrained(model_id)
```

ุณูููู ุจุชุญููู ูุฌููุนุฉ ุจูุงูุงุช WikiText-2 ูุชูููู ุงูุญูุฑุฉ ุจุงุณุชุฎุฏุงู ุจุนุถ ุฅุณุชุฑุงุชูุฌูุงุช ุงููุงูุฐุฉ ุงูููุฒููุฉ ุงููุฎุชููุฉ. ูุธุฑูุง ูุฃู ูุฐู ุงููุฌููุนุฉ ุตุบูุฑุฉ ููููู ุจุชูุฑูุฑ ูุงุญุฏ ููุท ุนุจุฑ ุงููุฌููุนุฉุ ููููููุง ุชุญููู ุงููุฌููุนุฉ ูุชุดููุฑูุง ุจุงููุงูู ูู ุงูุฐุงูุฑุฉ.

```python
from datasets import load_dataset

test = load_dataset("wikitext", "wikitext-2-raw-v1", split="test")
encodings = tokenizer("\n\n".join(test["text"]), return_tensors="pt")
```

ูุน ๐ค Transformersุ ูููููุง ุจุจุณุงุทุฉ ุชูุฑูุฑ `input_ids` ูู `labels` ุฅูู ูููุฐุฌูุงุ ููุชู ุฅุฑุฌุงุน ูุชูุณุท ุงูููุบุงุฑูุชููุงุช ุงูุณูุจูุฉ ููู ุฑูุฒ ูุฎุณุงุฑุฉ. ููุน ุฐููุ ูุน ููุฌ ุงููุงูุฐุฉ ุงูููุฒููุฉ ูุฏููุงุ ููุงู ุชุฏุงุฎู ูู ุงูุฑููุฒ ุงูุชู ููุฑุฑูุง ุฅูู ุงููููุฐุฌ ูู ูู ุชูุฑุงุฑ. ูุง ูุฑูุฏ ุฃู ูุชู ุชุถููู ุงูููุบุงุฑูุชููุงุช ุงูุงุญุชูุงููุฉ ููุฑููุฒ ุงูุชู ูุชุนุงูู ูุนูุง ููุท ูุณูุงู ูู ุฎุณุงุฑุชูุงุ ูุฐุง ูููููุง ุชุนููู ูุฐู ุงูุฃูุฏุงู ุฅูู `-100` ุจุญูุซ ูุชู ุชุฌุงูููุง. ูุง ููู ูู ูุซุงู ุนูู ููููุฉ ุงูููุงู ุจุฐูู ูุน ุฎุทูุฉ ูู `512`. ููุฐุง ูุนูู ุฃู ุงููููุฐุฌ ุณูููู ูุฏูู 512 ุฑูุฒูุง ุนูู ุงูุฃูู ูุณูุงู ุนูุฏ ุญุณุงุจ ุงูุงุญุชูุงููุฉ ุงูุดุฑุทูุฉ ูุฃู ุฑูุฒ ูุงุญุฏ (ุดุฑูุทุฉ ุฃู ุชููู ููุงู 512 ุฑูุฒูุง ุณุงุจููุง ูุชุงุญูุง ููุชุนุงูู ุงูุดุฑุทู ูุนู).

```python
import torch
from tqdm import tqdm

max_length = model.config.n_positions
stride = 512
seq_len = encodings.input_ids.size(1)

nlls = []
prev_end_loc = 0
for begin_loc in tqdm(range(0, seq_len, stride)):
end_loc = min(begin_loc + max_length, seq_len)
trg_len = end_loc - prev_end_loc  # ูุฏ ูุฎุชูู ุนู ุงูุฎุทูุฉ ูู ุงูุญููุฉ ุงูุฃุฎูุฑุฉ
input_ids = encodings.input_ids[:, begin_loc:end_loc].to(device)
target_ids = input_ids.clone()
target_ids[:, :-trg_len] = -100

with torch.no_grad():
outputs = model(input_ids, labels=target_ids)

# ูุชู ุญุณุงุจ ุงูุฎุณุงุฑุฉ ุจุงุณุชุฎุฏุงู CrossEntropyLoss ุงูุฐู ูุญุณุจ ุงููุชูุณุท ุนูู ุงูุชุตูููุงุช ุงูุตุงูุญุฉ
# ูุงุญุธ ุฃู ุงููููุฐุฌ ูุญุณุจ ุงูุฎุณุงุฑุฉ ููุท ุนูู trg_len - 1 ูู ุงูุชุตูููุงุชุ ูุฃูู ูุชุญูู ุฏุงุฎูููุง ุฅูู ุงููุณุงุฑ ุจูุงุณุทุฉ 1.
neg_log_likelihood = outputs.loss

nlls.append(neg_log_likelihood)

prev_end_loc = end_loc
if end_loc == seq_len:
break

ppl = torch.exp(torch.stack(nlls).mean())
```

ูุนุทู ุชุดุบูู ูุฐุง ูุน ุทูู ุงูุฎุทูุฉ ูุณุงูู ุทูู ุงูุฅุฏุฎุงู ุงูุฃูุตู ูุชูุฌุฉ ููุงุซูุฉ ูุงุณุชุฑุงุชูุฌูุฉ ุงููุงูุฐุฉ ุบูุฑ ุงูููุฒููุฉ ุงูุชู ูุงูุดูุงูุง ุฃุนูุงู. ูููุง ุตุบุฑุช ุงูุฎุทูุฉุ ุฒุงุฏ ุงูุณูุงู ุงูุฐู ุณูููู ูุฏู ุงููููุฐุฌ ูู ุฅุฌุฑุงุก ูู ุชูุจุคุ ููููุง ูุงูุช ุงูุญูุฑุฉ ุงููุจูุบ ุนููุง ุฃูุถู ุนุงุฏุฉู.

ุนูุฏูุง ูููู ุจุชุดุบูู ูุง ุณุจู ุจุงุณุชุฎุฏุงู `stride = 1024`ุ ุฃู ุจุฏูู ุชุฏุงุฎูุ ุชููู ูุชูุฌุฉ PPL ูู `19.44`ุ ููู ูุง ููุงุซู `19.93` ุงููุจูุบ ุนูู ูู ูุฑูุฉ GPT-2. ูู ุฎูุงู ุงุณุชุฎุฏุงู `stride = 512` ูุจุงูุชุงูู ุงุณุชุฎุฏุงู ุฅุณุชุฑุงุชูุฌูุฉ ุงููุงูุฐุฉ ุงูููุฒููุฉ ูุฏููุงุ ููุฎูุถ ูุฐุง ุฅูู `16.45`. ูุฐู ุงููุชูุฌุฉ ููุณุช ููุท ุฃูุถูุ ูููููุง ูุญุณูุจุฉ ุจุทุฑููุฉ ุฃูุฑุจ ุฅูู ุงูุชูููู ุงูุฐุงุชู ุงูุชุนุฒูุฒ ุงูุญูููู ูุงุญุชูุงููุฉ ุงูุชุณูุณู.